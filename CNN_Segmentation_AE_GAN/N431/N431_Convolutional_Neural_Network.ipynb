{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "N431_Convolutional_Neural_Network.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "joZkbxIjRSpe",
        "GS_pFnv4I8CA"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joZkbxIjRSpe"
      },
      "source": [
        "<img src='https://user-images.githubusercontent.com/6457691/90080969-0f758d00-dd47-11ea-8191-fa12fd2054a7.png' width = '200' align = 'right'>\n",
        "\n",
        "## *AIB / SECTION 4 / SPRINT 3 / NOTE 1*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Q_qCsRbRhJ0"
      },
      "source": [
        "# N431. 합성곱 신경망(Convolutional Neural Network)과 전이 학습(Transfer Learning)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 컴퓨터 비전(Computer Vision)"
      ],
      "metadata": {
        "id": "GS_pFnv4I8CA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN(Convolutional Neural Network, 합성곱 신경망)과 CNN의 구조"
      ],
      "metadata": {
        "id": "EFY-bjSLJ5YK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번 시간에는 **컴퓨터 비전(Computer Vision)**에서 자주 사용되는 **<font color=\"ff6f61\">합성곱 신경망(Convolutional Neural Network, CNN)</font>**을 알아보도록 하겠습니다.\n",
        "\n",
        "합성곱 신경망(CNN)이 이미지 분류에서 주목받은 시기는 2012년인데요.<br/>\n",
        "매년 열리는 이미지넷(ImageNet) 데이터셋 분류 경진대회인 ILSVRC 에서 2012년에 우승한 AlexNet 덕분이었습니다."
      ],
      "metadata": {
        "id": "iXw29Cewn4eE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "합성곱 신경망이 이미지 분류에서 주목받게 된 이유는 무엇일까요?\n",
        "\n",
        "이미지는 위치에 맞는 **공간적인 특성**을 가지고 있습니다.<br/>\n",
        "하지만 여러분이 Sprint 1 에서 구축해보셨던 다층 퍼셉트론 신경망(MLP)은<br/>\n",
        "**모든 입력 값을 `Flatten`으로 펴준 뒤에 연산**하기 때문에 이런 공간적 특성을 잘 살려내지 못합니다.\n",
        "\n",
        "MNIST 데이터 처럼 간단한 이미지 데이터는 MLP로도 분류가 가능하지만<br/>\n",
        "패턴이 복잡한 컬러 이미지를 이런 방식으로 분류하는 것은 쉽지 않은데요.<br/>\n",
        "\n",
        "반면 합성곱 신경망은 학습 과정에서 이런 공간적 특성을 보존하며 학습할 수 있습니다.<br/>\n",
        "합성곱 층은 이미지의 일부분을 훑으면서 연산이 진행되며 특징을 잡아내어 학습하기 때문에<br/>\n",
        "층이 깊어지더라도 공간적 특성을 최대한 보존할 수 있습니다.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R6dSe-37n4ZA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN의 구조"
      ],
      "metadata": {
        "id": "G2bWzF-f5wse"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "기본적인 CNN의 구조는 아래 그림과 같이 특징 추출 부분(1), 분류를 위한 신경망(2)의 2단계로 나눌 수 있습니다.\n"
      ],
      "metadata": {
        "id": "Jw4qHA_vRHsv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://i.imgur.com/yVw7una.png\" height=\"500\">\n"
      ],
      "metadata": {
        "id": "JuwxaZ9Ba9Lk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "먼저 특징이 추출되는 부분인 **합성곱 층(Convolution Layer)**과 **풀링 층(Pooling Layer)**에 대해서 알아보도록 하겠습니다."
      ],
      "metadata": {
        "id": "zv68vwVhLxEf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmhyZl21SrRM"
      },
      "source": [
        "## 합성곱(Convolution) 과 풀링(Pooling)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mTzSvWGiRUE"
      },
      "source": [
        "### 헙성곱(Convolution)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "먼저 합성곱 층에 대해 알아보도록 하겠습니다.<br/>\n",
        "합성곱 층에서는 **<font color=\"ff6f61\">합성곱 필터(Convolution Filter)</font>**가 **슬라이딩(Sliding)**하며 이미지 부분부분의 특징을 읽어나갑니다.\n",
        "\n",
        "아래는 필터가 슬라이딩하며 연산되는 모습을 나타낸 gif 입니다."
      ],
      "metadata": {
        "id": "sOIHghPgMCXO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCf1wc1XeHLX"
      },
      "source": [
        "<img src=\"https://cdn-images-1.medium.com/max/800/1*MrGSULUtkXc0Ou07QouV8A.gif\" height=\"250\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoQd17O0eI9I"
      },
      "source": [
        "위 이미지에서 볼 수 있듯 필터가 왼쪽 위부터 차례로 슬라이딩하며 합성곱을 진행해나갑니다.<br/>\n",
        "아래 그림은 각 위치에서 어떠한 방식으로 합성곱이 연산되는 지를 보여주고 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx2YBEDfeTos"
      },
      "source": [
        "<img src=\"https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/etc/note431/CNN2.png\" width=500>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnuJvghteg3k"
      },
      "source": [
        "다음으로는 Convolution에 적용할 수 있는 **패딩(Padding)**과 **스트라이드(Stride)**에 대해서 알아보도록 하겠습니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 패딩(Padding)"
      ],
      "metadata": {
        "id": "n5lRBJ3Cd3nO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VswD5Bi3i-Bh"
      },
      "source": [
        "**<font color=\"ff6f61\">패딩(Padding)</font>**은 이미지 외부를 특정한 값으로 둘러싸서 처리해주는 방식입니다.<br/>\n",
        "아래 그림처럼 '0'으로 둘러싸주는 제로-패딩(Zero-Padding)이 가장 많이 사용됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiiG6zBAjneL"
      },
      "source": [
        "<img src=\"https://i.imgur.com/GRDbmHF.gif\" height=\"300\">"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "연산되어 나오는 Output, 즉 Feature map 의 크기를 조절하고 실제 이미지 값을 충분히 활용하기 위해 사용됩니다."
      ],
      "metadata": {
        "id": "XMpl0BhpgE_6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 스트라이드(Stride)"
      ],
      "metadata": {
        "id": "_3BIcjj3gbBc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8XEooeujsn_"
      },
      "source": [
        "**<font color=\"ff6f61\">스트라이드(Stride)</font>**는 '보폭'이라는 뜻을 가진 단어입니다.<br/>\n",
        "Stride 를 조절하면 슬라이딩(Sliding)시에 몇 칸 씩 건너뛸지를 나타냅니다.\n",
        "\n",
        "위에서 살펴본 것처럼 필터가 한 칸씩 슬라이딩하려면 **`Stride=1`** 로 해주어야 하며<br/>\n",
        "두 칸씩 슬라이딩하려면 **`Stride=2`** 로 설정해주어야 합니다.\n",
        "\n",
        "두 가지 경우에 대해 아래 그림을 보며 알아보도록 하겠습니다.\n",
        "\n",
        "> ❗️ ***아래 그림에서 Stride가 변함에 따라 출력되는 Feature map의 크기가 어떻게 변하는지 주목해봅시다.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyaPAVo0iOOw"
      },
      "source": [
        "- **Stride = 1**\n",
        "\n",
        "<img src=\"https://adeshpande3.github.io/assets/Stride1.png\"/>\n",
        "\n",
        "- **Stride = 2**\n",
        "\n",
        "<img src=\"https://adeshpande3.github.io/assets/Stride2.png\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **필터 크기(Filter size), 패딩(Padding), 스트라이드(Stride)에 따른 Feature map 크기 변화**\n",
        "\n",
        "$$\n",
        "N_{\\text{out}} = \\bigg[\\frac{N_{\\text{in}} + 2p - k}{s}\\bigg] + 1\n",
        "$$\n",
        "\n",
        "$N_{\\text{in}}$ : 입력되는 이미지의 크기(=피처 수) <br/>\n",
        "$N_{\\text{out}}$ : 출력되는 이미지의 크기(=피처 수) <br/>\n",
        "$k$ : 합성곱에 사용되는 커널(=필터)의 크기 <br/>\n",
        "$p$ : 합성곱에 적용한 패딩 값 <br/>\n",
        "$s$ : 합성곱에 적용한 스트라이드 값"
      ],
      "metadata": {
        "id": "3mKnqO9hh3JU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 풀링(Pooling)"
      ],
      "metadata": {
        "id": "RTGx-oIvqNrs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "가로, 세로 방향의 공간을 줄이기 위한 **<font color=\"ff6f61\">풀링(Pooling)</font>**을 수행합니다.\n",
        "\n",
        "풀링 방법에는 **최대 풀링(Max pooling)**과 **평균 풀링(Average pooling)**이 있습니다. <br/>\n",
        "최대 풀링은 정해진 범위 내에서 가장 큰 값을 꺼내오는 방식이며 평균 풀링은 정해진 범위 내에 있는 모든 요소의 평균을 가져오는 방식입니다.<br/>\n",
        "일반적으로 이미지를 처리할 때에는 각 부분의 특징을 최대로 보존하기 위해서 최대 풀링을 사용합니다.<br/>\n",
        "아래 그림은 $2×2$ 크기의 최대 풀링과 평균 풀링을 처리하는 과정을 비교하여 나타낸 것입니다."
      ],
      "metadata": {
        "id": "TEgga8hnlVbp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://i.imgur.com/ZuJLMFi.png\" height=\"350\">"
      ],
      "metadata": {
        "id": "oRPICim2m82Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 그림에서 왼쪽은 최대 풀링으로 각각의 2×2의 범위 내에서 가장 큰 요소인 100,184,12,45 출력 데이터로 가져옵니다.<br/>\n",
        "오른쪽은 평균 풀링으로 각각의 2×2의 범위 내 요소의 평균값인 36,80,12,15 를 출력 데이터로 가져옵니다.\n",
        "\n",
        "풀링 층은 학습해야 할 **가중치가 없으며 채널 수가 변하지 않는다**는 특징을 가지고 있습니다."
      ],
      "metadata": {
        "id": "xJh9rCxenRfe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 완전 연결 신경망(Fully Connected Layer)"
      ],
      "metadata": {
        "id": "GxUvevp0rTMG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "합성곱 층(Convolutional Layer)와 풀링 층(Pooling Layer)에서 충분히 특징을 추출했다면,<br/>\n",
        "다음은 분류를 위한 완전 연결 신경망을 구축할 차례입니다.\n",
        "\n",
        "완전 연결 신경망은 여러분이 이전에 구축했던 다층 퍼셉트론 신경망으로 구성되어 있으며<br/>\n",
        "풀어야 하는 문제에 따라서 출력층을 잘 설계해주는 것이 중요합니다."
      ],
      "metadata": {
        "id": "JxzWkZZsrbh_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN의 학습"
      ],
      "metadata": {
        "id": "sE9PzC_in4es"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "그렇다면 CNN에서는 어떤 부분이 학습될까요?<br/>\n",
        "영상을 잠깐 멈추고 지금까지 배운 층에서 어떤 부분에 학습되는 가중치가 있었을 지 알아보도록 합시다."
      ],
      "metadata": {
        "id": "ulvrdHmvq_7z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이미 위 내용을 학습하면서 눈치채신 분들도 계시겠지만<br/>\n",
        "정답은 Convolution 층에 있는 **Filter의 가중치**입니다.\n",
        "\n",
        "그렇다면 학습된 필터의 모습은 어떻게 생겼을까요?<br/>\n",
        "아래 그림은 ImageNet 데이터를 학습한 CNN의 첫 번째 Convolution 층의 Filter 가중치를 시각화한 이미지입니다."
      ],
      "metadata": {
        "id": "O8VjlBaDnDwy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_-V8usaYgA4"
      },
      "source": [
        "<img src=\"https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/etc/note431/CNN3.png\" height = \"300\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "그럼 층이 깊어지면 필터는 어떤 특징을 잡아낼까요?<br/>\n",
        "Convolution 층과 Pooling 층을 거치면서 이미지가 작아지고 Convolution 층의 Filter는 더 큰 특징을 포착하게 됩니다.\n",
        "\n",
        "아래는 CNN층이 깊어지면서 필터가 어떤 부분을 학습하게 되는 지를 나타낸 이미지입니다."
      ],
      "metadata": {
        "id": "NVLVPDny0kTD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://i.imgur.com/0mOlT1j.jpg\" height=\"450\">"
      ],
      "metadata": {
        "id": "8E19cnxf0Prb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "그림을 보면 낮은 층에서는 가로, 세로 등의 특징을 학습함을 볼 수 있고, 층이 깊어지면서 물체의 일부를 포착하게 됩니다.<br/>\n",
        "그리고 층이 더욱 깊어지게 되면 물체 전체의 윤곽에 해당하는 특징을 학습함을 알 수 있습니다."
      ],
      "metadata": {
        "id": "cGF4DVqQ1D5q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example"
      ],
      "metadata": {
        "id": "ZmO175F-E06B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "일반적인 이미지를 10개의 클래스로 분류하는 데이터셋인 **Cifar10 데이터셋**을 직접 구축한 CNN을 통해 분류하는 예제를 풀어보도록 하겠습니다. "
      ],
      "metadata": {
        "id": "nZS3uGWPE3cN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ❓ ***Cifar10 예제는 이진 분류, 다중 분류, 회귀 중 어디에 속할까요? <br/>\n",
        "<font color=\"ff6f61\">항상 문제를 풀기 전에 자신이 풀고자 하는 문제가 어디에 속하는지 생각</font>해보도록 합시다.***"
      ],
      "metadata": {
        "id": "cUD3jcOA2Bok"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **먼저 필요한 패키지와 라이브러리를 불러옵니다.**"
      ],
      "metadata": {
        "id": "D1WIUhRN2T1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "a3_oj5cBF4xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **시드(Seed)를 고정합니다.**"
      ],
      "metadata": {
        "id": "MJnJ4fba2bVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "DkMQjH2DGHRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **데이터셋을 불러온 후 학습 데이터셋(Train Dataset)과 시험 데이터셋(Test Dataset)으로 나누어(Split)주고 픽셀값을 정규화 하여줍니다.**"
      ],
      "metadata": {
        "id": "IyerYNv02dPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "id": "dZkwnB1IGI9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype('float32') / 255.\n",
        "X_test = X_test.astype('float32') / 255."
      ],
      "metadata": {
        "id": "EZcCmUp3GLmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=.2)"
      ],
      "metadata": {
        "id": "VNAzT2gxGNW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **이제 본격적으로 신경망 모델을 구축해보겠습니다.**\n",
        "\n",
        "    3개의 Convolution 층 사이에 Pooling 층을 끼워넣어 특징 추출 부분을 구성하고<br/>\n",
        "1개의 은닉층과 출력층으로 구성된 완전 연결 신경망으로 분류기를 구축합니다.\n",
        "\n",
        "    > ❗️ ***아래 주어진 예시 코드 이외에도 층을 추가해보거나 제외해보면서<br/>\n",
        "모델 구조를 다양하게 바꾸어 성능을 테스트 해봅시다.***"
      ],
      "metadata": {
        "id": "xpMHG1EX2jpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "-5YpsDB0F5Sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "T9MwYE1HGE-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train,\n",
        "          batch_size=128,\n",
        "          validation_data=(X_val, y_val),\n",
        "          epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6O4H7Q3Gggx",
        "outputId": "fc14b0c5-6b61-4ff2-b1d1-6f31cacc6d05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "313/313 [==============================] - 11s 8ms/step - loss: 1.6036 - accuracy: 0.4191 - val_loss: 1.3597 - val_accuracy: 0.5149\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.1811 - accuracy: 0.5817 - val_loss: 1.0740 - val_accuracy: 0.6236\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.9995 - accuracy: 0.6459 - val_loss: 1.0357 - val_accuracy: 0.6376\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.8806 - accuracy: 0.6913 - val_loss: 0.9105 - val_accuracy: 0.6808\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.7891 - accuracy: 0.7240 - val_loss: 0.8642 - val_accuracy: 0.6959\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.7068 - accuracy: 0.7538 - val_loss: 0.8481 - val_accuracy: 0.7056\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.6291 - accuracy: 0.7795 - val_loss: 0.8562 - val_accuracy: 0.7035\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.5632 - accuracy: 0.8033 - val_loss: 0.8267 - val_accuracy: 0.7180\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.4853 - accuracy: 0.8295 - val_loss: 0.8418 - val_accuracy: 0.7246\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.4193 - accuracy: 0.8533 - val_loss: 0.8970 - val_accuracy: 0.7168\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3040231610>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. **학습한 신경망 모델을 사용하여 평가합니다.**"
      ],
      "metadata": {
        "id": "Nyttu_ZW4B0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2GZgwmqGg_u",
        "outputId": "1f99c028-134d-401e-dffc-b6fe1d05c6d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 1s - loss: 0.9178 - accuracy: 0.7166 - 851ms/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9178150296211243, 0.7166000008583069]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 전이학습 (Transfer Learning)\n"
      ],
      "metadata": {
        "id": "B94pA-ImrmDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "논문 등 여러 학술자료를 검색할 수 있는 [구글 스칼라(Google Scholar)](https://scholar.google.com/)로 가면 다음과 같은 말을 볼 수 있습니다."
      ],
      "metadata": {
        "id": "G71z-HBEOgIs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://i.imgur.com/0AgnMo3.png\" height=\"250\"/>\n"
      ],
      "metadata": {
        "id": "9U7OX1YdOk_H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 페이지에서 볼 수 있는 **\"거인의 어깨에 올라서서 더 넓은 세상을 바라보라\"**는 말은<br/>\n",
        "'이미 잘 정립된 지식을 바탕으로 하여 더 높은 곳에 이를 수 있었다'는 뜻을 가지고 있는데요.\n",
        "\n",
        "이를 신경망 학습에 적용한 것이 바로 **<font color=\"ff6f61\">전이 학습(Transfer Learning)</font>** 입니다.<br/>\n",
        "일반적으로 전이 학습은 대량의 데이터를 학습한 **사전 학습 모델(Pre-trained Model)**의 가중치를 그대로 가져온 뒤<br/>\n",
        "분류기, 즉 완전 연결 신경망 부분만 추가로 설계하여 사용합니다.\n",
        "\n",
        "다음 이미지는 전이 학습을 나타낸 이미지입니다.<br/>\n",
        "사전 학습 모델(위)을 바탕으로 새로운 모델(아래)을 구축합니다."
      ],
      "metadata": {
        "id": "f3ha8RPjPRPP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://i.imgur.com/LT79Yw1.jpg\" height=\"400\"/>\n",
        "\n"
      ],
      "metadata": {
        "id": "qfqNMbc6rtbx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "사전 학습 모델의 가중치는 대량의 데이터를 학습하여 얻어지는데요.<br/>\n",
        "여러 데이터의 일반적인 특징을 많이 학습하였기 때문에 어떠한 데이터를 넣더라도 준수한 성능을 보입니다.\n",
        "\n",
        "일반적으로 사전 학습 가중치는 학습되지 않도록 고정(**`freeze`**)한 채로 진행되기 때문에<br/>\n",
        "빠르게 좋은 결과를 얻을 수 있다는 장점이 있습니다."
      ],
      "metadata": {
        "id": "qJUXF_GhZonI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 이미지 분류를 위한 주요 사전 학습 모델(Pre-trained Model)"
      ],
      "metadata": {
        "id": "DjmfDav-sLLK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음으로는 이미지 분류에서 사용되는 주요 사전 학습 모델인 **VGG, Inception, ResNet** 에 대해 알아보도록 하겠습니다.\n",
        "\n",
        "> ❗️ ***모델의 구조를 모두 외울 필요는 없습니다. 각 모델의 이름 정도만 알고 넘어가도 충분합니다.***"
      ],
      "metadata": {
        "id": "mlTm66WtbKI5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **VGG**"
      ],
      "metadata": {
        "id": "Y2xbXvK9sQ1X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG는 2014년 ILSVRC 에서 우승을 거둔 모델입니다.<br/>\n",
        "층의 개수에 따라 VGG13, VGG16, VGG19 가 있는데요.<br/>\n",
        "모든 VGG는 아래와 같은 3가지 특징을 가지고 있습니다.\n",
        "\n",
        "1. 모든 합성곱 층에서 **3×3 크기의 필터 사용**<br/>\n",
        "    - 대신 층을 깊게 쌓음으로써 기존 7×7, 11×11 크기의 필터 이상의 표현력을 가질 수 있도록 함\n",
        "2. 활성화 함수로 **ReLU를 사용**하고 가중치 초깃값으로는 **He 초기화**을 사용<br/>\n",
        "    - 층을 깊게 쌓았음에도 기울기 소실(Gradient vanishing)문제기 빌셍하지 않음\n",
        "3. 마지막으로 완전 연결 층에 드롭아웃(Dropout)을 사용하여 과적합 방지 및 옵티마이저는 아담(Adam)  사용\n",
        "\n",
        "VGG16의 모델 구조는 아래와 같습니다."
      ],
      "metadata": {
        "id": "AbjSMd8p2CNc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://i.imgur.com/2egGDNg.png\" height=\"300\"/>"
      ],
      "metadata": {
        "id": "xIW8vYF1fymb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **GoogLeNet(Inception)**"
      ],
      "metadata": {
        "id": "RYsuGOpKojF6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GoogleNet은 2015년 ILSVRC 에서 우승을 거둔 모델입니다.<br/>\n",
        "GoogLeNet 역시 기본적인 합성곱 신경망이 결합된 형태를 띠고 있는데요.<br/>\n",
        "하지만 세로 방향의 깊이 뿐만 아니라 **가로 방향으로도 넓은 신경망 층**을 가지고 있다는 것이 특징입니다.\n",
        "\n",
        "GoogLeNet의 구조는 아래와 같습니다.\n"
      ],
      "metadata": {
        "id": "pm7eIZmt2DOS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://i.imgur.com/zt5ND1y.png\" height=\"300\"/>\n"
      ],
      "metadata": {
        "id": "WYjE1ioxgK6t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이렇게 가로 방향으로 층을 넓게 구성한 것을 **인셉션(Inception)** 구조라고 하는데요.<br/>\n",
        "위와 같은 인셉션 구조를 활용하여 크기가 다른 필터와 풀링을 병렬적으로 적용한 뒤 결과를 조합합니다."
      ],
      "metadata": {
        "id": "eJaibJAMhr0W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **ResNet**"
      ],
      "metadata": {
        "id": "G9EChig7omfE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet은 2016년 ILSVRC 에서 우승을 거둔 모델입니다.<br/>\n",
        "먼저 ResNet의 구조를 나타낸 이미지를 살펴보겠습니다."
      ],
      "metadata": {
        "id": "GfZ4nGbQiX-2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://i.imgur.com/DWcwuKl.png\" height=\"400\"/>\n",
        "\n"
      ],
      "metadata": {
        "id": "UCT2mOKNoPs5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  위 이미지에서 층을 넘어 이어지는 화살표를 볼 수 있는데요.<br/>\n",
        "  이 화살표는 ResNet의 특징인 **Residual Connection(=Skipped Connection)** 입니다.<br/>\n",
        "  Residual Connection를 이미지로 나타내면 아래와 같은데요."
      ],
      "metadata": {
        "id": "x3o0S0PjsT9X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://i.imgur.com/xdNL4LC.jpg\" height=\"300\"/>"
      ],
      "metadata": {
        "id": "Pk8Q_4axyZ0n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "층을 거친 데이터의 출력에 거치지 않은 출력을 더해주게 됩니다.<br/>\n",
        "이 방법을 사용하면 역전파 과정에서 미분을 적용하더라도 1 이상의 값으로 보존되기 때문에<br/>\n",
        "층이 깊어짐에 따라 발생하는 기울기 소실(Vanishing Gradient) 문제를 어느정도 해결할 수 있습니다.\n",
        "\n",
        "다음은 이러한 사전 학습 모델을 Keras 코드를 통해 어떻게 적용할 수 있을지에 대해 알아보겠습니다."
      ],
      "metadata": {
        "id": "QEFjHExUyeUE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Example"
      ],
      "metadata": {
        "id": "XxrarPeTxg_2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "일반적인 이미지를 10개의 클래스로 분류하는 데이터셋인 **Cifar10 데이터셋**을 VGG를 통해 분류하는 예제를 풀어보도록 하겠습니다. "
      ],
      "metadata": {
        "id": "HlLsIVB1tNhH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **먼저 필요한 패키지와 라이브러리를 불러옵니다.**"
      ],
      "metadata": {
        "id": "n-XFSj4DtoVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "pvsxOyPuz9sD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **시드(Seed)를 고정합니다.**"
      ],
      "metadata": {
        "id": "gb8GyrNZtqyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "Su3Kxz-j1SdE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **데이터셋을 불러온 후 학습 데이터셋(Train Dataset)과 시험 데이터셋(Test Dataset)으로 나누어(Split)주고 픽셀값을 정규화 하여줍니다.**"
      ],
      "metadata": {
        "id": "hIX277tVttyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "id": "PV-gE1jF1fFc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d128ea7f-7fbc-4d71-d55b-4b5b84bd28a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 3s 0us/step\n",
            "170508288/170498071 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype('float32') / 255.\n",
        "X_test = X_test.astype('float32') / 255."
      ],
      "metadata": {
        "id": "BwpD7xhu2BOq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=.2)"
      ],
      "metadata": {
        "id": "ufUGQnqq2OnA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **사전 학습 모델을 불러옵니다.**"
      ],
      "metadata": {
        "id": "ROvPKZcltxei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model = VGG16(weights='imagenet', include_top=False)"
      ],
      "metadata": {
        "id": "TRj-27RJ0Lh9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53dcbbc0-c8cb-41b0-f0ba-41e3e1781835"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. **사전 학습 모델 위에 완전 연결 신경망을 추가합니다.**\n",
        "\n",
        "    아래에 추가된 **`GlobalAveragePooling2d()`** 층은<br/>\n",
        "    데이터 Shape을 **`(None, None, None, 512)`**에서 **`(None, 512)`**로 변화시켜주는 역할을 합니다."
      ],
      "metadata": {
        "id": "Ikt9_l4tt3Fv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(pretrained_model)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dense(10,activation='softmax'))"
      ],
      "metadata": {
        "id": "8tCaq8JI0T5h"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEuLadvP38ad",
        "outputId": "416664ca-742b-4959-9c19-5d8de839c3d0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, None, None, 512)   14714688  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 512)              0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,781,642\n",
            "Trainable params: 14,781,642\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "7pC6Za0c3_Gn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train,\n",
        "          batch_size=128,\n",
        "          validation_data=(X_val, y_val),\n",
        "          epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlDI_OGK4I8h",
        "outputId": "fe8222f2-89ef-4171-ac5e-4ec2a7f144f7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "313/313 [==============================] - 21s 37ms/step - loss: 1.9015 - accuracy: 0.2437 - val_loss: 1.7320 - val_accuracy: 0.3358\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 11s 34ms/step - loss: 1.3883 - accuracy: 0.4595 - val_loss: 1.2017 - val_accuracy: 0.5701\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 1.0569 - accuracy: 0.6228 - val_loss: 1.0006 - val_accuracy: 0.6500\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 11s 34ms/step - loss: 0.8371 - accuracy: 0.7121 - val_loss: 0.8358 - val_accuracy: 0.7161\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 11s 34ms/step - loss: 0.6857 - accuracy: 0.7698 - val_loss: 0.7123 - val_accuracy: 0.7632\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.5634 - accuracy: 0.8104 - val_loss: 0.7133 - val_accuracy: 0.7672\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 11s 35ms/step - loss: 0.4743 - accuracy: 0.8412 - val_loss: 0.7318 - val_accuracy: 0.7712\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 11s 34ms/step - loss: 0.4118 - accuracy: 0.8641 - val_loss: 0.7039 - val_accuracy: 0.7838\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 11s 34ms/step - loss: 0.3364 - accuracy: 0.8895 - val_loss: 0.6829 - val_accuracy: 0.7962\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 11s 34ms/step - loss: 0.2966 - accuracy: 0.9012 - val_loss: 0.7183 - val_accuracy: 0.7900\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fba10203e90>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. **학습한 신경망 모델을 사용하여 평가합니다.**"
      ],
      "metadata": {
        "id": "F5FpsKxzw5Z_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ga3CxGi_4SRt",
        "outputId": "04ee95ad-845b-457c-d7a8-40bacf0c5a54"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 2s - loss: 0.7755 - accuracy: 0.7828 - 2s/epoch - 7ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7754948139190674, 0.782800018787384]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 이미지 증강(Image Augmentation)"
      ],
      "metadata": {
        "id": "tNM8WlYhscY-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "기본적인 **이미지 증강(Image Augmentation)** 방법에 대해서 알아보겠습니다.<br/>\n",
        "이미지 증강이란 회전, 반전, 자르기, 밝기 혹은 채도 변화 등을 통해 데이터를 늘리는 방법인데요.\n",
        "\n",
        "아마 여러분들은 대부분 아래 사진에 있는 동물이 무엇인지 판단하실 수 있을 겁니다."
      ],
      "metadata": {
        "id": "9HWFMQh-qYKy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://i.imgur.com/7nP1Kv2.jpg\" height=\"300\"/>\n",
        "<img src=\"https://i.imgur.com/VQIdbd3.jpg\" height=\"300\"/>\n"
      ],
      "metadata": {
        "id": "-KEgCqSo7DOt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "하지만 우리가 가지고 있는 데이터셋은 대부분 정면의 고양이 사진을 가지고 학습하게 되는데요.<br/>\n",
        "그렇기 때문에 우리의 모델은 위와 같이 판단해야 하는 물체가 기울어져 있거나 뒤집어진 이미지에서는 잘 예측하지 못한다는 취약점을 가지고 있습니다.\n",
        "\n",
        "사람처럼 **일반화(Generalization)**가 잘 되는 모델을 만들기 위해서 학습 데이터셋에 있는 이미지를 일부러 회전하거나 기울여서 나타내는데요.<br/>\n",
        "이러한 방법을 **<font color=\"ff6f61\">이미지 데이터 증강(Image Data Augmentation)</font>** 이라고 합니다. \n",
        "\n",
        "이미지 증강을 사용하면 이미지를 랜덤하게 회전하거나, 늘리고 줄이거나, 확대하거나, 좌우 반전한 이미지 등을 훈련 데이터셋으로 사용할 수 있습니다.<br/>\n",
        "이를 통해 더욱 **강건(Robust)**한 모델을 만들 수 있습니다.\n",
        "\n",
        "> ❗️ ***이미지 증강을 위한 코드가 궁금하다면 Reference 자료를 통해 알아보도록 합시다***"
      ],
      "metadata": {
        "id": "fTcWMNMjHX4s"
      }
    }
  ]
}