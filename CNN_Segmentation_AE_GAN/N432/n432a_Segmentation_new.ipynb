{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ttogle918/ds-section4-sprint3/blob/master/N432/n432a_Segmentation_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d21da178",
      "metadata": {
        "id": "d21da178"
      },
      "source": [
        "<img align=\"right\" src=\"https://ds-cs-images.s3.ap-northeast-2.amazonaws.com/Codestates_Fulllogo_Color.png\" width=100>\n",
        "\n",
        "## *DATA SCIENCE / SECTION 4 / SPRINT 3 / NOTE 2*\n",
        "\n",
        "---\n",
        "\n",
        "# N432. Image Segmentation & Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e0f7f70",
      "metadata": {
        "id": "0e0f7f70"
      },
      "source": [
        "## 문제1.\n",
        "Lecture Note에 구성되어 있는 U-Net모델에서 baseline 모델을 MobilenetV2가 아닌 Vgg16을 사용하겠습니다.\n",
        "\n",
        "또한, 업샘플러 부분을 pix2pix가 아닌 직접,Conv2DTranspose를 사용해 구현해보겠습니다.\n",
        "\n",
        "U-Net을 구성하기 위해서는 vgg16 모델에서 다운샘플링할 때 꺼내온 5개의 레이어와 업샘플링할 때 레이어의 결과값의 형태가 같아야 합니다.\n",
        "\n",
        "U-Net을 구성하기 위해 알맞은 A, B, C, D를 입력하세요.\n",
        "- [100, 100, 100, 100] 형태로 입력하세요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5167c770",
      "metadata": {
        "id": "5167c770"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9787de00",
      "metadata": {
        "id": "9787de00"
      },
      "outputs": [],
      "source": [
        "img_shape = (128, 128, 3)\n",
        "base_model = tf.keras.applications.VGG16(input_shape=img_shape, include_top=False)\n",
        "down_stack=tf.keras.Model(inputs=[base_model.input],\n",
        "                       outputs=[\n",
        "                                base_model.get_layer(name='block5_conv3').output,\n",
        "                                base_model.get_layer(name='block4_conv3').output,\n",
        "                                base_model.get_layer(name='block3_conv3').output,\n",
        "                                base_model.get_layer(name='block2_conv2').output,\n",
        "                                base_model.get_layer(name='block1_conv2').output\n",
        "])\n",
        "\n",
        "down_stack.trainable = False\n",
        "\n",
        "i=tf.keras.Input(shape=img_shape)\n",
        "\n",
        "out, out1, out2, out3, out4 = down_stack(i)\n",
        "\n",
        "A = 512\n",
        "B = 256\n",
        "C = 128\n",
        "D = 64\n",
        "\n",
        "out = tf.keras.layers.Conv2DTranspose(A, 3,strides=2,padding='same')(out)\n",
        "out = tf.keras.layers.Add()([out,out1])\n",
        "\n",
        "out = tf.keras.layers.Conv2DTranspose(B, 3,strides=2,padding='same')(out)\n",
        "out = tf.keras.layers.Add()([out,out2])\n",
        "\n",
        "out = tf.keras.layers.Conv2DTranspose(C, 3,strides=2,padding='same')(out)\n",
        "out = tf.keras.layers.Add()([out,out3])\n",
        "\n",
        "out = tf.keras.layers.Conv2DTranspose(D, 3,strides=2,padding='same')(out)\n",
        "out = tf.keras.layers.Add()([out,out4])\n",
        "\n",
        "out = tf.keras.layers.Conv2D(3, 3, activation='elu', padding='same') (out)\n",
        "out = tf.keras.layers.Dense(3,activation='softmax')(out)\n",
        "\n",
        "unet_model = tf.keras.Model(inputs=[i], outputs=[out])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9eaf2658",
      "metadata": {
        "id": "9eaf2658"
      },
      "source": [
        "## 문제2.\n",
        "이미지 증강을 수행하는 함수 data_augmentation을 정의하겠습니다\n",
        "\n",
        "해당 이미지 증강 함수는 다음과 같은 처리를 합니다.\n",
        "1. 랜덤 좌우 반전\n",
        "2. 랜덤 밝기 변화\n",
        "3. 랜덤 채도 변화"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c28920a3",
      "metadata": {
        "id": "c28920a3"
      },
      "source": [
        "1, 2, 3에 해당하는 내용을 적어주세요.\n",
        "- adjust_saturation, rgb_to_grayscale, central_crop 같이 적어주세요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "247ff08b",
      "metadata": {
        "id": "247ff08b"
      },
      "outputs": [],
      "source": [
        "def data_augmentation(image, label):\n",
        "\n",
        "    image = tf.image.flip_left_right(image)\n",
        "    image = tf.image.adjust_brightness(image, max_delta=0.3) \n",
        "    image = tf.image.rgb_to_grayscale(image)\n",
        "\n",
        "    image = tf.cast(image, tf.float32) / 255.\n",
        "\n",
        "    return image, label"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "n432a_Segmentation_new.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}