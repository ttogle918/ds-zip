{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Skn9ZDVioced"
   },
   "source": [
    "<img src='https://user-images.githubusercontent.com/6457691/90080969-0f758d00-dd47-11ea-8191-fa12fd2054a7.png' width = '200' align = 'right'>\n",
    "\n",
    "## *DATA SCIENCE / SECTION 4 / SPRINT 2 / Assignment 3*\n",
    "\n",
    "--- \n",
    "\n",
    "# Language Modeling with RNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m4TPAYK_iMTP"
   },
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPZul2xafYbg"
   },
   "source": [
    "다음 링크는 LSTM을 사용하여 Spam 메시지 분류를 수행한 캐글 노트북입니다. => [Link](https://www.kaggle.com/kredy10/simple-lstm-for-text-classification) <br/>\n",
    "\n",
    "위 노트북에서 사용한 코드를 참고하여<br/>\n",
    "캐글 데이터셋인 [Women's E-Commerce Clothing Reviews](https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews) 를 분류해 보세요.\n",
    "\n",
    "- 분류에 사용될 텍스트 데이터 : **`Review Text`** 열을 사용합니다.\n",
    "- 레이블(label) 데이터 : **`Recommended IND`** 열을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Bz3tWeejexjS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import EarlyStopping\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yUA6-p7qSI-i"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "file = files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o5ai82pA0PNF"
   },
   "source": [
    "### 1) 데이터 전처리\n",
    "    \n",
    "- 데이터셋을 데이터프레임으로 읽어옵니다.\n",
    "- 필요없는 열(column)을 삭제합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "XtaZvHZ21Q6h"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jn-HVoj34duo"
   },
   "outputs": [],
   "source": [
    "### 이곳에서 과제를 수행해 주세요 ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_vTYLN_0XGO"
   },
   "source": [
    "### 2) 텍스트 분류를 수행해주세요.\n",
    "\n",
    "- 데이터셋 split시 test_size의 비율은 20%로, `random_state = 42` 로 설정합니다. \n",
    "- Tokenizer의 `num_words=3000` 으로 설정합니다.\n",
    "- pad_sequence의 `maxlen=400` 으로 설정합니다.\n",
    "- 학습 시, 파라미터는 `batch_size=128, epochs=10, validation_split=0.2` 로 설정합니다.\n",
    "- EarlyStopping을 적용합니다. 파라미터는 `monitor='val_loss',min_delta=0.0001, patience=3` 로 설정합니다.\n",
    "- evaluate 했을 때의 loss와 accuarcy를 [loss, acc] 형태로 입력해주세요. Ex) [0.4321, 0.8765]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dzuZGPoB4eoc"
   },
   "outputs": [],
   "source": [
    "### 이곳에서 과제를 수행해 주세요 ###"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "vdnZ6GKoknDr"
   ],
   "name": "N423a_Language Modeling with RNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
