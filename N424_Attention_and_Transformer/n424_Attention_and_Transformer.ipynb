{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "n424_Attention_and_Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "d9ixL-TF_uWx",
        "y_Sn-XoHANda",
        "j6lc3U9wBSrg",
        "XZo2_s-Z2Vi2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9ixL-TF_uWx"
      },
      "source": [
        "<img align=\"right\" src=\"https://ds-cs-images.s3.ap-northeast-2.amazonaws.com/Codestates_Fulllogo_Color.png\" width=100>\n",
        "\n",
        "## ***DATA SCIENCE / SECTION 4 / SPRINT 2 / NOTE 4***\n",
        "\n",
        "---\n",
        "\n",
        "# Attention, Transformer & Others"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_Sn-XoHANda"
      },
      "source": [
        "## Warm Up\n",
        "\n",
        "ì§€ë‚œ ì‹œê°„ì— ë°°ì› ë˜ ë‚´ìš©ì„ ë– ì˜¬ë ¤ë´…ì‹œë‹¤.\n",
        "\n",
        "- RNN, LSTM, GRU\n",
        "\n",
        "    - RNN ê¸°ë°˜ ëª¨ë¸ì˜ ì¥ì ì— ëŒ€í•´ì„œ ìƒê°í•´ë´…ì‹œë‹¤.\n",
        "    - RNN ê¸°ë°˜ ëª¨ë¸ì˜ ë‹¨ì ì— ëŒ€í•´ì„œ ìƒê°í•´ë´…ì‹œë‹¤. (2ê°€ì§€ ì´ìƒ)\n",
        "        - LSTMê³¼ GRUëŠ” ì–´ë–¤ ë‹¨ì ì„ ì–´ë–»ê²Œ ê·¹ë³µí•˜ì˜€ëŠ”ì§€ ë‹¤ì‹œ ì•Œì•„ë´…ì‹œë‹¤.\n",
        "\n",
        "- ì´ë²ˆ ì‹œê°„ì—ëŠ” Attentionê³¼ Transformerì— ëŒ€í•´ì„œ ë°°ìš¸ ì˜ˆì •ì…ë‹ˆë‹¤.\n",
        "    - [Attentionì´ ê²°í•©ëœ Seq2Seq ëª¨ë¸](https://youtu.be/WsQLdu2JMgI) ì†Œê°œ ì˜ìƒ\n",
        "        - Attention : ì£¼ì˜, ì§‘ì¤‘\n",
        "        - ë²ˆì—­í•  ë•Œ ì–´ë–¤ ë‹¨ì–´ì— ì£¼ì˜, ì§‘ì¤‘ í•´ì•¼í•  ì§€ë¥¼ ì•Œë ¤ì£¼ëŠ” ê²ƒì´ Attention\n",
        "    - [Transformer](https://www.youtube.com/watch?v=mxGCEWOxfe8) ì†Œê°œ ì˜ìƒ\n",
        "        - RNNê³¼ëŠ” ì™„ì „íˆ ë‹¤ë¥¸ ëª¨ë¸\n",
        "        - ***Attention is All You Need : í•„ìš”í•œ ê±´ Attention ë¿***\n",
        "    - [GPT](https://www.youtube.com/watch?v=FeEmmylAF0o) ì†Œê°œ ì˜ìƒ\n",
        "        - ì‚¬ì „ í•™ìŠµ ì–¸ì–´ ëª¨ë¸\n",
        "        - GPTì˜ êµ¬ì¡°\n",
        "    - [BERT](https://youtu.be/vo3cyr_8eDQ?t=712) ì†Œê°œ ì˜ìƒ (11:52 ë¶€í„°)\n",
        "        - BERTì˜ êµ¬ì¡°\n",
        "        - MLM(Masked Self-Attention)\n",
        "        - NSP(Next Sentence Prediction)\n",
        "\n",
        "- ìì—°ì–´ ì²˜ë¦¬ì˜ ë‹¤ì–‘í•œ íƒœìŠ¤í¬ì— ëŒ€í•´ì„œ ì•Œì•„ë´…ì‹œë‹¤. ë‹¤ìŒ í‚¤ì›Œë“œ ì¤‘ ê´€ì‹¬ìˆëŠ” ê²ƒì„ êµ¬ê¸€ë§í•˜ì—¬ ì•Œì•„ë´…ì‹œë‹¤. \n",
        "    - ìì—°ì–´ ì´í•´(Natural Language Understanding, NLU)\n",
        "        - ê°ì„± ë¶„ì„ ë° ë¬¸ì„œ ë¶„ë¥˜\n",
        "        - ìì—°ì–´ ì¶”ë¡ (Natural Language Inference, NLI)\n",
        "        - ê¸°ê³„ ë…í•´(Machine Reading Comprehension, MRC)\n",
        "    - ìì—°ì–´ ìƒì„±(Natural Language Generation, NLG)\n",
        "    - ê¸°ê³„ ë²ˆì—­(Machine Translation)\n",
        "    - TTS(Text to Speech), STT(Speech to Text)\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6lc3U9wBSrg"
      },
      "source": [
        "## ğŸ† í•™ìŠµ ëª©í‘œ\n",
        "\n",
        "- **Attention ë©”ì»¤ë‹ˆì¦˜ì„ ì´í•´í•˜ê³  ì–´ë–¤ ë¬¸ì œë¥¼ í•´ê²°í–ˆëŠ”ì§€ ì•Œ ìˆ˜ ìˆë‹¤.**\n",
        "    - Attention ë©”ì»¤ë‹ˆì¦˜ì´ ë¬´ì—‡ì´ë©° ê¸°ê³„ë²ˆì—­(Machine Translation) ì„±ëŠ¥ì„ ëŒì–´ì˜¬ë ¸ëŠ”ì§€ ì•Œ ìˆ˜ ìˆë‹¤.\n",
        "    - Attention ìœ¼ë¡œë„ í•´ê²°í•  ìˆ˜ ì—†ëŠ” RNN ê¸°ë°˜ ëª¨ë¸ì˜ ë‹¨ì ì— ëŒ€í•´ì„œ ì•Œ ìˆ˜ ìˆë‹¤.\n",
        "\n",
        "- **Transformerì˜ ì¥ì ê³¼ ì£¼ìš” í”„ë¡œì„¸ìŠ¤ì¸ Self-Attentionì— ëŒ€í•´ ì´í•´í•˜ê³  ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.** \n",
        "    - íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ ë°œí‘œí•œ ë…¼ë¬¸ ì œëª©ì€ ì™œ \"Attention is All You Need\"ì¸ì§€ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.\n",
        "    - Positional Encodingì„ ì ìš©í•˜ëŠ” ì´ìœ ì— ëŒ€í•´ì„œ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.\n",
        "    - Masked Self-Attentionê°€ íŠ¸ëœìŠ¤í¬ë¨¸ êµ¬ì¡° ì¤‘ ì–´ë””ì— ì ìš©ë˜ë©° ì–´ë–¤ ì—­í• ì„ í•˜ëŠ”ì§€ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤. \n",
        "    - ê¸°ì¡´ RNNê³¼ ë¹„êµí•˜ì—¬ Transformerê°€ ê°€ì§€ëŠ” ì¥ì ì— ëŒ€í•´ì„œ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.\n",
        "\n",
        "- **GPT, BERT ê·¸ë¦¬ê³  ë‹¤ë¥¸ ëª¨ë¸ì— ëŒ€í•´ì„œ ê°œëµì ìœ¼ë¡œ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.**\n",
        "    - GPT(Generative Pre-Training)\n",
        "        - ì‚¬ì „ í•™ìŠµëœ ì–¸ì–´ ëª¨ë¸(Pre-trained LM)ì˜ Pre-trainingê³¼ Fine-tuningì€ ë¬´ì—‡ì´ê³  ê°ê° ì–´ë–¤ ì¢…ë¥˜ì˜ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ëŠ” ì§€ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.\n",
        "        - GPTëŠ” Transformerë¥¼ ì–´ë–»ê²Œ ë³€í˜•í•˜ì˜€ëŠ”ì§€ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.\n",
        "    - BERT(Bidirectional Encoder Representation by Transformer)\n",
        "        - BERTëŠ” Transformerë¥¼ ì–´ë–»ê²Œ ë³€í˜•í•˜ì˜€ìœ¼ë©° GPTì™€ì˜ ì°¨ì´ ë¬´ì—‡ì¸ì§€ ì•Œ ìˆ˜ ìˆë‹¤.\n",
        "        - MLM(Masked Language Model)ì€ ë¬´ì—‡ì¸ì§€ ì´í•´í•  ìˆ˜ ìˆë‹¤.\n",
        "        - NSP(Next Sentence Prediction)ì€ ë¬´ì—‡ì¸ì§€ ì´í•´í•  ìˆ˜ ìˆë‹¤.\n",
        "    - ìµœê·¼ ì–¸ì–´ ëª¨ë¸ì˜ ë°œì „ì€ ì–´ë–»ê²Œ ì§„í–‰ë˜ê³  ìˆëŠ”ì§€ ì•Œ ìˆ˜ ìˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01tsYPjM_yH-"
      },
      "source": [
        "## RNN with Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COGueQEOGZdv"
      },
      "source": [
        "RNNì´ ê°€ì§„ ê°€ì¥ í° ë‹¨ì  ì¤‘ í•˜ë‚˜ëŠ” **ì¥ê¸° ì˜ì¡´ì„±(Long-term dependency)** ë¬¸ì œì…ë‹ˆë‹¤.<br/>ì¥ê¸° ì˜ì¡´ì„± ë¬¸ì œë€ ë¬¸ì¥ì´ ê¸¸ì–´ì§ˆ ê²½ìš° ì• ë‹¨ì–´ì˜ ì •ë³´ë¥¼ ìƒì–´ë²„ë¦¬ê²Œ ë˜ëŠ” í˜„ìƒì…ë‹ˆë‹¤.<br/>ì¥ê¸° ì˜ì¡´ì„± ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë‚˜ì˜¨ ê²ƒì´ ì…€ êµ¬ì¡°ë¥¼ ê°œì„ í•œ LSTMê³¼ GRUì…ë‹ˆë‹¤.<br/>ê¸°ê³„ ë²ˆì—­ì—ì„œ RNN ê¸°ë°˜ì˜ ëª¨ë¸(LSTM, GRU)ì´ ë‹¨ì–´ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°©ë²•ì€ ì•„ë˜ì™€ ê°™ë‹¤ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8mTUUb7BJV2"
      },
      "source": [
        "<img src=\"https://user-images.githubusercontent.com/45377884/86040995-f27b4800-ba7f-11ea-8ca1-67b2517573eb.gif\" alt=\"seq2seq_6\" width=\"800\" />\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cubjTVyGxuuh"
      },
      "source": [
        "í•˜ì§€ë§Œ LSTM, GRUë¡œ ê°œì„ í•˜ì˜€ë”ë¼ë„ ë¬¸ì¥ì´ ê¸¸ì–´ì§€ë©´ ëª¨ë“  ë‹¨ì–´ ì •ë³´ë¥¼ ê³ ì • ê¸¸ì´ì˜ Hidden state ë²¡í„°ì— ë‹´ê¸° ì–´ë µë‹¤ëŠ” ë‹¨ì ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.<br/>\n",
        "ë§ì€ ë‹¨ì–´ì˜ ì˜ë¯¸ë¥¼ ë²¡í„° í•˜ë‚˜ì— ë‹´ê¸°ì—” ë¶€ì¡±í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.<br/>\n",
        "ì´ëŸ° ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„œ ê³ ì•ˆëœ ë°©ë²•ì´ ë°”ë¡œ **Attention** ì…ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hx5ZqJaYgoWe"
      },
      "source": [
        "<img src=\"https://user-images.githubusercontent.com/45377884/86040873-b942d800-ba7f-11ea-9f59-ee23923f777e.gif\" alt=\"seq2seq_7\" width=\"800\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1SEDqkfYmU8"
      },
      "source": [
        "Attentionì€ ê° ì¸ì½”ë”ì˜ Time-step ë§ˆë‹¤ ìƒì„±ë˜ëŠ” Hidden state ë²¡í„°ë¥¼ ê°„ì§í•©ë‹ˆë‹¤.<br/>\n",
        "ì…ë ¥ ë‹¨ì–´ê°€ Nê°œë¼ë©´ ê·¸ë§Œí¼ì˜ Hidden state ë²¡í„°ë¥¼ ëª¨ë‘ ê°„ì§í•˜ê²Œ ë©ë‹ˆë‹¤.<br/>\n",
        "ëª¨ë“  ë‹¨ì–´ê°€ ì…ë ¥ë˜ë©´ ìƒì„±ëœ Hidden state ë²¡í„°ë¥¼ ëª¨ë‘ ë””ì½”ë”ì— ë„˜ê²¨ì¤ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1Furq4hDZPG"
      },
      "source": [
        "ë””ì½”ë”ì—ì„œëŠ” ë‹¨ì–´ë¥¼ ìƒì„±í•  ë•Œë§ˆë‹¤ ì¸ì½”ë”ì—ì„œ ë„˜ì–´ì˜¨ ëª¨ë“  Hidden state ë²¡í„°ì™€ ì–¼ë§ˆë‚˜ ê´€ë ¨ì´ ìˆëŠ”ì§€ ê°€ì¤‘ì¹˜ë¥¼ êµ¬í•©ë‹ˆë‹¤.<br/>ì´ ë•Œ ë””ì½”ë”ì˜ Hidden state ë²¡í„°ì™€ ì¸ì½”ë”ì˜ ê° Hidden state ë²¡í„°ë¥¼ ë‚´ì í•˜ì—¬ ê°€ì¤‘ì¹˜ë¥¼ êµ¬í•˜ê²Œ ë©ë‹ˆë‹¤.<br/>ì•„ë˜ëŠ” ë””ì½”ë” ì²« ë‹¨ì–´ \"I\"(`Time-step 4`)ì— ëŒ€í•œ ì–´í…ì…˜ ê°€ì¤‘ì¹˜ê°€ êµ¬í•´ì§€ëŠ” ê³¼ì •ì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmGvkTW7M1eE"
      },
      "source": [
        "<img src=\"https://user-images.githubusercontent.com/45377884/86044868-ae8b4180-ba85-11ea-9fee-2977edfd47ce.gif\" alt=\"seq2seq_img\" width=\"800\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1Iz1neANg5L"
      },
      "source": [
        "ë””ì½”ë”ëŠ” ì¸ì½”ë”ì—ì„œ ë„˜ì–´ì˜¨ ëª¨ë“  Hidden state ë²¡í„°ì— ëŒ€í•´ ìœ„ì™€ ê°™ì€ ê³„ì‚°ì„ ì‹¤ì‹œí•©ë‹ˆë‹¤.<br/>\n",
        "ê·¸ë ‡ê¸° ë•Œë¬¸ì— Time-stepë§ˆë‹¤ ì¶œë ¥í•  ë‹¨ì–´(Target word)ê°€ ì–´ë–¤ Hidden state ë²¡í„°ì™€ ì—°ê´€ì´ ìˆëŠ” ì§€, ì¦‰ ì–´ë–¤ ë‹¨ì–´ì— **ì§‘ì¤‘(Attention)**í•  ì§€ë¥¼ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.<br/>ì´ëŸ° ê³¼ì •ì„ ê±°ì³ ë‹¨ì–´ë¥¼ ìƒì„±í•˜ë©´ ì¸ì½”ë”ì— ì…ë ¥ë˜ëŠ” ëª¨ë“  ë‹¨ì–´ì˜ ì •ë³´ë¥¼ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.<br/>ì¦‰, ì¥ê¸° ì˜ì¡´ì„± ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.<br/>ì˜ˆì‹œë¡œ ì œì‹œë˜ì—ˆë˜ ë¬¸ì¥(`Je suis etudiant => I am a student`)ì„ ë²ˆì—­í–ˆì„ ë•Œ ê° ë‹¨ì–´ë§ˆë‹¤ì˜ Attention ìŠ¤ì½”ì–´ë¥¼ ì‹œê°í™”í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZ5o7VwCOpQg"
      },
      "source": [
        "<img src=\"https://user-images.githubusercontent.com/45377884/86047018-29a22700-ba89-11ea-98ee-a90b2fb70a23.gif\" alt=\"attn_visualization\" width=\"500\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXn15KKCffXx"
      },
      "source": [
        "Attentionì„ êµ¬í˜„í•œ ì½”ë“œë¥¼ ì‹¤í–‰í•´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "- **ëª¨ë“ˆ ì„í¬íŠ¸ / í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-gJBkcrfcM7"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67Sm3kyRfuyu",
        "outputId": "1d7665e1-ded3-45d3-f229-af5acff765fc"
      },
      "source": [
        "# Download the file\n",
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "    extract=True)\n",
        "\n",
        "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "2646016/2638744 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roj-oDN9fz3D"
      },
      "source": [
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "                 if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "  w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "  w = re.sub(r\"([?.!,Â¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,Â¿]+\", \" \", w)\n",
        "\n",
        "  w = w.strip()\n",
        "\n",
        "  # adding a start and an end token to the sentence\n",
        "  # so that the model know when to start and stop predicting.\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ljYaCtQf4VT",
        "outputId": "a159c514-fb32-46cb-ff6c-c928e62b25ef"
      },
      "source": [
        "en_sentence = u\"May I borrow this book?\"\n",
        "sp_sentence = u\"Â¿Puedo tomar prestado este libro?\"\n",
        "print(preprocess_sentence(en_sentence))\n",
        "print(preprocess_sentence(sp_sentence).encode('utf-8'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> may i borrow this book ? <end>\n",
            "b'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra76W5Hkf7QP"
      },
      "source": [
        "# 1. Remove the accents\n",
        "# 2. Clean the sentences\n",
        "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
        "def create_dataset(path, num_examples):\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "  word_pairs = [[preprocess_sentence(w) for w in line.split('\\t')]\n",
        "                for line in lines[:num_examples]]\n",
        "\n",
        "  return zip(*word_pairs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZLq0gWxf9_R",
        "outputId": "70d6fe22-cbdb-48e4-e982-09ff062e316d"
      },
      "source": [
        "en, sp = create_dataset(path_to_file, None)\n",
        "print(en[-1])\n",
        "print(sp[-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
            "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rwo7oj6WgAY5"
      },
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqPktihKgCqs"
      },
      "source": [
        "def load_dataset(path, num_examples=None):\n",
        "  # creating cleaned input, output pairs\n",
        "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xJxnsOviQ7Y"
      },
      "source": [
        "# Try experimenting with the size of that dataset\n",
        "num_examples = 30000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
        "\n",
        "# Calculate max_length of the target tensors\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJzfJMD2iRm7",
        "outputId": "a4897624-9bf2-4978-d4f8-7cbd000f8e00"
      },
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24000 24000 6000 6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNcJ5CiHgo7M"
      },
      "source": [
        "- **ì„¤ì •í•˜ê¸°**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gyhFLuRg0VP"
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ngvIQ5xg2WP",
        "outputId": "510c044f-99e0-47ac-fcd5-7ea2c66f305a"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 16]), TensorShape([64, 11]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoFkIUrQhEjZ"
      },
      "source": [
        "- **ì¸ì½”ë” êµ¬í˜„**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrVGkNVYhDkG"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state=hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0p3wzwMhNbb",
        "outputId": "05824a4b-8e3c-4275-8a92-d41356ca8336"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print('Encoder output shape: (batch size, sequence length, units)', sample_output.shape)\n",
        "print('Encoder Hidden state shape: (batch size, units)', sample_hidden.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 16, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoB8eAG_hPls"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yej3jZPdhSCL",
        "outputId": "7cb9b8ca-5815-41cf-9fed-a71daa0e2413"
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units)\", attention_result.shape)\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1)\", attention_weights.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 16, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gui7f8kVhYhC"
      },
      "source": [
        "- **ë””ì½”ë” êµ¬í˜„**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V_tdtO2hT1b"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Lkg44lphcGZ",
        "outputId": "3ad33517-e0e5-4f00-f1d7-2c6e4fa2c8e8"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print('Decoder output shape: (batch_size, vocab size)', sample_decoder_output.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 4935)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGEjBTgDheMw"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
        "                                                            reduction='none')\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUhuss6ChgiY"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MRQ6Ulhh0VW",
        "outputId": "a04a676a-548a-4963-d3ee-582f70e462b5"
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "      \n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 4.7960\n",
            "Epoch 1 Batch 100 Loss 2.2292\n",
            "Epoch 1 Batch 200 Loss 1.9146\n",
            "Epoch 1 Batch 300 Loss 1.6447\n",
            "Epoch 1 Loss 2.0216\n",
            "Time taken for 1 epoch 45.51616978645325 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.4850\n",
            "Epoch 2 Batch 100 Loss 1.4446\n",
            "Epoch 2 Batch 200 Loss 1.3863\n",
            "Epoch 2 Batch 300 Loss 1.2924\n",
            "Epoch 2 Loss 1.3546\n",
            "Time taken for 1 epoch 34.42869186401367 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.0562\n",
            "Epoch 3 Batch 100 Loss 0.9927\n",
            "Epoch 3 Batch 200 Loss 0.8976\n",
            "Epoch 3 Batch 300 Loss 0.8325\n",
            "Epoch 3 Loss 0.9220\n",
            "Time taken for 1 epoch 34.383094787597656 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.7657\n",
            "Epoch 4 Batch 100 Loss 0.7361\n",
            "Epoch 4 Batch 200 Loss 0.6516\n",
            "Epoch 4 Batch 300 Loss 0.5745\n",
            "Epoch 4 Loss 0.6181\n",
            "Time taken for 1 epoch 34.198145627975464 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.4225\n",
            "Epoch 5 Batch 100 Loss 0.5018\n",
            "Epoch 5 Batch 200 Loss 0.4357\n",
            "Epoch 5 Batch 300 Loss 0.4594\n",
            "Epoch 5 Loss 0.4176\n",
            "Time taken for 1 epoch 34.26620602607727 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.3250\n",
            "Epoch 6 Batch 100 Loss 0.2546\n",
            "Epoch 6 Batch 200 Loss 0.3414\n",
            "Epoch 6 Batch 300 Loss 0.3458\n",
            "Epoch 6 Loss 0.2867\n",
            "Time taken for 1 epoch 34.169394969940186 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.2158\n",
            "Epoch 7 Batch 100 Loss 0.1921\n",
            "Epoch 7 Batch 200 Loss 0.1899\n",
            "Epoch 7 Batch 300 Loss 0.1386\n",
            "Epoch 7 Loss 0.2041\n",
            "Time taken for 1 epoch 34.23347210884094 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.1367\n",
            "Epoch 8 Batch 100 Loss 0.1689\n",
            "Epoch 8 Batch 200 Loss 0.1746\n",
            "Epoch 8 Batch 300 Loss 0.2270\n",
            "Epoch 8 Loss 0.1526\n",
            "Time taken for 1 epoch 34.12479901313782 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.1603\n",
            "Epoch 9 Batch 100 Loss 0.1013\n",
            "Epoch 9 Batch 200 Loss 0.1304\n",
            "Epoch 9 Batch 300 Loss 0.1260\n",
            "Epoch 9 Loss 0.1181\n",
            "Time taken for 1 epoch 34.020458698272705 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0900\n",
            "Epoch 10 Batch 100 Loss 0.0797\n",
            "Epoch 10 Batch 200 Loss 0.0944\n",
            "Epoch 10 Batch 300 Loss 0.1101\n",
            "Epoch 10 Loss 0.0954\n",
            "Time taken for 1 epoch 33.88239026069641 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7aJioMoiYx1"
      },
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L9MXJY9iZhv"
      },
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLJ37OOOib_L"
      },
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "id": "93IpAAFMi9Yb",
        "outputId": "695a756c-59b8-4151-a1b1-88007b66e39e"
      },
      "source": [
        "translate(u'hace mucho frio aqui.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> hace mucho frio aqui . <end>\n",
            "Predicted translation: it s very cold here . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "id": "_uQW40H-jAYu",
        "outputId": "53a5ec39-05de-458f-af7d-c75f9c31d6b5"
      },
      "source": [
        "translate(u'esta es mi vida.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> esta es mi vida . <end>\n",
            "Predicted translation: this is my life . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9y9W20irk9mO"
      },
      "source": [
        "-----------------------------\n",
        "------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpSQ4utmO71g"
      },
      "source": [
        "## Transformer : Attention is All You Need"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_Nkvve_FFIG"
      },
      "source": [
        "<img src=\"https://fastly.syfy.com/sites/syfy/files/styles/2280x1280_hero/public/2020/01/transformers-last-knight.jpg?offset-x=0&offset-y=0\" alt=\"transformer_electric\" width=\"400\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKH7yo-AO3Ph"
      },
      "source": [
        "íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ê¸°ê³„ ë²ˆì—­ì„ ìœ„í•œ ìƒˆë¡œìš´ ëª¨ë¸ë¡œ ì´ì „ì— ë“±ì¥í–ˆë˜ Attention ë©”ì»¤ë‹ˆì¦˜ì„ ê·¹ëŒ€í™”í•˜ì—¬ ë›°ì–´ë‚œ ë²ˆì—­ ì„±ëŠ¥ì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.<br/>ìµœê·¼ ìì—°ì–´ì²˜ë¦¬ ëª¨ë¸ SOTA(State-of-the-Art)ì˜ ê¸°ë³¸ ì•„ì´ë””ì–´ëŠ” ëª¨ë‘ íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ê³  ìˆìŠµë‹ˆë‹¤.<br/>ëª¨ë¸ì„ ì†Œê°œí•œ ë…¼ë¬¸ [Attention is All You Need](https://arxiv.org/abs/1706.03762) ëŠ” 3ë…„ ì‚¬ì´ì— 18000ë²ˆ ì´ìƒ ì¸ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.<br/> íŠ¸ëœìŠ¤í¬ë¨¸ê°€ ìì—°ì–´ì²˜ë¦¬ê°€ ì•„ë‹Œ ë‹¤ë¥¸ ë¬¸ì œë„ ì˜ í’€ê³ ìˆê¸° ë•Œë¬¸ì— ìµœê·¼ì—ëŠ” ì»´í“¨í„° ë¹„ì „ ìª½ì—ì„œë„ ì ìš©í•˜ë ¤ëŠ” ì‹œë„ê°€ ìˆìœ¼ë©°, ë©€í‹°ëª¨ë‹¬(Multi-Modal) ëª¨ë¸ì—ë„ ì ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤.<br/>\n",
        "\n",
        "Attentionì„ ì ìš©í•˜ì˜€ë“  ê·¸ë ‡ì§€ ì•Šë“ , RNN ê¸°ë°˜ ëª¨ë¸ì´ ê°€ì§„ íŠ¹ì§•ì€ ë‹¨ì–´ê°€ **ìˆœì„œëŒ€ë¡œ** ë“¤ì–´ì˜¨ë‹¤ëŠ” ì ì…ë‹ˆë‹¤.<br/>ì²˜ë¦¬í•´ì•¼ í•˜ëŠ” ì‹œí€€ìŠ¤ê°€ ê¸¸ìˆ˜ë¡ **ì—°ì‚° ì†ë„ê°€ ëŠë ¤**ì§‘ë‹ˆë‹¤. **íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ì´ëŸ° ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë“±ì¥í•œ ëª¨ë¸**ì…ë‹ˆë‹¤.<br/>ëª¨ë“  í† í°ì„ ë™ì‹œì— ì…ë ¥ë°›ì•„ ë³‘ë ¬ ì—°ì‚°í•˜ê¸° ë•Œë¬¸ì— ë‹¨ì–´ê°€ ì…ë ¥ë˜ê¸°ë¥¼ ê¸°ë‹¤ë¦¬ì§€ ì•Šì•„ë„ ëœë‹¤ëŠ” ì¥ì ì´ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì•„ë˜ëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ì˜ êµ¬ì¡°ë¥¼ ë‹¨ìˆœí•˜ê²Œ ì‹œê°í™”í•œ ê·¸ë¦¼ì…ë‹ˆë‹¤.<br/>ì¸ì½”ë” ë¸”ë¡ê³¼ ë””ì½”ë” ë¸”ë¡ì´ 6ê°œì”© ëª¨ì—¬ìˆìŠµë‹ˆë‹¤.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEjnrUq-Zq9X"
      },
      "source": [
        "<img src=\"http://jalammar.github.io/images/t/The_transformer_encoder_decoder_stack.png\" alt=\"positional_encoding\" width=\"700\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNUm_DCUO_Yn"
      },
      "source": [
        "ê·¸ë¦¼ í•˜ë‚˜ë¥¼ ë” ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ì•„ë˜ëŠ” ë…¼ë¬¸ì´ ì œì‹œí•œ íŠ¸ëœìŠ¤í¬ë¨¸ì˜ êµ¬ì¡°ì…ë‹ˆë‹¤.<br/>ê·¸ë¦¼ì„ ë³´ë©´ ì»¤ë‹¤ë€ íšŒìƒ‰ ë¸”ë¡ì´ 2ê°œ ìˆìŠµë‹ˆë‹¤.<br/>ì™¼ìª½ì€ ì¸ì½”ë” ë¸”ë¡ í•˜ë‚˜ë¥¼ ë‚˜íƒ€ë‚´ê³  ì˜¤ë¥¸ìª½ì€ ë””ì½”ë” ë¸”ë¡ í•˜ë‚˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.<br/>ì¸ì½”ë” ë¸”ë¡ì€ í¬ê²Œ 2ê°œì˜ sub-layer **[`Multihead (Self) Attention`, `Feed Forward`]** ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆìŠµë‹ˆë‹¤.<br/>ë””ì½”ë” ë¸”ë¡ì€ 3ê°œì˜ sub-layer **[`Masked Multihead (Self) Attention`, `Multihead (Encoder-Decoder) Attention` `Feed Forward`]** ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yf5KKTsuPENw"
      },
      "source": [
        "<img src=\"https://miro.medium.com/max/1400/1*BHzGVskWGS_3jEcYYi6miQ.png\" alt=\"positional_encoding\" width=\"550\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntqpucgWuOKh"
      },
      "source": [
        "### Positional Encoding (ìœ„ì¹˜ ì¸ì½”ë”©)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jO2N2G4pPiA3"
      },
      "source": [
        "<img width=\"400\" alt=\"pe\" src=\"https://user-images.githubusercontent.com/45377884/112799904-ecb3a100-90a9-11eb-9072-87a965e81a77.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fw_uLipBPnMG"
      },
      "source": [
        "íŠ¸ëœìŠ¤í¬ë¨¸ì—ì„œëŠ” ëª¨ë“  ë‹¨ì–´ê°€ ë™ì‹œì— ì…ë ¥ë©ë‹ˆë‹¤.<br/>ê·¸ë˜ì„œ ë‹¨ì–´ì˜ ìœ„ì¹˜ ì •ë³´ë¥¼ ì œê³µí•˜ê¸° ìœ„í•œ ë²¡í„°ë¥¼ ë”°ë¡œ ì œê³µí•´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤.<br/>ë‹¨ì–´ì˜ ìƒëŒ€ì ì¸ ìœ„ì¹˜ ì •ë³´ë¥¼ ì œê³µí•˜ê¸° ìœ„í•œ ë²¡í„°ë¥¼ ë§Œë“œëŠ” ê³¼ì •ì„ `Positional Encoding` ì´ë¼ê³  í•©ë‹ˆë‹¤.<br/>`Positional Encoding`ì€ ì•„ë˜ì™€ ê°™ì€ ìˆ˜ì‹ìœ¼ë¡œ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤. ìˆ˜ì‹ì´ ë³µì¡í•˜ë‹ˆ ì¼ë‹¨ì€ ì‹ì„ ì´í•´í•˜ë ¤ê³  í•˜ì§€ ì•Šìœ¼ì…”ë„ ë©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQLVS_0zPpdA"
      },
      "source": [
        "$$\n",
        "\\begin{aligned}\n",
        "\\text{PE}_{\\text{pos},2i} &= \\sin \\bigg(\\frac{\\text{pos}}{10000^{2i/d_{\\text{model}}}}\\bigg) \\\\\n",
        "\\text{PE}_{\\text{pos},2i+1} &= \\cos \\bigg(\\frac{\\text{pos}}{10000^{2i/d_{\\text{model}}}}\\bigg)\n",
        "\\end{aligned}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqVM-W4y3cCG"
      },
      "source": [
        "ì•„ë˜ `Positional Encoding`ì„ ì‹œê°í™”í•œ ìë£Œë¡œë¶€í„° ì¼ì •í•œ íŒ¨í„´ì´ ìˆëŠ” ë²¡í„°ì„ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.<br/>ì´ë¥¼ í†µí•´ ë‹¨ì–´ì˜ ìƒëŒ€ì ì¸ ìœ„ì¹˜ë¥¼ íŒŒì•… `Positional Encoding`ì´ ìˆëŠ” ì´ìœ ë¥¼ ì´í•´í•˜ëŠ” ê²ƒì— ì§‘ì¤‘í•˜ë„ë¡ í•©ì‹œë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZXLdjSfPva1"
      },
      "source": [
        "<img src=\"http://jalammar.github.io/images/t/transformer_positional_encoding_large_example.png\" alt=\"positional_encoding\" width=\"500\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yD70CNguVAC"
      },
      "source": [
        "### Self-Attention\n",
        "***(N434ì—ì„œ ì´ê²ƒë§Œì´ë¼ë„ ì œëŒ€ë¡œ ì•Œê³  ë„˜ì–´ê°‘ì‹œë‹¤)***\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gEVfOCmPycD"
      },
      "source": [
        "<img width=\"300\" alt=\"self-Attn\" src=\"https://user-images.githubusercontent.com/45377884/112809266-ca735080-90b4-11eb-9a25-7f34f37880c7.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2AxXXfPP0wH"
      },
      "source": [
        "**Self-Attention** ì€ íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ì£¼ìš” ë©”ì»¤ë‹ˆì¦˜ì…ë‹ˆë‹¤.\n",
        "\n",
        "> *The animal didn't cross the street because <ins>it</ins> was too tired* \n",
        "\n",
        "ìœ„ì™€ ê°™ì€ ë¬¸ì¥ì„ ì œëŒ€ë¡œ ë²ˆì—­í•˜ë ¤ë©´ **_\"it\"_** ê³¼ ê°™ì€ ì§€ì‹œëŒ€ëª…ì‚¬ê°€ ì–´ë–¤ ëŒ€ìƒì„ ê°€ë¦¬í‚¤ëŠ”ì§€ ì•Œì•„ì•¼ í•©ë‹ˆë‹¤.<br/>ë²ˆì—­í•˜ë ¤ëŠ” ë¬¸ì¥ ë‚´ë¶€ ìš”ì†Œì˜ ê´€ê³„ë¥¼ ì˜ íŒŒì•…í•˜ê¸° ìœ„í•´ì„œ ë¬¸ì¥ ìì‹ ì— ëŒ€í•´ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì„ ì ìš©í•©ë‹ˆë‹¤.<br/>ì´ë¥¼ `Self-Attention`ì´ë¼ê³  í•©ë‹ˆë‹¤.<br/>ì•„ë˜ëŠ” **_\"it\"_** ì´ ì–´ë–¤ ë‹¨ì–´ì™€ ê°€ì¥ ì—°ê´€ë˜ì–´ ìˆëŠ” ì§€ë¥¼ ì‹œê°í™”í•œ ê·¸ë¦¼ì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvAsFAWJP2xz"
      },
      "source": [
        "<img src=\"http://jalammar.github.io/images/t/transformer_self-attention_visualization.png\" alt=\"self_attention_visualization\" width=\"350\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FG-Z6J9qwpyL"
      },
      "source": [
        "\n",
        "**`Self-Attention`**ì€ ì–´ë–¤ ê³¼ì •ì´ê¸¸ë˜ ë‹¨ì–´ ì‚¬ì´ì˜ ê´€ê³„ë¥¼ ì•Œì•„ë‚¼ ìˆ˜ ìˆì„ê¹Œìš”?<br/>ë¹„ë°€ì€ **3ê°€ì§€ ê°€ì¤‘ì¹˜ ë²¡í„°**ì— ìˆìŠµë‹ˆë‹¤.<br/>ê° ë²¡í„°ëŠ” **ì¿¼ë¦¬(Query), í‚¤(Key), ë°¸ë¥˜(Value)**ë¼ê³  ë¶€ë¦…ë‹ˆë‹¤.<br/>RNNì˜ Hidden state ë²¡í„°ë¥¼ ëŒ€ì²´í•˜ê¸° ìœ„í•œ ê°€ì¤‘ì¹˜ ë²¡í„°ë¼ê³  ìƒê°í•˜ì‹œë©´ ë©ë‹ˆë‹¤.<br/> ê°ê°ì˜ ë²¡í„°ê°€ ì–´ë–¤ ì—­í• ì„ í•˜ëŠ”ì§€ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "- **ì¿¼ë¦¬(q)**ëŠ” ë¶„ì„í•˜ê³ ì í•˜ëŠ” ë‹¨ì–´ì— ëŒ€í•œ ê°€ì¤‘ì¹˜ ë²¡í„°ì…ë‹ˆë‹¤.\n",
        "\n",
        "- **í‚¤(k)**ëŠ” ê° ë‹¨ì–´ê°€ í•´ë‹¹ ì¿¼ë¦¬ì™€ ì–¼ë§ˆë‚˜ ì—°ê´€ìˆëŠ” ì§€ë¥¼ ë¹„êµí•˜ê¸° ìœ„í•œ ê°€ì¤‘ì¹˜ ë²¡í„°ì…ë‹ˆë‹¤. \n",
        "\n",
        "- **ë°¸ë¥˜(v)**ëŠ” ê° ë‹¨ì–´ì˜ ì˜ë¯¸ë¥¼ ì‚´ë ¤ì£¼ê¸° ìœ„í•œ ê°€ì¤‘ì¹˜ ë²¡í„°ì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrXC04GQy4Yb"
      },
      "source": [
        "**`Self-Attention`**ì€ ì„¸ ê°€ì§€ ê°€ì¤‘ì¹˜ ë²¡í„°ë¥¼ ëŒ€ìƒìœ¼ë¡œ ì–´í…ì…˜ì„ ì ìš©í•©ë‹ˆë‹¤.\n",
        "\n",
        "1. ë¨¼ì €, **ì¿¼ë¦¬(q)ì™€ ëª¨ë“  ë‹¨ì–´ì˜ í‚¤(k) ë²¡í„°ë¥¼ ë‚´ì **í•©ë‹ˆë‹¤. ë‚´ì ì„ í†µí•´ ë‚˜ì˜¤ëŠ” ê°’ì´ Attention ìŠ¤ì½”ì–´(Score)ê°€ ë©ë‹ˆë‹¤.\n",
        "\n",
        "2. íŠ¸ëœìŠ¤í¬ë¨¸ì—ì„œëŠ” ì´ ê°€ì¤‘ì¹˜ë¥¼ q,k,v ë²¡í„° ì°¨ì› $d_k$ ì˜ ì œê³±ê·¼ $\\sqrt{d_k}$ ë¡œ ë‚˜ëˆ„ì–´ì¤ë‹ˆë‹¤. ê³„ì‚°ê°’ì„ ì•ˆì •ì ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ê¸° ìœ„í•œ ê³„ì‚° ë³´ì •ìœ¼ë¡œ ìƒê°í•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.  \n",
        "\n",
        "3. ë‹¤ìŒìœ¼ë¡œ **Softmax**ë¥¼ ì·¨í•´ì£¼ë©´ ì¿¼ë¦¬ì— í•´ë‹¹í•˜ëŠ” ë‹¨ì–´ì™€ ë¬¸ì¥ ë‚´ ë‹¤ë¥¸ ë‹¨ì–´ê°€ ê°€ì§€ëŠ” ê´€ê³„ì˜ ë¹„ìœ¨ì„ êµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "4. ë§ˆì§€ë§‰ìœ¼ë¡œ **ë°¸ë¥˜(v) ê° ë‹¨ì–´ì˜ ë²¡í„°ë¥¼ ê³±í•´ì¤€ í›„ ëª¨ë‘ ë”í•˜ë©´** Self-Attention ê³¼ì •ì´ ë§ˆë¬´ë¦¬ë©ë‹ˆë‹¤. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XUQi85yy7kR"
      },
      "source": [
        "**`Self-Attention`** ì˜ ê³¼ì •ì„ ê·¸ë¦¼ìœ¼ë¡œ ë‹¤ì‹œ ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTREy_tA1tAc"
      },
      "source": [
        "**1. ê°€ì¤‘ì¹˜ í–‰ë ¬ $W^Q, W^K, W^V$ ë¡œë¶€í„° ê° ë‹¨ì–´ì˜ ì¿¼ë¦¬, í‚¤, ë°¸ë¥˜(q, k, v) ë²¡í„°ë¥¼ ë§Œë“¤ì–´ëƒ…ë‹ˆë‹¤.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBOvyUgjRE6C"
      },
      "source": [
        "<img src=\"http://jalammar.github.io/images/xlnet/self-attention-1.png\" alt=\"transformer_15\" width=\"600\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH4SjvhPQB0h"
      },
      "source": [
        "**2. ë¶„ì„í•˜ê³ ì í•˜ëŠ” ë‹¨ì–´ì˜ ì¿¼ë¦¬ ë²¡í„°(q)ì™€ ë¬¸ì¥ ë‚´ ëª¨ë“  ë‹¨ì–´(ìì‹  í¬í•¨)ì˜ í‚¤ ë²¡í„°(k)ë¥¼ ë‚´ì í•˜ì—¬ ê° ë‹¨ì–´ì™€ ì–¼ë§ˆë‚˜ ê´€ë ¨ ì •ë„ë¥¼ êµ¬í•©ë‹ˆë‹¤.**\n",
        "\n",
        "(ì•„ë˜ ê·¸ë¦¼ì—ì„œëŠ” $\\sqrt{d_k}$ë¡œ ë‚˜ëˆ„ì–´ ì¤€ ë’¤ì— Softmaxë¥¼ ì·¨í•´ì£¼ëŠ” ê³¼ì •ì€ ìƒëµë˜ì—ˆìŠµë‹ˆë‹¤.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKrYd1eWRIH7"
      },
      "source": [
        "<img src=\"http://jalammar.github.io/images/xlnet/self-attention-2.png\" alt=\"transformer_15\" width=\"600\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZ_HnY9vQD4o"
      },
      "source": [
        "**3.  Softmaxì˜ ì¶œë ¥ê°’ê³¼ë°¸ë¥˜ ë²¡í„°(v)ë¥¼ ê³±í•´ì¤€ ë’¤ ë”í•˜ë©´ í•´ë‹¹ ë‹¨ì–´ì— ëŒ€í•œ Self-Attention ì¶œë ¥ê°’ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKbpOuTVRKf0"
      },
      "source": [
        "<img src=\"http://jalammar.github.io/images/xlnet/self-attention-3.png\" alt=\"transformer_15\" width=\"600\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iMflDTbQFV4"
      },
      "source": [
        "**4. í•˜ë‚˜ì˜ ë²¡í„°ì— ëŒ€í•´ì„œë§Œ ì‚´í´ë³´ì•˜ì§€ë§Œ ì‹¤ì œ Attention ê³„ì‚°ì€ í–‰ë ¬ ë‹¨ìœ„ë¡œ ë³‘ë ¬ ê³„ì‚°ë©ë‹ˆë‹¤.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMO4BdoQRM7P"
      },
      "source": [
        "<img src=\"http://jalammar.github.io/images/xlnet/self-attention-summary.png\" alt=\"transformer_15\" width=\"600\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lj6LqffDxYZu"
      },
      "source": [
        "ì‹¤ì œë¡œ ê° ë²¡í„°ëŠ” **í–‰ë ¬(Q, K, V)**ë¡œ í•œêº¼ë²ˆì— ê³„ì‚°ë©ë‹ˆë‹¤. $W^Q, W^K, W^V$ ëŠ” í•™ìŠµ ê³¼ì •ì—ì„œ ê°±ì‹ ë˜ëŠ” íŒŒë¼ë¯¸í„°ë¡œ ì´ë£¨ì–´ì§„ í–‰ë ¬ì…ë‹ˆë‹¤. ì„¸ í–‰ë ¬ê³¼ ë‹¨ì–´ í–‰ë ¬ì„ ë‚´ì í•˜ì—¬ ì¿¼ë¦¬, í‚¤, ë°¸ë¥˜ í–‰ë ¬(Q, K, V)ë¥¼ ë§Œë“¤ì–´ëƒ…ë‹ˆë‹¤.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "un25Mx6_RPem"
      },
      "source": [
        "<img src=\"http://jalammar.github.io/images/t/self-attention-matrix-calculation.png\" alt=\"transformer_12\" width=\"500\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0_CnhEVQI4h"
      },
      "source": [
        "ìœ„ì—ì„œ ì‚´í´ë³¸ ë°”ì™€ ê°™ì´\n",
        "\n",
        "1. ë¨¼ì € ì¿¼ë¦¬ í–‰ë ¬(Q)ê³¼ í‚¤ í–‰ë ¬(K)ì„ **ë‚´ì **í•©ë‹ˆë‹¤.\n",
        "\n",
        "2. ê²°ê³¼ë¡œ ë‚˜ì˜¤ëŠ” í–‰ë ¬ì˜ ìš”ì†Œë¥¼ $\\sqrt{d_k}$ ë¡œ **ë‚˜ëˆ„ì–´ ì¤ë‹ˆë‹¤.**\n",
        "\n",
        "3. í–‰ë ¬ì˜ ê° ìš”ì†Œì— `Softmax`ë¥¼ ì·¨í•´ì¤ë‹ˆë‹¤. \n",
        "\n",
        "4. ë§ˆì§€ë§‰ìœ¼ë¡œ **ë°¸ë¥˜ í–‰ë ¬(V)ê³¼ ë‚´ì **í•˜ë©´ ìµœì¢… ê²°ê³¼ í–‰ë ¬(Z)ì´ ë°˜í™˜ë©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uinyklXWyLrn"
      },
      "source": [
        "<img src=\"http://jalammar.github.io/images/t/self-attention-matrix-calculation-2.png\" alt=\"transformer_13\" width=\"700\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpxgcGIgj5PC"
      },
      "source": [
        "ì•„ë˜ëŠ” `Tensorflow` ì—ì„œ Self-Attentionì„ êµ¬í˜„í•œ ì½”ë“œì…ë‹ˆë‹¤. ì½”ë“œë¥¼ í†µí•´ Attentionì´ ê³„ì‚°ë˜ëŠ” ê³¼ì •ì„ ë‹¤ì‹œ ì‚´í´ë³´ë„ë¡ í•©ì‹œë‹¤. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFkqQMjHpIxI"
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  \"\"\"Calculate the attention weights.\n",
        "  q, k, v must have matching leading dimensions.\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "  The mask has different shapes depending on its type(padding or look ahead) \n",
        "  but it must be broadcastable for addition.\n",
        "  \n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable \n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "    \n",
        "  Returns:\n",
        "    output, attention_weights\n",
        "  \"\"\"\n",
        "\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "  \n",
        "  # scale matmul_qk\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  # add the mask to the scaled tensor.\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)  \n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "  # add up to 1.\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "  return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_RmjSVYluaO"
      },
      "source": [
        "### Multi-Head Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTRaQ5oVQ1gh"
      },
      "source": [
        "ë‹¤ìŒìœ¼ë¡œ **`Multi-Head Attention`** ì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.<br/>**`Multi-Head Attention`** ì´ë€ **`Self-Attention`** ì„ ë™ì‹œì— ì—¬ëŸ¬ ê°œë¡œ ì‹¤í–‰í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.<br/>ê° Head ë§ˆë‹¤ ë‹¤ë¥¸ Attention ê²°ê³¼ë¥¼ ë‚´ì–´ì£¼ê¸° ë•Œë¬¸ì— ì•™ìƒë¸”ê³¼ ìœ ì‚¬í•œ íš¨ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.<br/> ë…¼ë¬¸ì—ì„œëŠ” 8ê°œì˜ Headë¥¼ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.<br/>8ë²ˆì˜ Self-Attentionì„ ì‹¤í–‰í•˜ì—¬ ê°ê°ì˜ ì¶œë ¥ í–‰ë ¬ $Z_0, Z_1, \\cdots , Z_7$ ì„ ë§Œë“¤ì–´ëƒ…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rvzeSQkQ4SJ"
      },
      "source": [
        "<img src=\"http://jalammar.github.io/images/t/transformer_attention_heads_z.png\" alt=\"transformer_16\" width=\"500\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTcLefocQ7mC"
      },
      "source": [
        "ì¶œë ¥ëœ í–‰ë ¬ $Z_n (n=0,\\cdots,7)$ ì€ **ì´ì–´ë¶™ì—¬ì§‘ë‹ˆë‹¤(Concatenate)**.<br/>ë˜ ë‹¤ë¥¸ íŒŒë¼ë¯¸í„° í–‰ë ¬ì¸ $W^o$ ì™€ì˜ ë‚´ì ì„ í†µí•´ Multi-Head Attentionì˜ ìµœì¢… ê²°ê³¼ì¸ í–‰ë ¬ $Z$ë¥¼ ë§Œë“¤ì–´ëƒ…ë‹ˆë‹¤.<br/>ì—¬ê¸°ì„œ í–‰ë ¬ $W^o$ì˜ ìš”ì†Œ ì—­ì‹œ í•™ìŠµì„ í†µí•´ ê°±ì‹ ë©ë‹ˆë‹¤.<br/>ìµœì¢…ì ìœ¼ë¡œ ìƒì„±ëœ í–‰ë ¬ $Z$ëŠ” í† í° ë²¡í„°ë¡œ ì´ë£¨ì–´ì§„ í–‰ë ¬ $X$ì™€ **ë™ì¼í•œ í¬ê¸°(Shape)**ê°€ ë©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkS1oMy6Q-Pc"
      },
      "source": [
        "<img src=\"http://jalammar.github.io/images/t/transformer_attention_heads_weight_matrix_o.png\" alt=\"transformer_17\" width=\"500\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZo2_s-Z2Vi2"
      },
      "source": [
        "### Layer Normalization & Skip Connection\n",
        "\n",
        "<img width=\"300\" alt=\"lnorm_resicon\" src=\"https://user-images.githubusercontent.com/45377884/113169444-9056aa00-9280-11eb-8ba0-17c9211ad412.png\">\n",
        "\n",
        "íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ëª¨ë“  sub-layerì—ì„œ ì¶œë ¥ëœ ë²¡í„°ëŠ” **Layer normalization**ê³¼ **Skip connection**ì„ ê±°ì¹˜ê²Œ ë©ë‹ˆë‹¤.<br/>Layer normalizationì˜ íš¨ê³¼ëŠ” Batch normalizationê³¼ ìœ ì‚¬í•©ë‹ˆë‹¤. í•™ìŠµì´ í›¨ì”¬ ë¹ ë¥´ê³  ì˜ ë˜ë„ë¡ í•©ë‹ˆë‹¤.<br/>Skip connection(í˜¹ì€ Residual connection)ì€ ì—­ì „íŒŒ ê³¼ì •ì—ì„œ ì •ë³´ê°€ ì†Œì‹¤ë˜ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.<br/>Sprint3ì—ì„œ ë°°ìš¸ ResNetì˜ ì£¼ìš” ë©”ì»¤ë‹ˆì¦˜ì´ë¯€ë¡œ í•´ë‹¹ ë¶€ë¶„ì—ì„œ ë”ìš± ìì„¸í•˜ê²Œ ë‹¤ë£° ì˜ˆì •ì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQPefZjI2UTM"
      },
      "source": [
        "### Feed Forward Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHwk8VeqmNzU"
      },
      "source": [
        "<img width=\"300\" alt=\"á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-03-29 á„‹á…©á„’á…® 5 27 32\" src=\"https://user-images.githubusercontent.com/45377884/112808809-58027080-90b4-11eb-8ca7-ffa38e577d3d.png\">\n",
        "\n",
        "ë‹¤ìŒìœ¼ë¡œ **`FFNN(Feed forward neural network)`** ë¡œ ë“¤ì–´ê°‘ë‹ˆë‹¤.<br/>ì€ë‹‰ì¸µì˜ ì°¨ì›ì´ ëŠ˜ì–´ë‚¬ë‹¤ê°€ ë‹¤ì‹œ ì›ë˜ ì°¨ì›ìœ¼ë¡œ ì¤„ì–´ë“œëŠ” ë‹¨ìˆœí•œ 2ì¸µ ì‹ ê²½ë§ì…ë‹ˆë‹¤.<br/>í™œì„±í™” í•¨ìˆ˜(Activation function)ìœ¼ë¡œ ReLUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "\n",
        "$$\n",
        "\\text{FFNN}(x) = \\max(0, W_1x + b_1) W_2 +b_2\n",
        "$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzFup_5pDupE"
      },
      "source": [
        "### Masked Self-Attention\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_kn1-AYR18G"
      },
      "source": [
        "<img width=\"300\" alt=\"Masked_Self-Attention_in_structure\" src=\"https://user-images.githubusercontent.com/45377884/112808936-78322f80-90b4-11eb-9315-22cd9caad41d.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNdrsLrER3w2"
      },
      "source": [
        "**Masked Self-Attention**ì€ ë””ì½”ë” ë¸”ë¡ì—ì„œ ì‚¬ìš©ë˜ëŠ” íŠ¹ìˆ˜í•œ Self-Attentionì…ë‹ˆë‹¤.<br/> ë””ì½”ë”ëŠ” Auto Regressive í•˜ê²Œ ë‹¨ì–´ë¥¼ ìƒì„±í•˜ê¸° ë•Œë¬¸ì— íƒ€ê¹ƒ ë‹¨ì–´ ì´í›„ ë‹¨ì–´ë¥¼ ë³´ì§€ ì•Šê³  ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•´ì•¼ í•©ë‹ˆë‹¤.<br/>ë”°ë¼ì„œ íƒ€ê¹ƒ ë‹¨ì–´ ë’¤ì— ìœ„ì¹˜í•œ ë‹¨ì–´ëŠ” Self-Attentionì— ì˜í–¥ì„ ì£¼ì§€ ì•Šë„ë¡ **ë§ˆìŠ¤í‚¹(masking)**ì„ í•´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8-UwtUcR5WO"
      },
      "source": [
        "<img width=\"500\" alt=\"Masked_Self-Attention_ex\" src=\"http://jalammar.github.io/images/xlnet/transformer-decoder-block-self-attention-2.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33J9FxItR70W"
      },
      "source": [
        "***Self-Attention (without Masking) vs Masked Self-Attention***\n",
        "\n",
        "<img width=\"500\" alt=\"Masked_Self-Attention_ex2\" src=\"http://jalammar.github.io/images/gpt2/self-attention-and-masked-self-attention.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWJfqdxHSAY3"
      },
      "source": [
        "ì›ë˜ Self-Attention ë©”ì»¤ë‹ˆì¦˜ì€ ì¿¼ë¦¬ í–‰ë ¬(Q)ì™€ í‚¤ í–‰ë ¬(K)ì˜ ë‚´ì ìœ¼ë¡œ ë‚˜ì˜¨ í–‰ë ¬ì„ ì°¨ì›ì˜ ì œê³±ê·¼ $\\sqrt{d_k}$ ë¡œ ë‚˜ëˆ„ì–´ ì¤€ ë‹¤ìŒ Softmaxë¥¼ ì·¨í•´ì£¼ê³  ë°¸ë¥˜ í–‰ë ¬(V)ê³¼ ë‚´ì í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
        "\n",
        "**`Masked Self-Attention`** ì—ì„œëŠ” Softmaxë¥¼ ì·¨í•´ì£¼ê¸° ì „, ê°€ë ¤ì£¼ê³ ì í•˜ëŠ” ìš”ì†Œì—ë§Œ $-\\infty$ ì— í•´ë‹¹í•˜ëŠ” ë§¤ìš° ì‘ì€ ìˆ˜ë¥¼ ë”í•´ì¤ë‹ˆë‹¤.<br/>ì•„ë˜ ì˜ˆì‹œì—ì„œëŠ” -10ì–µ(=-1e9)ì„ ë”í•´ì£¼ì—ˆìŠµë‹ˆë‹¤.<br/>ì´ ê³¼ì •ì„ **ë§ˆìŠ¤í‚¹(Masking)**ì´ë¼ê³  í•©ë‹ˆë‹¤.<br/>ë§ˆìŠ¤í‚¹ëœ ê°’ì€ Softmaxë¥¼ ì·¨í•´ ì£¼ì—ˆì„ ë•Œ 0ì´ ë‚˜ì˜¤ë¯€ë¡œ Attention ë©”ì»¤ë‹ˆì¦˜ì— ë°˜ì˜ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbTQf8oxzth-"
      },
      "source": [
        "<img width=\"600\" alt=\"masked_1\" src=\"http://jalammar.github.io/images/gpt2/transformer-attention-mask.png\">\n",
        "\n",
        "<img width=\"600\" alt=\"masked_2\" src=\"http://jalammar.github.io/images/gpt2/transformer-attention-masked-scores-softmax.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98r-D1WjSH3w"
      },
      "source": [
        "ìœ„ì—ì„œ ë“±ì¥í–ˆë˜ Self-Attentionì„ êµ¬í˜„ ì½”ë“œì—ì„œ. `mask` ì™€ ê´€ë ¨ëœ ë¶€ë¶„ë§Œ ë‹¤ì‹œ ë³´ë„ë¡ í•©ì‹œë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03EldudrJgAD"
      },
      "source": [
        "# def scaled_dot_product_attention(q, k, v, mask):\n",
        "#   \"\"\"Calculate the attention weights.\n",
        "#   q, k, v must have matching leading dimensions.\n",
        "#   k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "#   The mask has different shapes depending on its type(padding or look ahead) \n",
        "#   but it must be broadcastable for addition.\n",
        "  \n",
        "#   Args:\n",
        "#     q: query shape == (..., seq_len_q, depth)\n",
        "#     k: key shape == (..., seq_len_k, depth)\n",
        "#     v: value shape == (..., seq_len_v, depth_v)\n",
        "#     mask: Float tensor with shape broadcastable \n",
        "#           to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "    \n",
        "#   Returns:\n",
        "#     output, attention_weights\n",
        "#   \"\"\"\n",
        "\n",
        "#   matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "  \n",
        "#   # scale matmul_qk\n",
        "#   dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "#   scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    \n",
        "  \"\"\"\n",
        "    maskê°€ ìˆì„ ê²½ìš° maskingëœ ìë¦¬ì—ëŠ” (-inf)ì— í•´ë‹¹í•˜ëŠ” ì ˆëŒ“ê°’ì´ í° ìŒìˆ˜ -1e9(=-10ì–µ)ì„ ë”í•´ì¤ë‹ˆë‹¤.\n",
        "    ê·¸ ê°’ì— softmaxë¥¼ ì·¨í•´ì£¼ë©´ ê±°ì˜ 0ì— ê°€ê¹Œìš´ ê°’ì´ ë‚˜ì˜µë‹ˆë‹¤. ê·¸ ë‹¤ìŒ value ê³„ì‚°ì‹œì— ë°˜ì˜ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
        "  \"\"\"\n",
        "    \n",
        "  # add the mask to the scaled tensor.\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)  \n",
        "\n",
        "\n",
        "#   # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "#   # add up to 1.\n",
        "#   attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "#   output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "#   return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OSVcyskH543"
      },
      "source": [
        "### Encoder-Decoder Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUGAg5ikSb_F"
      },
      "source": [
        "<img width=\"300\" alt=\"Encoder-Decoder_Attention\" src=\"https://user-images.githubusercontent.com/45377884/112809435-f8f12b80-90b4-11eb-96e1-3b0f7c530659.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wepMQd4oSdkE"
      },
      "source": [
        "ë””ì½”ë”ì—ì„œ Masked Self-Attention ì¸µì„ ì§€ë‚œ ë²¡í„°ëŠ” **Encoder-Decoder Attention** ì¸µìœ¼ë¡œ ë“¤ì–´ê°‘ë‹ˆë‹¤.<br/>ì¢‹ì€ ë²ˆì—­ì„ ìœ„í•´ì„œëŠ” ë²ˆì—­í•  ë¬¸ì¥ê³¼ ë²ˆì—­ëœ ë¬¸ì¥ ê°„ì˜ ê´€ê³„ ì—­ì‹œ ì¤‘ìš”í•©ë‹ˆë‹¤.<br/> ë²ˆì—­í•  ë¬¸ì¥ê³¼ ë²ˆì—­ë˜ëŠ” ë¬¸ì¥ì˜ ì •ë³´ ê´€ê³„ë¥¼ ì—®ì–´ì£¼ëŠ” ë¶€ë¶„ì´ ë°”ë¡œ ì´ ë¶€ë¶„ì…ë‹ˆë‹¤.\n",
        "\n",
        "ì´ ì¸µì—ì„œëŠ” **ë””ì½”ë” ë¸”ë¡ì˜** Masked Self-Attentionìœ¼ë¡œë¶€í„° ì¶œë ¥ëœ ë²¡í„°ë¥¼ **ì¿¼ë¦¬(Q)** ë²¡í„°ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.<br/>**í‚¤(K)ì™€ ë°¸ë¥˜(V)** ë²¡í„°ëŠ” ìµœìƒìœ„(=6ë²ˆì§¸) ì¸ì½”ë” ë¸”ë¡ì—ì„œ ì‚¬ìš©í–ˆë˜ ê°’ì„ ê·¸ëŒ€ë¡œ ê°€ì ¸ì™€ì„œ ì‚¬ìš©í•©ë‹ˆë‹¤.<br/>**`Encoder-Decoder Attention`** ì¸µì˜ ê³„ì‚° ê³¼ì •ì€ Self-Attention í–ˆë˜ ê²ƒê³¼ ë™ì¼í•©ë‹ˆë‹¤.\n",
        "\n",
        "ì•„ë˜ëŠ” **`Encoder-Decoder Attention`** ê°€ ì§„í–‰ë˜ëŠ” ìˆœì„œë¥¼ ë‚˜íƒ€ë‚¸ ì´ë¯¸ì§€ì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kawL4lmnSh0v"
      },
      "source": [
        "<img width=\"700\" alt=\"Encoder-Decoder_Attention_gif\" src=\"http://jalammar.github.io/images/t/transformer_decoding_1.gif\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOn_vpeyRyyT"
      },
      "source": [
        "### Linear & Softmax Layer\n",
        "\n",
        "ì´ì œ ëì…ë‹ˆë‹¤!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYcth4VySk4T"
      },
      "source": [
        "<img width=\"300\" alt=\"Linear_Softmax\" src=\"https://user-images.githubusercontent.com/45377884/112815762-994a4e80-90bb-11eb-9a57-a8be65c1a30b.png\">\n",
        "\n",
        "ë””ì½”ë”ì˜ ìµœìƒì¸µì„ í†µê³¼í•œ ë²¡í„°ë“¤ì€ Linear ì¸µì„ ì§€ë‚œ í›„ Softmaxë¥¼ í†µí•´ ì˜ˆì¸¡í•  ë‹¨ì–´ì˜ í™•ë¥ ì„ êµ¬í•˜ê²Œ ë©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBx1WzlmRwcM"
      },
      "source": [
        "### ì½”ë“œ ì‹¤ìŠµ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_-WgBYX5-4K"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX26HWbe6Cph",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "4237c92d-3aa5-4585-e448-e9fe1209b9ec"
      },
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-146109541dcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mTransformerBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mff_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTransformerBlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiHeadAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         self.ffn = keras.Sequential(\n",
            "\u001b[0;31mNameError\u001b[0m: name 'layers' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_VY_WXJ6FdH"
      },
      "source": [
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvOXtcK76JV8"
      },
      "source": [
        "vocab_size = 20000  # Only consider the top 20k words\n",
        "maxlen = 200  # Only consider the first 200 words of each movie review\n",
        "(x_train, y_train), (x_val, y_val) = keras.datasets.imdb.load_data(num_words=vocab_size)\n",
        "print(len(x_train), \"Training sequences\")\n",
        "print(len(x_val), \"Validation sequences\")\n",
        "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_val = keras.preprocessing.sequence.pad_sequences(x_val, maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_M438h6OPe"
      },
      "source": [
        "embed_dim = 32  # Embedding size for each token\n",
        "num_heads = 2  # Number of attention heads\n",
        "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
        "\n",
        "inputs = layers.Input(shape=(maxlen,))\n",
        "embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
        "x = embedding_layer(inputs)\n",
        "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "x = transformer_block(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = layers.Dense(20, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y38uKp96TQf"
      },
      "source": [
        "model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "history = model.fit(\n",
        "    x_train, y_train, batch_size=32, epochs=2, validation_data=(x_val, y_val)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZ9M6E4rk4xc"
      },
      "source": [
        "--------------------\n",
        "-------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb-St9gHFVQX"
      },
      "source": [
        "## GPT, BERT & Others\n",
        "\n",
        "ì´ë²ˆì— ë°°ìš¸ GPTì™€ BERTëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ êµ¬ì¡°ì˜ ì¼ë¶€ë¶„ì„ ë³€í˜•í•˜ì—¬ ë§Œë“¤ì–´ì§„ ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤. ë‘ ëª¨ë¸ì€ **ì‚¬ì „ í•™ìŠµëœ ì–¸ì–´ ëª¨ë¸(Pre-trained Language Model)** ì´ë¼ëŠ” ê³µí†µì ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì‚¬ì „ í•™ìŠµì´ë€ ëŒ€ëŸ‰ì˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¯¸ë¦¬ í•™ìŠµí•˜ëŠ” ê³¼ì •ì¸ë°ìš”. ì—¬ê¸°ì— í•„ìš”í•œ ë°ì´í„°ë¥¼ ì¶”ê°€ í•™ìŠµì‹œì¼œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ìµœì í™”í•©ë‹ˆë‹¤. ì´ëŸ° í•™ìŠµ ë°©ë²•ì„ ì „ì´ í•™ìŠµ(Transfer Learning)ì´ë¼ê³ ë„ í•©ë‹ˆë‹¤. ìµœê·¼ ë°œí‘œë˜ê³  ìˆëŠ” SOTA(ìµœê³  ì„±ëŠ¥) ì–¸ì–´ ëª¨ë¸ì€ ëª¨ë‘ ì „ì´ í•™ìŠµì„ ì‚¬ìš©í•œ ëª¨ë¸ì…ë‹ˆë‹¤. \n",
        "\n",
        "ì´ë²ˆ ì‹œê°„ì—ëŠ” ëŒ€í‘œì ì¸ ë‘ ê°€ì§€ ì‚¬ì „ í•™ìŠµëœ ì–¸ì–´ ëª¨ë¸, GPTì™€ BERTì— ëŒ€í•´ ê°œëµì ìœ¼ë¡œ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ì´ëŸ° ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ ìµœê·¼ ë°œí‘œë˜ëŠ” ëª¨ë¸ì˜ ê²½í–¥ì„±ì— ëŒ€í•´ì„œë„ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yz7HMOrtGwJD"
      },
      "source": [
        "### GPT (2018.6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aiUjhboTxmy"
      },
      "source": [
        "<img width=\"300\" alt=\"Linear_Softmax\" src=\"https://openai.com/content/images/2019/05/openai-cover.png\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZdn1m3mTy87"
      },
      "source": [
        "**GPT**ëŠ” **G**enerative **P**re-trained **T**ransformer ì˜ ì•½ìë¡œ 2018ë…„ 6ì›”ì— OpenAIë¥¼ í†µí•´ ë°œí‘œë˜ì—ˆìŠµë‹ˆë‹¤.<br/>ì—°ì´ì–´ ë°œí‘œí•œ GPT-2(2019.2), GPT-3(2020.6)ê°€ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ë©´ì„œ ì„¸ê°„ì˜ ì£¼ëª©ì„ ë°›ì•˜ìŠµë‹ˆë‹¤.<br/>ê¸°ì‚¬ë¥¼ ì²¨ë¶€í•´ë“œë¦¬ë‹ˆ ì˜ìƒì´ ëë‚˜ê³  ì¶”ê°€ì ìœ¼ë¡œ ì½ì–´ë³´ì‹œë©´ ì¢‹ê² ìŠµë‹ˆë‹¤. \n",
        "\n",
        "- ì‹¬í™”ë‚´ìš© : Generativeë€? (ë‹¹ì¥ì€ ì´í•´í•˜ì§€ ëª»í•˜ì…”ë„ ì¢‹ìŠµë‹ˆë‹¤) - [discriminative vs generative](https://ratsgo.github.io/generative%20model/2017/12/17/compare/)\n",
        "\n",
        "- GPT2 ê¸°ì‚¬\n",
        "    - [The AI that was too dangerous to release](https://blog.floydhub.com/gpt2/)\n",
        "    - [OpenAI, ê³µìœ í•˜ê¸°ì—ëŠ” ë„ˆë¬´ ìœ„í—˜í•œ â€˜í…ìŠ¤íŠ¸ ìƒì„± AIâ€™ì˜ ì§„ì‹¤](http://www.aitimes.com/news/articleView.html?idxno=121589)\n",
        "\n",
        "- GPT3 ê¸°ì‚¬\n",
        "    - [A GPT-3 bot posted comments on Reddit for a week and no one noticed](https://www.technologyreview.com/2020/10/08/1009845/a-gpt-3-bot-posted-comments-on-reddit-for-a-week-and-no-one-noticed/)\n",
        "    - [GPT3ê°€ ì“´ ë‰´ìŠ¤ê°€ ë­í‚¹ 1ìœ„, ì‚¬ëŒì„ ì´ê²¼ë‹¤](http://www.aitimes.com/news/articleView.html?idxno=131593)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqhHhR8r8NLF"
      },
      "source": [
        "GPT-1, GPT-2, GPT-3ê°€ ì „ë¶€ ë™ì¼í•˜ì§€ëŠ” ì•Šì§€ë§Œ ê¸°ë³¸ì ìœ¼ë¡œ ë™ì¼í•œ êµ¬ì¡°ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "GPTì˜ êµ¬ì¡°ë¥¼ ì•Œì•„ë³´ê¸° ì „ì— ê¸°ë³¸ì´ ë˜ëŠ” ì•„ì´ë””ì–´ì¸ **ì‚¬ì „ í•™ìŠµ(Pre-training)** ì´ë¼ëŠ” ì•„ì´ë””ì–´ì— ëŒ€í•´ì„œ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIvqSVD4wMnW"
      },
      "source": [
        "- **ì‚¬ì „ í•™ìŠµëœ ì–¸ì–´ ëª¨ë¸ (Pre-trained LM)**\n",
        "\n",
        "í˜¹ì‹œ ì•„ë˜ì™€ ê°™ì€ ì¼€ì´ìŠ¤ë¥¼ ë³¸ ì  ìˆìœ¼ì‹ ê°€ìš”?\n",
        "\n",
        "<img width=\"500\" alt=\"pre-train\" src=\"https://user-images.githubusercontent.com/45377884/112774307-3e413900-9074-11eb-94ab-f3bc000ff95e.png\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkf1OJv6U8Gq"
      },
      "source": [
        "ìˆ˜ëŠ¥ êµ­ì–´ ì‹œí—˜ì—ì„œ ì±…ì„ ë§ì´ ì½ì€ í•™ìƒì€ ì¡°ê¸ˆë§Œ ê³µë¶€í•´ë„ ìƒìœ„ê¶Œ ì„±ì ì„ ìœ ì§€í•˜ëŠ” ê²½ìš°ê°€ ì¢…ì¢… ìˆìŠµë‹ˆë‹¤.<br/> GPTì—ì„œ ì‚¬ìš©ëœ **ì‚¬ì „ í•™ìŠµ**ì´ë¼ëŠ” ì•„ì´ë””ì–´ë„ ìœ ì‚¬í•œ ìƒê°ì—ì„œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.<br/>ì•„ë˜ ê·¸ë¦¼ì„ ë³´ë©° ì‚¬ì „ í•™ìŠµ ì–¸ì–´ ëª¨ë¸ì— ëŒ€í•´ì„œ ì„¤ëª…ì„ ì´ì–´ë‚˜ê°€ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ue0QaxvK63RP"
      },
      "source": [
        "<img width=\"700\" alt=\"Pre-training\" src=\"https://user-images.githubusercontent.com/45377884/112943247-35cc2980-916c-11eb-99be-2fa7657507d2.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSoHE5F8U-d2"
      },
      "source": [
        "ì‚¬ì „ í•™ìŠµ ì–¸ì–´ ëª¨ë¸ì€ í¬ê²Œ 2ê°€ì§€ ê³¼ì •ì„ í†µí•´ ì™„ì„±ë©ë‹ˆë‹¤. ì²« ë²ˆì§¸ê°€ **ì‚¬ì „ í•™ìŠµ(Pre-training)**ì…ë‹ˆë‹¤. \n",
        "\n",
        "ì¡´ì¬í•˜ëŠ” ìì—°ì–´ ì¤‘ì—ëŠ” ì±…(Book corpus)ì´ë‚˜ ìœ„í‚¤í”¼ë””ì•„(Wiki corpus) ë“± ë ˆì´ë¸”ë§ ë˜ì§€ ì•Šì€ ë°ì´í„°ê°€ ë” ë§ìŠµë‹ˆë‹¤.<br/>ì—¬ëŸ¬ë¶„ì´ ì§€ê¸ˆ ì½ê³  ìˆëŠ” ê°•ì˜ ë…¸íŠ¸ ì—­ì‹œ ë ˆì´ë¸”ë§ ë˜ì§€ ì•Šì€ ìì—°ì–´ ë°ì´í„° ì…ë‹ˆë‹¤.<br/>\n",
        "ì±…ì„ ë§ì´ ì½ëŠ” ê²ƒì²˜ëŸ¼ ë ˆì´ë¸”ë§ ë˜ì§€ ì•Šì€ ë°ì´í„°ë¥¼ ëª¨ë¸ì´ í•™ìŠµí•˜ë„ë¡ í•˜ëŠ” ê³¼ì •ì„ **ì‚¬ì „ í•™ìŠµ** ì´ë¼ê³  í•©ë‹ˆë‹¤.\n",
        "\n",
        "ì‚¬ì „ í•™ìŠµì´ ëë‚œ ëª¨ë¸ì— ìš°ë¦¬ê°€ í•˜ê³ ìí•˜ëŠ” íƒœìŠ¤í¬ì— íŠ¹í™”ëœ(Task specific) ë°ì´í„°ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.<br/> ì´ë¥¼ **Fine-tuning** ì´ë¼ê³  í•©ë‹ˆë‹¤.<br/> Fine-tuningì—ì„œëŠ” í•™ìŠµì‹œ ë ˆì´ë¸”ë§ ëœ ë°ì´í„° [Ex) ê°ì„± ë¶„ì„, ìì—°ì–´ ì¶”ë¡ (NLI), ì§ˆì˜ ì‘ë‹µ(QA)] ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4zkV_8d6TbJ"
      },
      "source": [
        "- **ëª¨ë¸ êµ¬ì¡° (ê·¸ë¦¼ì€ 6ê°œì˜ ë””ì½”ë” ë¸”ë¡ì„ ì‚¬ìš©í•˜ì§€ë§Œ GPTëŠ” 12ê°œì˜ ë¸”ë¡ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.)**\n",
        "\n",
        "<img width=\"700\" alt=\"Pre-training\" src=\"http://jalammar.github.io/images/xlnet/transformer-decoder-intro.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1N5Jgrt9GNx"
      },
      "source": [
        "GPTì—ì„œëŠ” ì¸ì½”ë”ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ë””ì½”ë” ë¸”ë¡ë‚´ì— **2ê°œì˜ Sub-layer**ë§Œ ìˆìŠµë‹ˆë‹¤. íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ë””ì½”ë” ë¸”ë¡ì—ì„œëŠ” Masked Self-Attentionì„ ì§€ë‚˜ì„œ Encoder-Decoder Attention ì¸µìœ¼ë¡œ ë“¤ì–´ê°”ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ GPTëŠ” ì¸ì½”ë”ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ Encoder-Decoder Attentionì¸µì´ ë¹ ì§€ê²Œ ë©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqFHif7m8vR8"
      },
      "source": [
        "- **ì‚¬ì „ í•™ìŠµ(Pre-training)**\n",
        "\n",
        "ë ˆì´ë¸”ë§ ë˜ì§€ ì•Šì€ ëŒ€ëŸ‰ì˜ ë§ë­‰ì¹˜ $U = (u_1, \\cdots , u_n)$ ì— ëŒ€í•´ ë¡œê·¸ ìš°ë„ $L_1$ ì„ ìµœëŒ€í™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµë©ë‹ˆë‹¤. ë‹¤ìŒì— ì˜¬ ë‹¨ì–´ë¥¼ ê³„ì†í•´ì„œ ë§ì¶”ëŠ” ë°©ì‹ìœ¼ë¡œ í•™ìŠµí•©ë‹ˆë‹¤.\n",
        "\n",
        "$$\n",
        "L_1(U) = \\sum_i \\log P(u_i \\vert u_{i-k}, \\cdots, u_{i-1}; \\Theta)\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOjb7lmd96FT"
      },
      "source": [
        "- **Fine-tuning**\n",
        "\n",
        "ê¸°ì¡´ ëª¨ë¸ì—ì„œëŠ” íƒœìŠ¤í¬ì— ë§ì¶° ëª¨ë¸ êµ¬ì¡°ë¥¼ ë³€ê²½í•´ì£¼ê³  í•™ìŠµì„ ì§„í–‰ì‹œì¼°ìŠµë‹ˆë‹¤.\n",
        "\n",
        "í•˜ì§€ë§Œ GPTì™€ ê°™ì€ ì‚¬ì „ í•™ìŠµ ì–¸ì–´ ëª¨ë¸ì€ Fine-tuning ê³¼ì •ì—ì„œ ë°ì´í„°ì˜ ì…ë ¥ ë°©ì‹ë§Œì„ ë³€í˜•ì‹œí‚¤ê³  ëª¨ë¸ êµ¬ì¡°ëŠ” ì¼ì •í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_0mywdu-ydy"
      },
      "source": [
        "<img width=\"600\" alt=\"fine-tune_structure\" src=\"https://user-images.githubusercontent.com/45377884/112949500-408abc80-9174-11eb-8090-4f0be34db572.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KKJNSrp-0Uk"
      },
      "source": [
        "\n",
        "Fine-tuningì€ ë ˆì´ë¸”ë§ ëœ ë§ë­‰ì¹˜ $C = (x_1, \\cdots , x_m)$ ì— ëŒ€í•˜ì—¬ ë¡œê·¸ ìš°ë„ $L_2$ ë¥¼ ìµœëŒ€í™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµí•©ë‹ˆë‹¤.\n",
        "\n",
        "$$\n",
        "L_2(C) = \\sum_{(x,y)} \\log P(y \\vert x_1, \\cdots , x_m)\n",
        "$$\n",
        "\n",
        "Fine-tuningì—ì„œ í•™ìŠµí•˜ëŠ” ë°ì´í„°ì…‹ì´ í´ ë•ŒëŠ” ë³´ì¡° ëª©ì í•¨ìˆ˜ë¡œ $L_1$ ì„ ì¶”ê°€í•˜ì—¬ $L_3$ë¡œ í•™ìŠµí•˜ë©´ í•™ìŠµì´ ë” ì˜ ì§„í–‰ë©ë‹ˆë‹¤.\n",
        "\n",
        "$$\n",
        "L_3(C) = L_2(C) + \\lambda \\cdot L_1(C)\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8E47CeLkDkb-"
      },
      "source": [
        "- **ê²°ê³¼ & ê²°ë¡ **\n",
        "\n",
        "LSTM, GRUë¥¼ ì‚¬ìš©í•œ ê¸°ì¡´ ëª¨ë¸ë³´ë‹¤ ìì—°ì–´ ì¶”ë¡ (NLI), ì§ˆì˜ ì‘ë‹µ(QA), ë¶„ë¥˜(Classification) ë“±ì˜ íƒœìŠ¤í¬ì—ì„œ ë†’ì€ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ì˜€ìŠµë‹ˆë‹¤.<br/>GPTëŠ” ì‚¬ì „ í•™ìŠµëœ ì–¸ì–´ ëª¨ë¸ì„ ë°”íƒ•ìœ¼ë¡œ ì¢‹ì€ ì„±ëŠ¥ì„ í™•ë³´í•  ìˆ˜ ìˆë‹¤ëŠ” ì ê³¼ ì‚¬ì „ í•™ìŠµ ëª¨ë¸ì— Transformer êµ¬ì¡°ê°€ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì„ì„ ì•Œ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aHDyu6nq5ir"
      },
      "source": [
        "### BERT (2018.10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6PsrQKgAmyz"
      },
      "source": [
        "<img width=\"600\" alt=\"model_name\" src=\"https://user-images.githubusercontent.com/45377884/112963631-88184500-9182-11eb-8c87-f470e25d7567.png\">\n",
        "\n",
        "> [ë‹¤ì–‘í•œ ìºë¦­í„° ì´ë¦„ì„ ë”´ NLP ëª¨ë¸](https://towardsdatascience.com/machine-learnings-obsession-with-kids-tv-show-characters-728edfb43b3c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWjBLUwWAoay"
      },
      "source": [
        "**BERT**(**B**idirectional **E**ncoder **R**epresentation by **T**ransformer)ëŠ” 2018ë…„ 10ì›” êµ¬ê¸€ì—ì„œ ë°œí‘œí•œ ëª¨ë¸ì…ë‹ˆë‹¤.\n",
        "\n",
        "ëª¨ë¸ ì´ë¦„ì—ì„œ ì•Œ ìˆ˜ ìˆë“¯ BERTëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ì¸ì½”ë”ë§Œì„ ì‚¬ìš©í•˜ì—¬ ì–‘ë°©í–¥(Bidirectional)ìœ¼ë¡œ ì½ì–´ëƒ…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJV0Z4s3dn1a"
      },
      "source": [
        "- **êµ¬ì¡°**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wo4epFbAqp7"
      },
      "source": [
        "GPTê°€ íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ë””ì½”ë” ë¸”ë¡ì„ 12ê°œ ìŒ“ì•„ì˜¬ë¦° ëª¨ë¸ì´ì—ˆë‹¤ë©´ **BERTëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ì¸ì½”ë” ë¸”ë¡**ì„ 12ê°œ ìŒ“ì•„ì˜¬ë¦° ëª¨ë¸ì…ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpUIL_WuAspc"
      },
      "source": [
        "<img width=\"500\" alt=\"model_name\" src=\"http://jalammar.github.io/images/bert-base-bert-large-encoders.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rwwu_ynaAuC9"
      },
      "source": [
        "BERT ì—­ì‹œ GPT ì™€ ë™ì¼í•œ Pre-trained LM ì´ê¸° ë•Œë¬¸ì— Pre-trainingê³¼ Fine-tuning ê³¼ì •ì„ í†µí•´ í•™ìŠµë©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGnMfe2efIMd"
      },
      "source": [
        "- **ì‚¬ì „ í•™ìŠµ(Pre-training)**\n",
        "\n",
        "BERTì˜ íŠ¹ì´í•œ ì‚¬ì „ í•™ìŠµ ë°©ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. BERTì˜ ì‚¬ì „ í•™ìŠµ ê³¼ì •ì—ì„œ ì‚¬ìš©ë˜ëŠ” **2ê°€ì§€ ë°©ë²•(MLM, NSP)**ì„ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEIRSx5vV_Pt"
      },
      "source": [
        "> **MLM(Masked Language Model)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RHHJKmVBrJV"
      },
      "source": [
        "ì²« ë²ˆì§¸ëŠ” MLM(Masked Language Model) ì…ë‹ˆë‹¤. í˜¹ì‹œ ì•„ë˜ì™€ ê°™ì€ ë¬¸ì œë¥¼ í’€ì–´ë³´ì‹  ê²½í—˜ì´ ìˆìœ¼ì‹ ê°€ìš”?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAkoYiM-Bsmu"
      },
      "source": [
        "<img width=\"300\" alt=\"mlm\" src=\"https://thumb.mt.co.kr/06/2013/11/2013110718224659109_1.jpg/dims/optimize/\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40WZ-DudWEva"
      },
      "source": [
        "ì˜ì–´ ì‹œí—˜ì„ í•œ ë²ˆì¯¤ ì¤€ë¹„í•´ë³´ì‹  ë¶„ì´ë¼ë©´ ë¹ˆì¹¸ ì±„ìš°ê¸° ìœ í˜• ë¬¸ì œë¥¼ í’€ì–´ë³´ì‹  ì ì´ ìˆì„ ê²ƒì…ë‹ˆë‹¤. ë³´í†µì€ ë¹ˆì¹¸ì— ë¬¸ë²•ì /ì˜ë¯¸ì ìœ¼ë¡œ ì˜¬ë°”ë¥¸ ë‹¨ì–´ë¥¼ ì±„ìš°ê²Œ ë©ë‹ˆë‹¤.\n",
        "\n",
        "BERTë„ ì´ì²˜ëŸ¼ **ë¹ˆì¹¸ ì±„ìš°ê¸°**ë¥¼ í•˜ë©´ì„œ ë‹¨ì–´ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.<br/>BERTëŠ” ì‚¬ì „ í•™ìŠµ ê³¼ì •ì—ì„œ ë ˆì´ë¸”ë§ ë˜ì§€ ì•Šì€ ë§ë­‰ì¹˜ ì¤‘ì—ì„œ ëœë¤ìœ¼ë¡œ 15\\%ê°€ëŸ‰ì˜ ë‹¨ì–´ë¥¼ ë§ˆìŠ¤í‚¹í•©ë‹ˆë‹¤.<br/>ê·¸ë¦¬ê³  ë§ˆìŠ¤í‚¹ëœ ìœ„ì¹˜ì— ì›ë˜ ìˆë˜ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGQkOv6YWJjB"
      },
      "source": [
        "<img width=\"600\" alt=\"mlm_example\" src=\"http://jalammar.github.io/images/BERT-language-modeling-masked-lm.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFqu5WuaDgJY"
      },
      "source": [
        "MLMì€ ì–‘ìª½ì˜ ë¬¸ë§¥ì„ ë™ì‹œì— ë³¼ ìˆ˜ ìˆë‹¤ëŠ” ì¥ì ì´ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì•„ë˜ ê·¸ë¦¼ì€ GPTì™€ BERTì˜ í•™ìŠµ ë°©í–¥ì„ ë¹„êµí•˜ì—¬ ë‚˜íƒ€ë‚¸ ê·¸ë¦¼ì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a3g9iZEDkg-"
      },
      "source": [
        "<img width=\"300\" alt=\"gpt_vs_bert\" src=\"https://user-images.githubusercontent.com/45377884/113259927-a445ee80-9308-11eb-8fbd-95d5f553480a.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTT-rlIaDlw7"
      },
      "source": [
        "GPTëŠ” ***'ê±°ê¸°'*** ë¼ëŠ” ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•  ë•Œ 'ì–´ì œ ì¹´í˜ ê°”ì—ˆì–´'ì˜ ì •ë³´ë§Œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.<br/>\n",
        "í•˜ì§€ë§Œ BERTëŠ” ë¹ˆì¹¸ì— ë“¤ì–´ê°ˆ ***'ê±°ê¸°'*** ë¼ëŠ” ë‹¨ì–´ë¥¼ ì˜ˆì¸¡ í•  ë•Œ 'ì–´ì œ ì¹´í˜ ê°”ì—ˆì–´'ë¿ë§Œ ì•„ë‹ˆë¼ 'ì‚¬ëŒ ë§ë”ë¼'ì˜ ì •ë³´ë„ ì°¸ê³ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.<br/>\n",
        "ì´ë ‡ê²Œ ì–‘ë°©í–¥ìœ¼ë¡œ í•™ìŠµí•  ê²½ìš° ë‹¨ì–´ê°€ ë¬¸ë§¥ ì‚¬ì´ì—ì„œ ê°€ì§„ ì˜ë¯¸ë¥¼ ìµœëŒ€ë¡œ í•™ìŠµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "MLMì€ ë‹¤ì†Œ ê°„ë‹¨í•œ ì•„ì´ë””ì–´ì´ì§€ë§Œ ë‹¨ì–´ì˜ ë¬¸ë§¥ì  ì˜ë¯¸ë¥¼ ìµœëŒ€ë¡œ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ í•¨ìœ¼ë¡œì¨ BERTê°€ ë†’ì€ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ëŠ” ë°ì— ì»¤ë‹¤ë€ ì—­í• ì„ í•˜ì˜€ìŠµë‹ˆë‹¤.<br/>ë‹¤ìŒìœ¼ë¡œ 2ë²ˆì§¸ ë°©ë²•ì¸ NSPì— ëŒ€í•´ì„œ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JmCxVxFWB4d"
      },
      "source": [
        "> **NSP(Next Sentence Prediction)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6Xt904dG11P"
      },
      "source": [
        "BERTëŠ” NSP(Next Sentence Prediction) ë°©ì‹ìœ¼ë¡œë„ í•™ìŠµí•©ë‹ˆë‹¤. ë™ë¬¸ì„œë‹µì´ë¼ëŠ” ì‚¬ìì„±ì–´ ì•Œê³  ê³„ì‹ ê°€ìš”?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVdPbkU2G6uG"
      },
      "source": [
        "<img width=\"350\" alt=\"nsp_idea\" src=\"https://thx.sfo2.cdn.digitaloceanspaces.com/wr/hanja_images/%E6%9D%B1%E5%95%8F%E8%A5%BF%E7%AD%94_800.jpg\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEcsClhSXw95"
      },
      "source": [
        "NSPëŠ” ëª¨ë¸ì´ ë¬¸ë§¥ì— ë§ëŠ” ì´ì•¼ê¸°ë¥¼ í•˜ëŠ”ì§€ ì•„ë‹ˆë©´ ë™ë¬¸ì„œë‹µì„ í•˜ëŠ”ì§€ ì•„ë‹Œì§€ë¥¼ íŒë‹¨í•˜ë©° í•™ìŠµí•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.<br/>NSPì— ëŒ€í•´ ì•Œì•„ë³´ê¸° ì „ì— BERTì— ìˆëŠ” ë‘ ê°€ì§€ Special Tokenì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.<br/>BERTì˜ Special Tokenì€ `[SEP]`(Separation)ê³¼ `[CLS]`(Classification)ì´ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMJ0csCoIJSn"
      },
      "source": [
        "BERTëŠ” ì‚¬ì „ í•™ìŠµ ì‹œì— í…ìŠ¤íŠ¸ë¥¼ 2ê°œë¡œ ë‚˜ëˆ ì„œ ë„£ê²Œ ë©ë‹ˆë‹¤.<br/>`[CLS]`ëŠ” ëª¨ë“  ë‹¨ì–´ í† í° ì•ì— ìœ„ì¹˜í•˜ê³ , `[SEP]`ì€ ë‘ í…ìŠ¤íŠ¸ ì‚¬ì´ì™€ ë§¨ ë§ˆì§€ë§‰ì— ìœ„ì¹˜í•©ë‹ˆë‹¤.<br/>NSPëŠ” ê°€ìš´ë° `[SEP]` í† í° ë’¤ì— ì˜¤ëŠ” í…ìŠ¤íŠ¸ê°€ ì´ì „ í…ìŠ¤íŠ¸ì™€ ì´ì–´ì§€ëŠ” ë¶€ë¶„ì¸ì§€ë¥¼ `[CLS]`ë¥¼ í†µí•´ ì˜ˆì¸¡í•©ë‹ˆë‹¤.\n",
        "\n",
        "ë‘ ë¬¸ì¥ì´ ë°”ë¡œ ì´ì–´ì§€ëŠ” ë¬¸ì¥ì¼ ê²½ìš° **`IsNext`** ë¡œ íŒë‹¨í•˜ë©° ê·¸ë ‡ì§€ ì•Šì€ ë¬¸ì¥ ìŒì¼ ê²½ìš°  **`NotNext`** ë¥¼ íŒë‹¨í•˜ë„ë¡ í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwnji699X1LR"
      },
      "source": [
        "<img width=\"500\" alt=\"nsp_1\" src=\"http://jalammar.github.io/images/bert-next-sentence-prediction.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtNsNQHFInjv"
      },
      "source": [
        "ì•„ë˜ëŠ” ë“œë¼ë§ˆ ëŒ€ë³¸ì„ ì˜ˆì‹œë¡œ NSPê°€ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ” ì§€ë¥¼ ë‚˜íƒ€ë‚¸ ê·¸ë¦¼ì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id8g1fpoX-yl"
      },
      "source": [
        "<img width=\"500\" alt=\"nsp_2\" src=\"https://user-images.githubusercontent.com/45377884/86514846-d0067780-be4f-11ea-9809-c3e43b8ad3f9.png\">     \n",
        "\n",
        "<img width=\"500\" alt=\"nsp_3\" src=\"https://user-images.githubusercontent.com/45377884/86514847-d137a480-be4f-11ea-82be-d229bf75fbf8.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrXfjo2MX4RZ"
      },
      "source": [
        "NSP ì—­ì‹œ ê°„ë‹¨í•œ ì•„ì´ë””ì–´ì§€ë§Œ ëª¨ë¸ì´ ë¬¸ì¥ê³¼ ë¬¸ì¥ ì‚¬ì´ì˜ ê´€ê³„ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ í•¨ìœ¼ë¡œì¨ ì§ˆì˜ì‘ë‹µ(QA), ìì—°ì–´ ì¶”ë¡ (NLI) ë“±ì˜ íƒœìŠ¤í¬ì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¼ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8sUh3xCxv_U"
      },
      "source": [
        "- **Fine-tuning**\n",
        "\n",
        "BERT ì—­ì‹œ ëª¨ë¸ì˜ êµ¬ì¡°ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€í•œ ì±„ ë°ì´í„°ë¥¼ ì…ë ¥í•˜ëŠ” í˜•íƒœë§Œ ë°”ê¾¸ì–´ì„œ Fine-tuningì„ ì‹¤ì‹œí•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6cB2PLbMZc9"
      },
      "source": [
        "<img width=\"700\" alt=\"nsp_2\" src=\"http://jalammar.github.io/images/bert-tasks.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYDed3TaYB_c"
      },
      "source": [
        "(a)ëŠ” â€œSentenceâ€ ìŒì„ ë¶„ë¥˜í•˜ëŠ” íƒœìŠ¤í¬ì…ë‹ˆë‹¤. `[SEP]`ìœ¼ë¡œ ë‚˜ëˆ ì§„ â€œSentenceâ€ ìŒì„ ì…ë ¥ë°›ì•„ `[CLS]`ê°€ ì¶œë ¥í•˜ëŠ” í´ë˜ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
        "\n",
        "(b)ëŠ” ê°ì„±ë¶„ì„ ë“± í•˜ë‚˜ì˜ ë¬¸ì¥ì„ ì…ë ¥í•˜ì—¬ `[CLS]`ë¡œ í•´ë‹¹ ë¬¸ì¥ì„ ë¶„ë¥˜í•˜ëŠ” íƒœìŠ¤í¬ì…ë‹ˆë‹¤.\n",
        "\n",
        "(c)ëŠ” ì§ˆì˜ ì‘ë‹µ íƒœìŠ¤í¬ì…ë‹ˆë‹¤. ì§ˆë¬¸ê³¼ ë³¸ë¬¸ì— í•´ë‹¹í•˜ëŠ” ë‹¨ë½ì„ `[SEP]` í† í°ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì…ë ¥í•˜ë©´ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì„ ì¶œë ¥í•˜ë„ë¡ í•©ë‹ˆë‹¤.\n",
        "\n",
        "(d)ëŠ” í’ˆì‚¬ íƒœê¹…(POS tagging)ì´ë‚˜ ê°œì²´ëª… ì¸ì‹(Named Entity Recognition, NER) ë“±ì˜ íƒœìŠ¤í¬ì…ë‹ˆë‹¤. ì…ë ¥ë°›ì€ ê° í† í°ë§ˆë‹¤ ë‹µì„ ì¶œë ¥í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc45Gcc80eXj"
      },
      "source": [
        "- **ê²°ê³¼ & ê²°ë¡ **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i70diS5cMfR2"
      },
      "source": [
        "BERTëŠ” ê°„ë‹¨í•œ ì‚¬ì „ í•™ìŠµ ì•„ì´ë””ì–´ë¡œ ë§ì€ íƒœìŠ¤í¬ì—ì„œ SOTAë¥¼ ë‹¬ì„±í•˜ì˜€ìŠµë‹ˆë‹¤.<br/>ë‹¨ìˆœí•œ ì•„ì´ë””ì–´ë¥¼ í†µí•´ ì—„ì²­ë‚œ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ì˜€ê¸°ì— ë‹¹ì‹œ ë§ì€ ì¶©ê²©ì„ ì£¼ì—ˆìŠµë‹ˆë‹¤. ì´í›„ë¡œë„ BERTë¥¼ ê°œì„ í•˜ê¸° ìœ„í•œ ì—°êµ¬ê°€ ë§ì´ ì§„í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "íŠ¹íˆ MLMì„ í†µí•´ BERTê°€ ì¢‹ì€ ì„±ëŠ¥ì„ ë‹¬ì„±í•œ ë’¤ë¡œ í…ìŠ¤íŠ¸ì— ë…¸ì´ì¦ˆë¥¼ ì¤€ í›„ì— ì´ë¥¼ ë‹¤ì‹œ ë§ì¶”ëŠ”(Denoising) ë°©ë²•ì— ëŒ€í•´ ë§ì€ ì—°êµ¬ê°€ ì§„í–‰ë˜ì—ˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gweObbaTGpqX"
      },
      "source": [
        "### Beyond BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FfDoAT7Neng"
      },
      "source": [
        "- **ë” í° ëª¨ë¸ ë§Œë“¤ê¸°**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQLXjCffdLj9"
      },
      "source": [
        "<img width=\"700\" alt=\"getting_bigger\" src=\"https://www.microsoft.com/en-us/research/uploads/prod/2020/02/TurningNGL_Model__1400x788.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caGYeYHZdN3Z"
      },
      "source": [
        "GPT(2018.6)ì™€ BERT(2018.10) ì´í›„ë¡œë„ ìˆ˜ë§ì€ ëª¨ë¸ì´ ë°œí‘œë˜ì–´ ì™”ìŠµë‹ˆë‹¤. ì´í›„ ë°œí‘œë˜ê³  ìˆëŠ” ëª¨ë¸ì˜ ì£¼ìš” ê²½í–¥ì„± ì¤‘ í•˜ë‚˜ëŠ” **ëª¨ë¸ í¬ê¸° í‚¤ìš°ê¸°** ì…ë‹ˆë‹¤.<br/>ìœ„ ê·¸ë¦¼ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯  GPTì™€ BERTì´í›„ ë°œí‘œë˜ëŠ” ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„° ìˆ˜ëŠ” ê¸°í•˜ê¸‰ìˆ˜ì ìœ¼ë¡œ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "íŠ¹íˆ ì‘ë…„ 6ì›”ì— ë°œí‘œëœ GPT-3ì˜ íŒŒë¼ë¯¸í„° ê°œìˆ˜ëŠ” ì•½ 1750ì–µ ê°œë¡œ ìœ„ ê·¸ë¦¼ì— ë‚˜ì™€ìˆëŠ” T-NLGë³´ë‹¤ë„ 10ë°°ë‚˜ ë§ì€ íŒŒë¼ë¯¸í„° ìˆ˜ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.<br/>í¬ê¸°ë¥¼ í‚¤ìš¸ìˆ˜ë¡ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ê³  ìˆê¸° ë•Œë¬¸ì— ê³„ì†í•´ì„œ í‚¤ìš°ê³  ìˆëŠ” ìƒí™©ì…ë‹ˆë‹¤. <br/>í•˜ì§€ë§Œ ì‚¬ì „ í•™ìŠµì— ë”°ë¥¸ ë¹„ìš© ë¬¸ì œ ë“± í¬ê¸°ë§Œ ì»¤ì§€ëŠ” ëª¨ë¸ì— ëŒ€í•œ ìš°ë ¤ì˜ ì‹œê°ë„ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ENRgv7ZdQGv"
      },
      "source": [
        "<img width=\"400\" alt=\"getting_bigger_gpt3\" src=\"https://miro.medium.com/max/1164/1*C-KNWQC_wXh-Q2wc6VPK1g.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8iDUH8WsW36"
      },
      "source": [
        "- **ë” ì¢‹ì€ í•™ìŠµ ë°©ë²•ì„ ì ìš©í•˜ê±°ë‚˜ ê°€ë²¼ìš´ ëª¨ë¸ ë§Œë“¤ê¸°**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQw_pUUAdXA8"
      },
      "source": [
        "ê¸°ì¡´ GPTë‚˜ BERTì˜ ë‹¨ì ì„ ë³´ì™„í•˜ëŠ” ë°©í–¥ì˜ ì—°êµ¬ë„ ì§€ì†ë˜ê³  ìˆìŠµë‹ˆë‹¤. íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ë””ì½”ë” ë¸”ë¡ë§Œì„ ì‚¬ìš©í•œ GPTì™€ ì¸ì½”ë” ë¸”ë¡ë§Œì„ ì‚¬ìš©í•œ BERTëŠ” ìƒëŒ€ì ìœ¼ë¡œ ì“°ê¸°(ìƒì„±)ì™€ ì½ê¸°(ìì—°ì–´ ì´í•´)ì— íŠ¹í™”ëœ ëª¨ë¸ì…ë‹ˆë‹¤.<br/>**ë‘ ëª¨ë¸ì´ ì‚¬ìš©í–ˆë˜ ë°©ë²•ì„ ê²°í•©í•˜ê±°ë‚˜ ì‹¬í™”**ì‹œí‚¨ ëª¨ë¸ë¡œ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ì–»ì„ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.<br/>ëŒ€í‘œì ì¸ ëª¨ë¸ë¡œ Masking ë°©ë²•ì— ë³€í™”ë¥¼ ì£¼ëŠ” SpanBERT, RoBERTaë‚˜ Noising ë°©ë²•ì— ë³€í™”ë¥¼ ì¤€ XLNetì´ë‚˜ BART ë“±ì˜ ëª¨ë¸ì´ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIQ7NpPpdZOX"
      },
      "source": [
        "<img width=\"500\" alt=\"bart\" src=\"https://miro.medium.com/max/1400/0*MeyyeTYxwtSZJPiL\">   \n",
        "\n",
        "\n",
        "<img width=\"500\" alt=\"bart_noising\" src=\"https://www.weak-learner.com/assets/img/blog/personal/bart_transformations.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb_aui5ydbXf"
      },
      "source": [
        "ëª¨ë¸ ìì²´ê°€ í¬ë‹¤ ë³´ë‹ˆ ì‚¬ì´ì¦ˆë¥¼ ì¤„ì´ë˜ ì„±ëŠ¥ì€ ë³´ì „í•˜ëŠ” ìª½ìœ¼ë¡œë„ ë§ì€ ì—°êµ¬ê°€ ì§„í–‰ë˜ê³  ìˆìŠµë‹ˆë‹¤.<br/> DistillBERT, ALBERT(A Light BERT) ë‚˜ Electraê°€ ì´ëŸ° ë°©í–¥ìœ¼ë¡œ ì—°êµ¬ëœ ëŒ€í‘œì ì¸ ëª¨ë¸ì´ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.<br/>ì•„ë˜ëŠ” GAN-Like ë°©ë²•ì„ ì ìš©í•œ Electraì˜ ëª¨ë¸ êµ¬ì¡°ì¸ë°ìš”. ì´ëŸ° ëª¨ë¸ ëª¨ë‘ê°€ ë‹¤ì–‘í•œ ë°©ë²•ì„ ì´ìš©í•´ì„œ BERTì˜ í¬ê¸°ë¥¼ ì¤„ì´ê³  íš¨ìœ¨ì„±ì„ ë†’ì˜€ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w0WwJPMddHE"
      },
      "source": [
        "\n",
        "<img width=\"500\" alt=\"bart_noising\" src=\"https://1.bp.blogspot.com/-sHybc03nJRo/XmfLongdVYI/AAAAAAAAFbI/a0t5w_zOZ-UtxYaoQlVkmTRsyFJyFddtQCLcBGAsYHQ/s1600/image1.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Op5Ou_RsBB2"
      },
      "source": [
        "- **ì—¬ëŸ¬ ë°©ë©´ì—ì„œì˜ ë‹¤ì–‘í•œ ì‹œë„**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJSbrN17d25l"
      },
      "source": [
        "T5ë‚˜ GPT-3ì™€ ê°™ì€ ëª¨ë¸ì€ í•˜ë‚˜ì˜ ëª¨ë¸ë¡œ ë”ìš± ë‹¤ì–‘í•œ íƒœìŠ¤í¬ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì…ë‹ˆë‹¤.<br/>íŠ¹íˆ GPT-3ëŠ” Few-shot learning ë°©ë²•ë¡ ì„ ì ìš©í•œ ëª¨ë¸ë¡œ ì ë‹¹í•œ ê¸¸ì´ì˜ ì œì‹œë¬¸ë§Œ ì£¼ì–´ì£¼ë©´ Fine-tuning ì—†ì´ë„ ì—„ì²­ë‚˜ê²Œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.<br/>N-shot learning ì— ëŒ€í•´ì„œëŠ” ì•„ë˜ ìë£Œë¥¼ ì°¸ê³ í•˜ì‹œë©´ ë©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQp0fL9EeWqL"
      },
      "source": [
        "1. ***íŒŒì¸íŠœë‹(finetuning)*** : ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ íƒœìŠ¤í¬ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„° ì „ì²´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ëª¨ë¸ ì „ì²´ë¥¼ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ë°ì´í„°ì— ë§ê²Œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\n",
        "\n",
        "2. ***ì œë¡œìƒ·ëŸ¬ë‹(zero-shot learning)*** : ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ íƒœìŠ¤í¬ ë°ì´í„°ë¥¼ ì „í˜€ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ëª¨ë¸ì´ ë°”ë¡œ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ íƒœìŠ¤í¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
        "\n",
        "3. ***ì›ìƒ·ëŸ¬ë‹(one-shot learning)*** : ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ íƒœìŠ¤í¬ ë°ì´í„°ë¥¼ í•œ ê±´ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤. ëª¨ë¸ ì „ì²´ë¥¼ 1ê±´ì˜ ë°ì´í„°ì— ë§ê²Œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤. ì—…í…Œì´íŠ¸ ì—†ì´ ìˆ˜í–‰í•˜ëŠ” ì›ìƒ·ëŸ¬ë‹ë„ ìˆìŠµë‹ˆë‹¤. ëª¨ë¸ì´ 1ê±´ì˜ ë°ì´í„°ê°€ ì–´ë–»ê²Œ ìˆ˜í–‰ë˜ëŠ”ì§€ ì°¸ê³ í•œ ë’¤ ë°”ë¡œ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ íƒœìŠ¤í¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
        "\n",
        "4. ***í“¨ìƒ·ëŸ¬ë‹(few-shot learning)*** : ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ íƒœìŠ¤í¬ ë°ì´í„°ë¥¼ ëª‡ ê±´ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤. ëª¨ë¸ ì „ì²´ë¥¼ ëª‡ ê±´ì˜ ë°ì´í„°ì— ë§ê²Œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤. ì—…ë°ì´íŠ¸ ì—†ì´ ìˆ˜í–‰í•˜ëŠ” í“¨ì‚¿ëŸ¬ë‹ë„ ìˆìŠµë‹ˆë‹¤. ëª¨ë¸ì´ ëª‡ ê±´ì˜ ë°ì´í„°ê°€ ì–´ë–»ê²Œ ìˆ˜í–‰ë˜ëŠ”ì§€ ì°¸ê³ í•œ ë’¤ ë°”ë¡œ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ íƒœìŠ¤í¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16QSbKw43OKP"
      },
      "source": [
        "**ë‹¤êµ­ì–´(multilingual) ëª¨ë¸** ì—­ì‹œ ì—´ì‹¬íˆ ì—°êµ¬ë˜ê³  ìˆëŠ” ë¶„ì•¼ì…ë‹ˆë‹¤.<br/>ë³´í†µì˜ ê²½ìš° ë‹¨ì¼ ë§ë­‰ì¹˜ë¡œë§Œ ì‚¬ì „ í•™ìŠµì„ ì§„í–‰í•˜ê¸° ë•Œë¬¸ì— ì—¬ëŸ¬ ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ê³ ì í•˜ë©´ ì„±ëŠ¥ì´ ê¸‰ê²©íˆ ì €í•˜ë˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.\n",
        "\n",
        "ë‹¤ì–‘í•œ íƒœìŠ¤í¬ì—ì„œ ì–¸ì–´ë¥¼ ë„˜ë‚˜ë“¤ë©° ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ ì—­ì‹œ ë§ì´ ì—°êµ¬ë˜ê³  ìˆìŠµë‹ˆë‹¤.<br/>ëŒ€í‘œì ì¸ ëª¨ë¸ë¡œëŠ” mBART(multi-lingual BART), mT5(multi-lingual T5) ë“±ì´ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wia-8pdid6k9"
      },
      "source": [
        "\n",
        "\n",
        "ì§€ë‚œ 1ì›”ì—ëŠ” GPTë¥¼ ë°œí‘œí–ˆë˜ OpenAIì—ì„œ DALL-E ë¼ëŠ” ì¬ë¯¸ìˆëŠ” ëª¨ë¸ì„ ë°œí‘œí–ˆìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ì€ í…ìŠ¤íŠ¸ë¡œë¶€í„° ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.<br/>ì´ë ‡ê²Œ ìì—°ì–´ë¥¼ ë„˜ì–´ ë‹¤ì–‘í•œ ë§¤ì²´ë¡œ ê¸°ê³„ì™€ ì†Œí†µí•˜ëŠ” **ë©€í‹°ëª¨ë‹¬(Multi-Modal)**ì— ëŒ€í•œ ì—°êµ¬ë„ í™œë°œí•˜ê²Œ ì§„í–‰ë˜ê³  ìˆìŠµë‹ˆë‹¤.<br/>íŠ¹íˆ íŠ¸ëœìŠ¤í¬ë¨¸ê°€ ë©€í‹°ëª¨ë‹¬ ë¬¸ì œë¥¼ í‘¸ëŠ” ë°ì— êµ‰ì¥íˆ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ê³  ìˆê¸° ë•Œë¬¸ì— ì´ë¥¼ í™œìš©í•˜ì—¬ ë‹¤ì–‘í•œ ë¬¸ì œë¥¼ í’€ê³ ì í•˜ê³ ìˆìŠµë‹ˆë‹¤.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObY9pMs2d8Sh"
      },
      "source": [
        "<img width=\"700\" alt=\"dall-e\" src=\"https://user-images.githubusercontent.com/45377884/113083201-b9425500-9216-11eb-989a-3e5f28a794e5.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPgdtKE03lGX"
      },
      "source": [
        "## Review\n",
        "\n",
        "í•™ìŠµ ëª©í‘œì— ëŒ€í•´ ë‹¤ì‹œ ìƒê°í•´ë´…ì‹œë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t22B1RW63zTq"
      },
      "source": [
        "- Attentionì˜ ì¥ì ì— ëŒ€í•´ì„œ ìƒê°í•˜ê³  ì„¤ëª…í•´ë´…ë‹ˆë‹¤.\n",
        "\n",
        "    - RNN ëª¨ë¸ì˜ ë‹¨ì  2ê°€ì§€\n",
        "    - ì¥ê¸° ì˜ì¡´ì„±(Long-term dependency)\n",
        "    - Attentionì˜ ì¥ì "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMlh3bET4NRZ"
      },
      "source": [
        "- Transformerì˜ ì¥ì ê³¼ êµ¬ì¡°ì— ëŒ€í•´ì„œ ìƒê°í•˜ê³  ì„¤ëª…í•´ë´…ë‹ˆë‹¤.\n",
        "    - \"Attention is All You Need\" (ì™œ ë…¼ë¬¸ ì œëª©ì„ ì´ë ‡ê²Œ ì§€ì—ˆì„ì§€ì— ëŒ€í•´ì„œ ìƒê°í•´ë´…ì‹œë‹¤)\n",
        "    - Positional Encoding\n",
        "    - Self-Attention\n",
        "    - Masked Self-Attention\n",
        "    - Encoder-Decoder Attention\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XOZcD7x6SR2"
      },
      "source": [
        "- GPT & BERT\n",
        "    - ì‚¬ì „ í•™ìŠµ ì–¸ì–´ ëª¨ë¸(Pretrained Language Model), ì „ì´ í•™ìŠµ(Transfer Learning)\n",
        "        - ì‚¬ì „ í•™ìŠµ(Pre-training)\n",
        "        - Fine-tuning\n",
        "    - GPTì˜ êµ¬ì¡°\n",
        "    - BERTì˜ êµ¬ì¡°\n",
        "        - MLM(Masked Langauge Model)\n",
        "        - NSP(Next Sentence Prediction)\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQlhRzWQsQN1"
      },
      "source": [
        "## ì°¸ê³  ìë£Œ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHL_Cr3IA0IL"
      },
      "source": [
        "- Attentionì— ëŒ€í•´ ìì„¸í•˜ê²Œ ì•Œê³  ì‹¶ë‹¤ë©´\n",
        "    - [Visualizing A Neural Machine Translation Model](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/) (Mechanics of Seq2seq Models With Attention)\n",
        "    - [ë²ˆì—­](https://nlpinkorean.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)\n",
        "    - [Paper](https://arxiv.org/pdf/1409.0473.pdf) (Neural machine translation by jointly learning to align and translate)\n",
        "\n",
        "- íŠ¸ëœìŠ¤í¬ë¨¸ì— ëŒ€í•´ ì¡°ê¸ˆ ë” ìì„¸í•˜ê²Œ ì•Œê³  ì‹¶ë‹¤ë©´\n",
        "    - [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/)\n",
        "    - [ë²ˆì—­](https://nlpinkorean.github.io/illustrated-transformer/)\n",
        "    - [Paper](https://arxiv.org/pdf/1706.03762.pdf) (Attention is All You Need)\n",
        "\n",
        "- GPTì— ëŒ€í•´ ë” ìì„¸í•˜ê²Œ ì•Œê³  ì‹¶ë‹¤ë©´\n",
        "    - [The Illustrated GPT-2](http://jalammar.github.io/illustrated-gpt2/) (Visualizing Transformer Language Models)\n",
        "    - [Paper](https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf) (Improving Language Understanding by Generative Pre-Training)\n",
        "\n",
        "- BERTì— ëŒ€í•´ ë” ìì„¸í•˜ê²Œ ì•Œê³  ì‹¶ë‹¤ë©´\n",
        "    - [The Illustrated BERT, ELMo, and co.](http://jalammar.github.io/illustrated-bert/) (How NLP Cracked Transfer Learning)\n",
        "    - [ë²ˆì—­](https://nlpinkorean.github.io/illustrated-bert/)\n",
        "    - [Paper](https://arxiv.org/pdf/1810.04805.pdf) (Pre-training of Deep Bidirectional Transformers for\n",
        "Language Understanding)"
      ]
    }
  ]
}