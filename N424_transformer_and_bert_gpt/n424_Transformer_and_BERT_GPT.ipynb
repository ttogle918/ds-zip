{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "n424_Transformer_and_BERT_GPT.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "hBx1WzlmRwcM",
        "sXmedJR1AG1F",
        "HQlhRzWQsQN1"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9ixL-TF_uWx"
      },
      "source": [
        "<img align=\"right\" src=\"https://ds-cs-images.s3.ap-northeast-2.amazonaws.com/Codestates_Fulllogo_Color.png\" width=100>\n",
        "\n",
        "## ***DATA SCIENCE / SECTION 4 / SPRINT 2 / NOTE 4***\n",
        "\n",
        "---\n",
        "\n",
        "# Transformer & BERT, GPT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6lc3U9wBSrg"
      },
      "source": [
        "## ğŸ† í•™ìŠµ ëª©í‘œ\n",
        "\n",
        "- **Transformerì˜ ì¥ì ê³¼ ì£¼ìš” í”„ë¡œì„¸ìŠ¤ì¸ Self-Attentionì— ëŒ€í•´ ì´í•´í•˜ê³  ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.** \n",
        "    - íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ ë°œí‘œí•œ ë…¼ë¬¸ ì œëª©ì€ ì™œ \"Attention is All You Need\"ì¸ì§€ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.\n",
        "    - Positional Encodingì„ ì ìš©í•˜ëŠ” ì´ìœ ì— ëŒ€í•´ì„œ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.\n",
        "    - Masked Self-Attentionê°€ íŠ¸ëœìŠ¤í¬ë¨¸ êµ¬ì¡° ì¤‘ ì–´ë””ì— ì ìš©ë˜ë©° ì–´ë–¤ ì—­í• ì„ í•˜ëŠ”ì§€ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤. \n",
        "    - ê¸°ì¡´ RNNê³¼ ë¹„êµí•˜ì—¬ Transformerê°€ ê°€ì§€ëŠ” ì¥ì ì— ëŒ€í•´ì„œ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.\n",
        "\n",
        "- **GPT, BERT ê·¸ë¦¬ê³  ë‹¤ë¥¸ ëª¨ë¸ì— ëŒ€í•´ì„œ ê°œëµì ìœ¼ë¡œ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.**\n",
        "    - GPT(Generative Pre-Training)\n",
        "        - ì‚¬ì „ í•™ìŠµëœ ì–¸ì–´ ëª¨ë¸(Pre-trained LM)ì˜ Pre-trainingê³¼ Fine-tuningì€ ë¬´ì—‡ì´ê³  ê°ê° ì–´ë–¤ ì¢…ë¥˜ì˜ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ëŠ” ì§€ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.\n",
        "        - GPTëŠ” Transformerë¥¼ ì–´ë–»ê²Œ ë³€í˜•í•˜ì˜€ëŠ”ì§€ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.\n",
        "    - BERT(Bidirectional Encoder Representation by Transformer)\n",
        "        - BERTëŠ” Transformerë¥¼ ì–´ë–»ê²Œ ë³€í˜•í•˜ì˜€ìœ¼ë©° GPTì™€ì˜ ì°¨ì´ ë¬´ì—‡ì¸ì§€ ì•Œ ìˆ˜ ìˆë‹¤.\n",
        "        - MLM(Masked Language Model)ì€ ë¬´ì—‡ì¸ì§€ ì´í•´í•  ìˆ˜ ìˆë‹¤.\n",
        "        - NSP(Next Sentence Prediction)ì€ ë¬´ì—‡ì¸ì§€ ì´í•´í•  ìˆ˜ ìˆë‹¤.\n",
        "- **ìµœê·¼ ì–¸ì–´ ëª¨ë¸ì˜ ë°œì „ì€ ì–´ë–»ê²Œ ì§„í–‰ë˜ê³  ìˆëŠ”ì§€ ì•Œ ìˆ˜ ìˆë‹¤.**\n",
        "\n",
        "- ì£¼ì˜ : ì´í›„ì—ë„ ìƒˆë¡œìš´ ëª¨ë¸ì„ ê³µë¶€í•˜ê²Œ ë˜ë©´ ì•„ë˜ì™€ ê°™ì€ ìˆœì„œë¡œ í•™ìŠµí•˜ê²Œ ë  ê²ë‹ˆë‹¤.\n",
        "    1. ë…¼ë¬¸ì„ í†µí•´ í•´ë‹¹ ëª¨ë¸ì˜ ì»¨ì…‰ê³¼ ëŒ€ëµì ì¸ êµ¬ì¡°ë¥¼ íŒŒì•…í•œë‹¤.\n",
        "    2. ê¸°ì¡´ì— êµ¬í˜„ë˜ì–´ ìˆëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•´ í•´ë‹¹ ëª¨ë¸ì„ ì‚¬ìš©í•´ë³¸ë‹¤. (ì¶”ë¡  í˜¹ì€ íŒŒì¸íŠœë‹)\n",
        "    3. í•´ë‹¹ ëª¨ë¸ì— ëŒ€í•œ ì¢€ ë” ê¹Šì€ ì´í•´ê°€ í•„ìš”í•  ê²½ìš° ì½”ë“œë¡œ êµ¬í˜„í•´ë³¸ë‹¤.\n",
        "    - ì¦‰, ì˜¤ëŠ˜ì€ ì²« ë²ˆì§¸ë¡œ ì•„ë˜ ê°œë…ì„ ë°°ìš°ëŠ” ë§Œí¼ ëª¨ë“  ì½”ë“œë¥¼ ì´í•´í•˜ì§€ ëª»í•´ë„ ê´œì°®ìŠµë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwcgIeUuz3OK"
      },
      "source": [
        "## Warm Up\n",
        "\n",
        "ì§€ë‚œ ì‹œê°„ì— ë°°ì› ë˜ ë‚´ìš©ì„ ë– ì˜¬ë ¤ë´…ì‹œë‹¤.\n",
        "\n",
        "- RNN, LSTM, GRU\n",
        "\n",
        "    - RNN ê¸°ë°˜ ëª¨ë¸ì˜ ì¥ì ì— ëŒ€í•´ì„œ ìƒê°í•´ë´…ì‹œë‹¤.\n",
        "    - RNN ê¸°ë°˜ ëª¨ë¸ì˜ ë‹¨ì ì— ëŒ€í•´ì„œ ìƒê°í•´ë´…ì‹œë‹¤. (2ê°€ì§€ ì´ìƒ)\n",
        "        - LSTMê³¼ GRUëŠ” ì–´ë–¤ ë‹¨ì ì„ ì–´ë–»ê²Œ ê·¹ë³µí•˜ì˜€ëŠ”ì§€ ë‹¤ì‹œ ì•Œì•„ë´…ì‹œë‹¤.\n",
        "\n",
        "- ì´ë²ˆ ì‹œê°„ì—ëŠ” Transformerì— ëŒ€í•´ì„œ ë°°ìš¸ ì˜ˆì •ì…ë‹ˆë‹¤.\n",
        "    - [Transformer](https://www.youtube.com/watch?v=mxGCEWOxfe8) ì†Œê°œ ì˜ìƒ\n",
        "        - RNNê³¼ëŠ” ì™„ì „íˆ ë‹¤ë¥¸ ëª¨ë¸\n",
        "        - ***Attention is All You Need : í•„ìš”í•œ ê±´ Attention ë¿***\n",
        "    - [GPT](https://www.youtube.com/watch?v=FeEmmylAF0o) ì†Œê°œ ì˜ìƒ\n",
        "        - ì‚¬ì „ í•™ìŠµ ì–¸ì–´ ëª¨ë¸\n",
        "        - GPTì˜ êµ¬ì¡°\n",
        "    - [BERT](https://youtu.be/vo3cyr_8eDQ?t=712) ì†Œê°œ ì˜ìƒ (11:52 ë¶€í„°)\n",
        "        - BERTì˜ êµ¬ì¡°\n",
        "        - MLM(Masked Self-Attention)\n",
        "        - NSP(Next Sentence Prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpSQ4utmO71g"
      },
      "source": [
        "## 1. Transformer : Attention is All You Need"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zpodce2C3xqS"
      },
      "source": [
        "### íŠ¸ëœìŠ¤í¬ë¨¸(Transformer)ë€?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_Nkvve_FFIG"
      },
      "source": [
        "<img src=\"https://upload.wikimedia.org/wikipedia/en/thumb/9/94/Transformers_Age_of_Extinction_Poster.jpeg/220px-Transformers_Age_of_Extinction_Poster.jpeg\" alt=\"transformer_electric\" width=\"200\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKH7yo-AO3Ph"
      },
      "source": [
        "íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ê¸°ê³„ ë²ˆì—­ì„ ìœ„í•œ ìƒˆë¡œìš´ ëª¨ë¸ë¡œ ì´ì „ì— ë“±ì¥í–ˆë˜ Attention ë©”ì»¤ë‹ˆì¦˜ì„ ê·¹ëŒ€í™”í•˜ì—¬ ë›°ì–´ë‚œ ë²ˆì—­ ì„±ëŠ¥ì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.<br/>\n",
        "ìµœê·¼ ìì—°ì–´ì²˜ë¦¬ ëª¨ë¸ SOTA(State-of-the-Art)ì˜ ê¸°ë³¸ ì•„ì´ë””ì–´ëŠ” ê±°ì˜ ëª¨ë‘ íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ê³  ìˆìŠµë‹ˆë‹¤.<br/>\n",
        "ëª¨ë¸ì„ ì†Œê°œí•œ ë…¼ë¬¸ [Attention is All You Need](https://arxiv.org/abs/1706.03762) ëŠ” 3ë…„ ì‚¬ì´ì— 18000ë²ˆ ì´ìƒ ì¸ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.<br/>\n",
        "íŠ¸ëœìŠ¤í¬ë¨¸ê°€ ìì—°ì–´ì²˜ë¦¬ê°€ ì•„ë‹Œ ë‹¤ë¥¸ ë¬¸ì œë„ ì˜ í’€ê³ ìˆê¸° ë•Œë¬¸ì— ìµœê·¼ì—ëŠ” ì»´í“¨í„° ë¹„ì „ ìª½ì—ì„œë„ ì ìš©í•˜ë ¤ëŠ” ì‹œë„ê°€ ìˆìœ¼ë©°, ë©€í‹°ëª¨ë‹¬(Multi-Modal) ëª¨ë¸ì—ë„ ì ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤.<br/>\n",
        "\n",
        "RNN ê¸°ë°˜ ëª¨ë¸ì´ ê°€ì§„ êµ¬ì¡°ì  ë‹¨ì ì€ ë‹¨ì–´ê°€ **ìˆœì„œëŒ€ë¡œ** ë“¤ì–´ì˜¨ë‹¤ëŠ” ì ì…ë‹ˆë‹¤.<br/>\n",
        "ê·¸ë ‡ê¸° ë•Œë¬¸ì— ì²˜ë¦¬í•´ì•¼ í•˜ëŠ” ì‹œí€€ìŠ¤ê°€ ê¸¸ìˆ˜ë¡ **ì—°ì‚° ì‹œê°„ì´** ê¸¸ì–´ì§‘ë‹ˆë‹¤.<br/>\n",
        "**íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ì´ëŸ° ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë“±ì¥í•œ ëª¨ë¸**ì…ë‹ˆë‹¤.<br/>\n",
        "ëª¨ë“  í† í°ì„ ë™ì‹œì— ì…ë ¥ë°›ì•„ ë³‘ë ¬ ì—°ì‚°í•˜ê¸° ë•Œë¬¸ì— GPU ì—°ì‚°ì— ìµœì í™” ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì•„ë˜ëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ì˜ êµ¬ì¡°ë¥¼ ë‹¨ìˆœí•˜ê²Œ ì‹œê°í™”í•œ ê·¸ë¦¼ì…ë‹ˆë‹¤.<br/>\n",
        "Encoder, Decoderë¡œ í‘œí˜„ëœ ì‚¬ê°í˜•ì„ ê°ê° ì¸ì½”ë” ë¸”ë¡ê³¼ ë””ì½”ë” ë¸”ë¡ì´ë¼ê³  í•©ë‹ˆë‹¤.<br/>\n",
        "íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ì¸ì½”ë” ë¸”ë¡ê³¼ ë””ì½”ë” ë¸”ë¡ì´ 6ê°œì”© ëª¨ì—¬ìˆëŠ” êµ¬ì¡°ë¥¼ í•˜ê³  ìˆìŠµë‹ˆë‹¤. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEjnrUq-Zq9X"
      },
      "source": [
        "<img src=\"http://jalammar.github.io/images/t/The_transformer_encoder_decoder_stack.png\" alt=\"positional_encoding\" width=\"700\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNUm_DCUO_Yn"
      },
      "source": [
        "ê·¸ë¦¼ í•˜ë‚˜ë¥¼ ë” ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ì•„ë˜ëŠ” ë…¼ë¬¸ì—ì„œ íŠ¸ëœìŠ¤í¬ë¨¸ì˜ êµ¬ì¡°ë¥¼ ë‚˜íƒ€ë‚¸ ê·¸ë¦¼ì…ë‹ˆë‹¤.<br/>\n",
        "ê·¸ë¦¼ì„ ë³´ë©´ ì»¤ë‹¤ë€ íšŒìƒ‰ ë¸”ë¡ì´ 2ê°œ ìˆìŠµë‹ˆë‹¤.<br/>\n",
        "ì™¼ìª½ì€ ì¸ì½”ë” ë¸”ë¡ í•˜ë‚˜ë¥¼ ë‚˜íƒ€ë‚´ê³  ì˜¤ë¥¸ìª½ì€ ë””ì½”ë” ë¸”ë¡ í•˜ë‚˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.<br/>\n",
        "ì¸ì½”ë” ë¸”ë¡ì€ í¬ê²Œ 2ê°œì˜ sub-layer [**`Multi-Head (Self) Attention`, `Feed Forward`**] ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆìŠµë‹ˆë‹¤.<br/>\n",
        "ë””ì½”ë” ë¸”ë¡ì€ 3ê°œì˜ sub-layer [**`Masked Multi-Head (Self) Attention`, `Multi-Head (Encoder-Decoder) Attention`, `Feed Forward`**] ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yf5KKTsuPENw"
      },
      "source": [
        "<img src=\"https://miro.medium.com/max/1400/1*BHzGVskWGS_3jEcYYi6miQ.png\" alt=\"positional_encoding\" width=\"550\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntqpucgWuOKh"
      },
      "source": [
        "### Positional Encoding (ìœ„ì¹˜ ì¸ì½”ë”©)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jO2N2G4pPiA3"
      },
      "source": [
        "<img width=\"300\" alt=\"pe\" src=\"https://user-images.githubusercontent.com/45377884/112799904-ecb3a100-90a9-11eb-9072-87a965e81a77.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fw_uLipBPnMG"
      },
      "source": [
        "íŠ¸ëœìŠ¤í¬ë¨¸ì—ì„œëŠ” ë³‘ë ¬í™”ë¥¼ ìœ„í•´ ëª¨ë“  ë‹¨ì–´ ë²¡í„°ë¥¼ ë™ì‹œì— ì…ë ¥ë°›ìŠµë‹ˆë‹¤.<br/>\n",
        "ì»´í“¨í„°ëŠ” ì–´ë–¤ ë‹¨ì–´ê°€ ì–´ë””ì— ìœ„ì¹˜í•˜ëŠ”ì§€ ì•Œ ìˆ˜ ì—†ê²Œ ë©ë‹ˆë‹¤.<br/>\n",
        "ê·¸ë˜ì„œ ì»´í“¨í„°ê°€ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ë‹¨ì–´ì˜ ìœ„ì¹˜ ì •ë³´ë¥¼ ì œê³µí•˜ê¸° ìœ„í•œ ë²¡í„°ë¥¼ ë”°ë¡œ ì œê³µí•´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤.<br/>\n",
        "ë‹¨ì–´ì˜ ìƒëŒ€ì ì¸ ìœ„ì¹˜ ì •ë³´ë¥¼ ì œê³µí•˜ê¸° ìœ„í•œ ë²¡í„°ë¥¼ ë§Œë“œëŠ” ê³¼ì •ì„ `Positional Encoding` ì´ë¼ê³  í•©ë‹ˆë‹¤.<br/>\n",
        "\n",
        "`Positional Encoding`ì€ ì•„ë˜ì™€ ê°™ì€ ìˆ˜ì‹ìœ¼ë¡œ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.<br/>\n",
        "ìˆ˜ì‹ì´ ë³µì¡í•˜ë‹ˆ ìˆ˜í•™ì ìœ¼ë¡œ ì´í•´í•˜ë ¤ê³  í•˜ì§€ ì•Šìœ¼ì…”ë„ ë©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQLVS_0zPpdA"
      },
      "source": [
        "$$\n",
        "\\begin{aligned}\n",
        "\\text{PE}_{\\text{pos},2i} &= \\sin \\bigg(\\frac{\\text{pos}}{10000^{2i/d_{\\text{model}}}}\\bigg) \\\\\n",
        "\\text{PE}_{\\text{pos},2i+1} &= \\cos \\bigg(\\frac{\\text{pos}}{10000^{2i/d_{\\text{model}}}}\\bigg)\n",
        "\\end{aligned}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqVM-W4y3cCG"
      },
      "source": [
        "ì•„ë˜ëŠ” `Positional Encoding`ì„ í†µí•´ ë§Œë“¤ì–´ì§„ ë²¡í„°ë¥¼ ì‹œê°í™”í•œ ìë£Œì…ë‹ˆë‹¤.<br/>\n",
        "ì¼ì •í•œ íŒ¨í„´ì´ ìˆëŠ” ë²¡í„°ê°€ ë§Œë“¤ì–´ì§€ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.<br/>\n",
        "ì»´í“¨í„°ëŠ” ì´ë¥¼ í†µí•´ ë‹¨ì–´ì˜ ìƒëŒ€ì ì¸ ìœ„ì¹˜ë¥¼ íŒŒì•…í•˜ê²Œ ë©ë‹ˆë‹¤.<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZXLdjSfPva1"
      },
      "source": [
        "<img src=\"http://jalammar.github.io/images/t/transformer_positional_encoding_large_example.png\" alt=\"positional_encoding\" width=\"500\" />"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YO2S2h7q-vKE"
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "    \"\"\"\n",
        "    sin, cos ì•ˆì— ë“¤ì–´ê°ˆ ìˆ˜ì¹˜ë¥¼ êµ¬í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "    return pos * angle_rates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvW7dueW-zCK"
      },
      "source": [
        "def positional_encoding(position, d_model):\n",
        "    \"\"\"\n",
        "    ìœ„ì¹˜ ì¸ì½”ë”©(Positional Encoding)ì„ êµ¬í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
        "    \n",
        "    \"\"\"\n",
        "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "\n",
        "    # apply sin to even indices in the array; 2i\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    # apply cos to odd indices in the array; 2i+1\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yD70CNguVAC"
      },
      "source": [
        "### Self-Attention (ì…€í”„-ì–´í…ì…˜)\n",
        "***(ì´ë²ˆ ë…¸íŠ¸ì—ì„œëŠ” ì´ê²ƒë§Œì´ë¼ë„ ì•Œê³  ë„˜ì–´ê°€ë³´ë„ë¡ í•©ì‹œë‹¤)***\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gEVfOCmPycD"
      },
      "source": [
        "<img width=\"300\" alt=\"self-Attn\" src=\"https://user-images.githubusercontent.com/45377884/112809266-ca735080-90b4-11eb-9a25-7f34f37880c7.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2AxXXfPP0wH"
      },
      "source": [
        "íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ì£¼ìš” ë©”ì»¤ë‹ˆì¦˜ì¸ **Self-Attention**ì— ëŒ€í•´ ì•Œì•„ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì•„ë˜ì™€ ê°™ì€ ë¬¸ì¥ì´ ìˆë‹¤ê³  í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "> *The animal didn't cross the street because <ins>it</ins> was too tired* \n",
        "\n",
        "ìœ„ ë¬¸ì¥ì„ ì œëŒ€ë¡œ ë²ˆì—­í•˜ë ¤ë©´ **_\"it\"_** ê³¼ ê°™ì€ ì§€ì‹œëŒ€ëª…ì‚¬ê°€ ì–´ë–¤ ëŒ€ìƒì„ ê°€ë¦¬í‚¤ëŠ”ì§€ ì•Œì•„ì•¼ í•©ë‹ˆë‹¤.<br/>\n",
        "ê·¸ë ‡ê¸° ë•Œë¬¸ì— íŠ¸ëœìŠ¤í¬ë¨¸ì—ì„œëŠ” ë²ˆì—­í•˜ë ¤ëŠ” ë¬¸ì¥ ë‚´ë¶€ ìš”ì†Œì˜ ê´€ê³„ë¥¼ ì˜ íŒŒì•…í•˜ê¸° ìœ„í•´ì„œ, ë¬¸ì¥ ìì‹ ì— ëŒ€í•´ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì„ ì ìš©í•©ë‹ˆë‹¤.<br/>\n",
        "ì´ë¥¼ `Self-Attention`ì´ë¼ê³  í•©ë‹ˆë‹¤.\n",
        "\n",
        "ì•„ë˜ëŠ” **_\"it\"_** ì´ ì–´ë–¤ ë‹¨ì–´ì™€ ê°€ì¥ ì—°ê´€ë˜ì–´ ìˆëŠ” ì§€ë¥¼ ì‹œê°í™”í•œ ê·¸ë¦¼ì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvAsFAWJP2xz"
      },
      "source": [
        "<img src=\"http://jalammar.github.io/images/t/transformer_self-attention_visualization.png\" alt=\"self_attention_visualization\" width=\"350\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FG-Z6J9qwpyL"
      },
      "source": [
        "**`Self-Attention`**ì€ ì–´ë–¤ ê³¼ì •ì´ê¸¸ë˜ ë‹¨ì–´ ì‚¬ì´ì˜ ê´€ê³„ë¥¼ ì•Œì•„ë‚¼ ìˆ˜ ìˆì„ê¹Œìš”?\n",
        "\n",
        "Self-Attentionì—ì„œë„ ì¿¼ë¦¬(Query)-í‚¤(Key)-ë°¸ë¥˜(Value)ì˜ ì•„ì´ë””ì–´ê°€ ë™ì¼í•˜ê²Œ ë“±ì¥í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6au7EnYMtpi"
      },
      "source": [
        "----\n",
        "- **ì§€ë‚œ ì‹œê°„ì— ë°°ìš´ ë‚´ìš©ì„ ë³µìŠµí•´ë´…ì‹œë‹¤ - ê²€ìƒ‰ ì‹œìŠ¤í…œì—ì„œ í˜ëŸ¬ë‚˜ì˜¨ ì¿¼ë¦¬, í‚¤, ë°¸ë¥˜**\n",
        "\n",
        "Attentionì„ ë‹¤ë£° ë•Œ ë“±ì¥í–ˆë˜ ê²€ìƒ‰ ì‹œìŠ¤í…œì˜ ì•„ì´ë””ì–´ë¥¼ ë‹¤ì‹œ ë³µìŠµí•´ë´…ì‹œë‹¤.\n",
        "\n",
        "ì•„ë˜ëŠ” êµ¬ê¸€ì—ì„œ _\"what is attention in nlp\"_ ë¼ëŠ” ê²€ìƒ‰ì–´ë¥¼ êµ¬ê¸€ì— ì…ë ¥í–ˆì„ ë•Œì˜ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë‚˜íƒ€ë‚¸ ì´ë¯¸ì§€ì…ë‹ˆë‹¤.\n",
        "\n",
        "<img src=\"https://i.imgur.com/JdCQr1l.png\" alt=\"retrieval_system\" width=\"600\" />\n",
        "\n",
        "ê·¸ë¦¼ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´ ê²€ìƒ‰ ì‹œìŠ¤í…œì€ ì•„ë˜ì™€ ê°™ì€ 3ë‹¨ê³„ë¥¼ ê±°ì³ ì‘ë™í•©ë‹ˆë‹¤.\n",
        "\n",
        "1. ì°¾ê³ ì í•˜ëŠ” ì •ë³´ì— ëŒ€í•œ ê²€ìƒ‰ì–´(Query)ë¥¼ ì…ë ¥í•©ë‹ˆë‹¤.\n",
        "2. ê²€ìƒ‰ ì—”ì§„ì€ ê²€ìƒ‰ì–´ì™€ ê°€ì¥ ë¹„ìŠ·í•œ í‚¤ì›Œë“œ(Key)ë¥¼ ì°¾ìŠµë‹ˆë‹¤.\n",
        "3. ê·¸ë¦¬ê³  í•´ë‹¹ í‚¤ì›Œë“œ(Key)ì™€ ì—°ê²°ëœ í˜ì´ì§€(Value)ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
        "-------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnS4uzQOMsFO"
      },
      "source": [
        "ê¸°ì¡´ Attentionê³¼ì˜ ì°¨ì´ëŠ” ê° ë²¡í„°ê°€ ëª¨ë‘ ê°€ì¤‘ì¹˜ ë²¡í„°ë¼ëŠ” ì ì…ë‹ˆë‹¤.<br/>\n",
        "\n",
        "ê°ê°ì˜ ë²¡í„°ê°€ ì–´ë–¤ ì—­í• ì„ í•˜ëŠ”ì§€ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "- **ì¿¼ë¦¬(q)**ëŠ” ë¶„ì„í•˜ê³ ì í•˜ëŠ” ë‹¨ì–´ì— ëŒ€í•œ ê°€ì¤‘ì¹˜ ë²¡í„°ì…ë‹ˆë‹¤.\n",
        "\n",
        "- **í‚¤(k)**ëŠ” ê° ë‹¨ì–´ê°€ ì¿¼ë¦¬ì— í•´ë‹¹í•˜ëŠ” ë‹¨ì–´ì™€ ì–¼ë§ˆë‚˜ ì—°ê´€ìˆëŠ” ì§€ë¥¼ ë¹„êµí•˜ê¸° ìœ„í•œ ê°€ì¤‘ì¹˜ ë²¡í„°ì…ë‹ˆë‹¤.\n",
        "\n",
        "- **ë°¸ë¥˜(v)**ëŠ” ê° ë‹¨ì–´ì˜ ì˜ë¯¸ë¥¼ ì‚´ë ¤ì£¼ê¸° ìœ„í•œ ê°€ì¤‘ì¹˜ ë²¡í„°ì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrXC04GQy4Yb"
      },
      "source": [
        "**`Self-Attention`**ì€ ì„¸ ê°€ì§€ ê°€ì¤‘ì¹˜ ë²¡í„°ë¥¼ ëŒ€ìƒìœ¼ë¡œ ì–´í…ì…˜ì„ ì ìš©í•©ë‹ˆë‹¤.<br/>\n",
        "ì ìš©í•˜ëŠ” ë°©ì‹ì€ ê¸°ì¡´ Attention ë©”ì»¤ë‹ˆì¦˜ê³¼ ê±°ì˜ ë™ì¼í•©ë‹ˆë‹¤.\n",
        "\n",
        "1. ë¨¼ì €, **íŠ¹ì • ë‹¨ì–´ì˜ ì¿¼ë¦¬(q) ë²¡í„°ì™€ ëª¨ë“  ë‹¨ì–´ì˜ í‚¤(k) ë²¡í„°ë¥¼ ë‚´ì **í•©ë‹ˆë‹¤. ë‚´ì ì„ í†µí•´ ë‚˜ì˜¤ëŠ” ê°’ì´ Attention ìŠ¤ì½”ì–´(Score)ê°€ ë©ë‹ˆë‹¤.\n",
        "\n",
        "2. íŠ¸ëœìŠ¤í¬ë¨¸ì—ì„œëŠ” ì´ ê°€ì¤‘ì¹˜ë¥¼ q,k,v ë²¡í„° ì°¨ì› $d_k$ ì˜ ì œê³±ê·¼ì¸ $\\sqrt{d_k}$ ë¡œ ë‚˜ëˆ„ì–´ì¤ë‹ˆë‹¤.<br/>ê³„ì‚°ê°’ì„ ì•ˆì •ì ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ê¸° ìœ„í•œ ê³„ì‚° ë³´ì •ìœ¼ë¡œ ìƒê°í•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.  \n",
        "\n",
        "3. ë‹¤ìŒìœ¼ë¡œ **Softmax**ë¥¼ ì·¨í•´ì¤ë‹ˆë‹¤.<br/>\n",
        "ì´ë¥¼ í†µí•´ ì¿¼ë¦¬ì— í•´ë‹¹í•˜ëŠ” ë‹¨ì–´ì™€ ë¬¸ì¥ ë‚´ ë‹¤ë¥¸ ë‹¨ì–´ê°€ ê°€ì§€ëŠ” ê´€ê³„ì˜ ë¹„ìœ¨ì„ êµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "4. ë§ˆì§€ë§‰ìœ¼ë¡œ **ë°¸ë¥˜(v) ê° ë‹¨ì–´ì˜ ë²¡í„°ë¥¼ ê³±í•´ì¤€ í›„ ëª¨ë‘ ë”í•˜ë©´** Self-Attention ê³¼ì •ì´ ë§ˆë¬´ë¦¬ë©ë‹ˆë‹¤. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XUQi85yy7kR"
      },
      "source": [
        "**`Self-Attention`** ì˜ ê³¼ì •ì„ ê·¸ë¦¼ìœ¼ë¡œ ë‹¤ì‹œ ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTREy_tA1tAc"
      },
      "source": [
        "**1. ê°€ì¤‘ì¹˜ í–‰ë ¬ $W^Q, W^K, W^V$ ë¡œë¶€í„° ê° ë‹¨ì–´ì˜ ì¿¼ë¦¬, í‚¤, ë°¸ë¥˜(q, k, v) ë²¡í„°ë¥¼ ë§Œë“¤ì–´ëƒ…ë‹ˆë‹¤.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBOvyUgjRE6C"
      },
      "source": [
        "<img src=\"http://jalammar.github.io/images/xlnet/self-attention-1.png\" alt=\"transformer_15\" width=\"600\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH4SjvhPQB0h"
      },
      "source": [
        "**2. ë¶„ì„í•˜ê³ ì í•˜ëŠ” ë‹¨ì–´ì˜ ì¿¼ë¦¬ ë²¡í„°(q)ì™€ ë¬¸ì¥ ë‚´ ëª¨ë“  ë‹¨ì–´(ìì‹  í¬í•¨)ì˜ í‚¤ ë²¡í„°(k)ë¥¼ ë‚´ì í•˜ì—¬ ê° ë‹¨ì–´ì™€ ì–¼ë§ˆë‚˜ ê´€ë ¨ ì •ë„ë¥¼ êµ¬í•©ë‹ˆë‹¤.**\n",
        "\n",
        "(ì•„ë˜ ê·¸ë¦¼ì—ì„œëŠ” $\\sqrt{d_k}$ë¡œ ë‚˜ëˆ„ì–´ ì¤€ ë’¤ì— Softmaxë¥¼ ì·¨í•´ì£¼ëŠ” ê³¼ì •ì€ ìƒëµë˜ì—ˆìŠµë‹ˆë‹¤.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKrYd1eWRIH7"
      },
      "source": [
        "<img src=\"http://jalammar.github.io/images/xlnet/self-attention-2.png\" alt=\"transformer_15\" width=\"600\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZ_HnY9vQD4o"
      },
      "source": [
        "**3.  Softmaxì˜ ì¶œë ¥ê°’ê³¼ë°¸ë¥˜ ë²¡í„°(v)ë¥¼ ê³±í•´ì¤€ ë’¤ ë”í•˜ë©´ í•´ë‹¹ ë‹¨ì–´ì— ëŒ€í•œ Self-Attention ì¶œë ¥ê°’ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKbpOuTVRKf0"
      },
      "source": [
        "<img src=\"http://jalammar.github.io/images/xlnet/self-attention-3.png\" alt=\"transformer_15\" width=\"600\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iMflDTbQFV4"
      },
      "source": [
        "**4. í•˜ë‚˜ì˜ ë²¡í„°ì— ëŒ€í•´ì„œë§Œ ì‚´í´ë³´ì•˜ì§€ë§Œ ì‹¤ì œ Attention ê³„ì‚°ì€ í–‰ë ¬ ë‹¨ìœ„ë¡œ ë³‘ë ¬ ê³„ì‚°ë©ë‹ˆë‹¤.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMO4BdoQRM7P"
      },
      "source": [
        "<img src=\"http://jalammar.github.io/images/xlnet/self-attention-summary.png\" alt=\"transformer_15\" width=\"600\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lj6LqffDxYZu"
      },
      "source": [
        "ì‹¤ì œë¡œ ê° ë²¡í„°ëŠ” **í–‰ë ¬(Q, K, V)**ë¡œ í•œêº¼ë²ˆì— ê³„ì‚°ë©ë‹ˆë‹¤. $W^Q, W^K, W^V$ ëŠ” í•™ìŠµ ê³¼ì •ì—ì„œ ê°±ì‹ ë˜ëŠ” íŒŒë¼ë¯¸í„°ë¡œ ì´ë£¨ì–´ì§„ í–‰ë ¬ì…ë‹ˆë‹¤.<br/>\n",
        "ì„¸ í–‰ë ¬ê³¼ ë‹¨ì–´ í–‰ë ¬ì„ ë‚´ì í•˜ì—¬ ì¿¼ë¦¬, í‚¤, ë°¸ë¥˜ í–‰ë ¬(Q, K, V)ë¥¼ ë§Œë“¤ì–´ëƒ…ë‹ˆë‹¤.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "un25Mx6_RPem"
      },
      "source": [
        "<img src=\"http://jalammar.github.io/images/t/self-attention-matrix-calculation.png\" alt=\"transformer_12\" width=\"500\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0_CnhEVQI4h"
      },
      "source": [
        "ìœ„ì—ì„œ ì‚´í´ë³¸ ë°”ì™€ ê°™ì´\n",
        "\n",
        "1. ë¨¼ì € ì¿¼ë¦¬ í–‰ë ¬(Q)ê³¼ í‚¤ í–‰ë ¬(K)ì„ **ë‚´ì **í•©ë‹ˆë‹¤.\n",
        "\n",
        "2. ê²°ê³¼ë¡œ ë‚˜ì˜¤ëŠ” í–‰ë ¬ì˜ ìš”ì†Œë¥¼ $\\sqrt{d_k}$ ë¡œ **ë‚˜ëˆ„ì–´ ì¤ë‹ˆë‹¤.**\n",
        "\n",
        "3. í–‰ë ¬ì˜ ê° ìš”ì†Œì— `Softmax`ë¥¼ ì·¨í•´ì¤ë‹ˆë‹¤. \n",
        "\n",
        "4. ë§ˆì§€ë§‰ìœ¼ë¡œ **ë°¸ë¥˜ í–‰ë ¬(V)ê³¼ ë‚´ì **í•˜ë©´ ìµœì¢… ê²°ê³¼ í–‰ë ¬(Z)ì´ ë°˜í™˜ë©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uinyklXWyLrn"
      },
      "source": [
        "<img src=\"http://jalammar.github.io/images/t/self-attention-matrix-calculation-2.png\" alt=\"transformer_13\" width=\"700\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpxgcGIgj5PC"
      },
      "source": [
        "ì•„ë˜ëŠ” `Tensorflow` ì—ì„œ Self-Attentionì„ êµ¬í˜„í•œ ì½”ë“œì…ë‹ˆë‹¤. ì½”ë“œë¥¼ í†µí•´ Attentionì´ ê³„ì‚°ë˜ëŠ” ê³¼ì •ì„ ë‹¤ì‹œ ì‚´í´ë³´ë„ë¡ í•©ì‹œë‹¤. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFkqQMjHpIxI"
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  \"\"\"Calculate the attention weights.\n",
        "  q, k, v must have matching leading dimensions.\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "  The mask has different shapes depending on its type(padding or look ahead) \n",
        "  but it must be broadcastable for addition.\n",
        "  \n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable \n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "    \n",
        "  Returns:\n",
        "    output, attention_weights\n",
        "  \"\"\"\n",
        "\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "  \n",
        "  # scale matmul_qk\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  # add the mask to the scaled tensor.\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)  \n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "  # add up to 1.\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "  return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_RmjSVYluaO"
      },
      "source": [
        "### Multi-Head Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTRaQ5oVQ1gh"
      },
      "source": [
        "ë‹¤ìŒìœ¼ë¡œ **`Multi-Head Attention`** ì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.<br/>\n",
        "**`Multi-Head Attention`** ì´ë€ **`Self-Attention`** ì„ ë™ì‹œì— ì—¬ëŸ¬ ê°œë¡œ ì‹¤í–‰í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.<br/>\n",
        "ê° Head ë§ˆë‹¤ ë‹¤ë¥¸ Attention ê²°ê³¼ë¥¼ ë‚´ì–´ì£¼ê¸° ë•Œë¬¸ì— ì•™ìƒë¸”ê³¼ ìœ ì‚¬í•œ íš¨ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.<br/> \n",
        "ë…¼ë¬¸ì—ì„œëŠ” 8ê°œì˜ Headë¥¼ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.<br/>\n",
        "8ë²ˆì˜ Self-Attentionì„ ì‹¤í–‰í•˜ì—¬ ê°ê°ì˜ ì¶œë ¥ í–‰ë ¬ $Z_0, Z_1, \\cdots , Z_7$ ì„ ë§Œë“¤ì–´ëƒ…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rvzeSQkQ4SJ"
      },
      "source": [
        "<img src=\"http://jalammar.github.io/images/t/transformer_attention_heads_z.png\" alt=\"transformer_16\" width=\"500\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTcLefocQ7mC"
      },
      "source": [
        "ì¶œë ¥ëœ í–‰ë ¬ $Z_n (n=0,\\cdots,7)$ ì€ **ì´ì–´ë¶™ì—¬ì§‘ë‹ˆë‹¤(Concatenate)**.<br/>\n",
        "ë˜ ë‹¤ë¥¸ íŒŒë¼ë¯¸í„° í–‰ë ¬ì¸ $W^o$ ì™€ì˜ ë‚´ì ì„ í†µí•´ Multi-Head Attentionì˜ ìµœì¢… ê²°ê³¼ì¸ í–‰ë ¬ $Z$ë¥¼ ë§Œë“¤ì–´ëƒ…ë‹ˆë‹¤.<br/>\n",
        "ì—¬ê¸°ì„œ í–‰ë ¬ $W^o$ì˜ ìš”ì†Œ ì—­ì‹œ í•™ìŠµì„ í†µí•´ ê°±ì‹ ë©ë‹ˆë‹¤.<br/>\n",
        "ìµœì¢…ì ìœ¼ë¡œ ìƒì„±ëœ í–‰ë ¬ $Z$ëŠ” í† í° ë²¡í„°ë¡œ ì´ë£¨ì–´ì§„ í–‰ë ¬ $X$ì™€ **ë™ì¼í•œ í¬ê¸°(Shape)**ê°€ ë©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkS1oMy6Q-Pc"
      },
      "source": [
        "<img src=\"http://jalammar.github.io/images/t/transformer_attention_heads_weight_matrix_o.png\" alt=\"transformer_17\" width=\"500\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZo2_s-Z2Vi2"
      },
      "source": [
        "### Layer Normalization & Skip Connection\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLzwJ00c9zTV"
      },
      "source": [
        "<img width=\"300\" alt=\"lnorm_resicon\" src=\"https://user-images.githubusercontent.com/45377884/113169444-9056aa00-9280-11eb-8ba0-17c9211ad412.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OL55-1zZ9zrS"
      },
      "source": [
        "íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ëª¨ë“  sub-layerì—ì„œ ì¶œë ¥ëœ ë²¡í„°ëŠ” **Layer normalization**ê³¼ **Skip connection**ì„ ê±°ì¹˜ê²Œ ë©ë‹ˆë‹¤.<br/>\n",
        "Layer normalizationì˜ íš¨ê³¼ëŠ” Batch normalizationê³¼ ìœ ì‚¬í•©ë‹ˆë‹¤. í•™ìŠµì´ í›¨ì”¬ ë¹ ë¥´ê³  ì˜ ë˜ë„ë¡ í•©ë‹ˆë‹¤.<br/>\n",
        "Skip connection(í˜¹ì€ Residual connection)ì€ ì—­ì „íŒŒ ê³¼ì •ì—ì„œ ì •ë³´ê°€ ì†Œì‹¤ë˜ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.<br/>\n",
        "Sprint 3ì—ì„œ ë°°ìš¸ ResNetì˜ ì£¼ìš” ë©”ì»¤ë‹ˆì¦˜ì´ë¯€ë¡œ í•´ë‹¹ ë¶€ë¶„ì—ì„œ ë”ìš± ìì„¸í•˜ê²Œ ë‹¤ë£° ì˜ˆì •ì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQPefZjI2UTM"
      },
      "source": [
        "### Feed Forward Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHwk8VeqmNzU"
      },
      "source": [
        "<img width=\"300\" alt=\"á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2021-03-29 á„‹á…©á„’á…® 5 27 32\" src=\"https://user-images.githubusercontent.com/45377884/112808809-58027080-90b4-11eb-8ca7-ffa38e577d3d.png\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_H4S8ETC8BMO"
      },
      "source": [
        "ë‹¤ìŒìœ¼ë¡œ **`FFNN(Feed forward neural network)`** ë¡œ ë“¤ì–´ê°‘ë‹ˆë‹¤.<br/>ì€ë‹‰ì¸µì˜ ì°¨ì›ì´ ëŠ˜ì–´ë‚¬ë‹¤ê°€ ë‹¤ì‹œ ì›ë˜ ì°¨ì›ìœ¼ë¡œ ì¤„ì–´ë“œëŠ” ë‹¨ìˆœí•œ 2ì¸µ ì‹ ê²½ë§ì…ë‹ˆë‹¤.<br/>í™œì„±í™” í•¨ìˆ˜(Activation function)ìœ¼ë¡œ ReLUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "\n",
        "$$\n",
        " \\text{FFNN}(x) = \\max(0, W_1x + b_1) W_2 +b_2\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOLOYafDBGge"
      },
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzFup_5pDupE"
      },
      "source": [
        "### Masked Self-Attention\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_kn1-AYR18G"
      },
      "source": [
        "<img width=\"300\" alt=\"Masked_Self-Attention_in_structure\" src=\"https://user-images.githubusercontent.com/45377884/112808936-78322f80-90b4-11eb-9315-22cd9caad41d.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNdrsLrER3w2"
      },
      "source": [
        "**Masked Self-Attention**ì€ ë””ì½”ë” ë¸”ë¡ì—ì„œ ì‚¬ìš©ë˜ëŠ” íŠ¹ìˆ˜í•œ Self-Attentionì…ë‹ˆë‹¤.<br/>\n",
        "ë””ì½”ë”ëŠ” Auto Regressive í•˜ê²Œ ë‹¨ì–´ë¥¼ ìƒì„±í•˜ê¸° ë•Œë¬¸ì— íƒ€ê¹ƒ ë‹¨ì–´ ì´í›„ ë‹¨ì–´ë¥¼ ë³´ì§€ ì•Šê³  ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•´ì•¼ í•©ë‹ˆë‹¤.<br/>\n",
        "ë”°ë¼ì„œ íƒ€ê¹ƒ ë‹¨ì–´ ë’¤ì— ìœ„ì¹˜í•œ ë‹¨ì–´ëŠ” Self-Attentionì— ì˜í–¥ì„ ì£¼ì§€ ì•Šë„ë¡ **ë§ˆìŠ¤í‚¹(masking)**ì„ í•´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8-UwtUcR5WO"
      },
      "source": [
        "<img width=\"500\" alt=\"Masked_Self-Attention_ex\" src=\"http://jalammar.github.io/images/xlnet/transformer-decoder-block-self-attention-2.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33J9FxItR70W"
      },
      "source": [
        "***Self-Attention (without Masking) vs Masked Self-Attention***\n",
        "\n",
        "<img width=\"500\" alt=\"Masked_Self-Attention_ex2\" src=\"http://jalammar.github.io/images/gpt2/self-attention-and-masked-self-attention.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWJfqdxHSAY3"
      },
      "source": [
        "Self-Attention ë©”ì»¤ë‹ˆì¦˜ì€ ì¿¼ë¦¬ í–‰ë ¬(Q)ì™€ í‚¤ í–‰ë ¬(K)ì˜ ë‚´ì í•©ë‹ˆë‹¤.<br/>\n",
        "ê²°ê³¼ë¡œ ë‚˜ì˜¨ í–‰ë ¬ì„ ì°¨ì›ì˜ ì œê³±ê·¼ $\\sqrt{d_k}$ ë¡œ ë‚˜ëˆ„ì–´ ì¤€ ë‹¤ìŒ,<br/> \n",
        "Softmaxë¥¼ ì·¨í•´ì£¼ê³  ë°¸ë¥˜ í–‰ë ¬(V)ê³¼ ë‚´ì í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
        "\n",
        "**`Masked Self-Attention`** ì—ì„œëŠ” Softmaxë¥¼ ì·¨í•´ì£¼ê¸° ì „, ê°€ë ¤ì£¼ê³ ì í•˜ëŠ” ìš”ì†Œì—ë§Œ $-\\infty$ ì— í•´ë‹¹í•˜ëŠ” ë§¤ìš° ì‘ì€ ìˆ˜ë¥¼ ë”í•´ì¤ë‹ˆë‹¤.<br/>\n",
        "ì•„ë˜ ì˜ˆì‹œì—ì„œëŠ” -10ì–µ(=-1e9)ì„ ë”í•´ì£¼ì—ˆìŠµë‹ˆë‹¤.<br/>\n",
        "ì´ ê³¼ì •ì„ **ë§ˆìŠ¤í‚¹(Masking)**ì´ë¼ê³  í•©ë‹ˆë‹¤.<br/>\n",
        "ë§ˆìŠ¤í‚¹ëœ ê°’ì€ Softmaxë¥¼ ì·¨í•´ ì£¼ì—ˆì„ ë•Œ 0ì´ ë‚˜ì˜¤ë¯€ë¡œ Value ê³„ì‚°ì— ë°˜ì˜ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbTQf8oxzth-"
      },
      "source": [
        "<img width=\"600\" alt=\"masked_1\" src=\"http://jalammar.github.io/images/gpt2/transformer-attention-mask.png\">\n",
        "\n",
        "<img width=\"600\" alt=\"masked_2\" src=\"http://jalammar.github.io/images/gpt2/transformer-attention-masked-scores-softmax.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98r-D1WjSH3w"
      },
      "source": [
        "ìœ„ì—ì„œ ë“±ì¥í–ˆë˜ Self-Attentionì„ êµ¬í˜„ ì½”ë“œì—ì„œ. `mask` ì™€ ê´€ë ¨ëœ ë¶€ë¶„ë§Œ ë‹¤ì‹œ ë³´ë„ë¡ í•©ì‹œë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03EldudrJgAD"
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  \"\"\"Calculate the attention weights.\n",
        "  q, k, v must have matching leading dimensions.\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "  The mask has different shapes depending on its type(padding or look ahead) \n",
        "  but it must be broadcastable for addition.\n",
        "  \n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable \n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "    \n",
        "  Returns:\n",
        "    output, attention_weights\n",
        "  \"\"\"\n",
        "\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "  \n",
        "  # scale matmul_qk\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    \n",
        "  \"\"\"\n",
        "    maskê°€ ìˆì„ ê²½ìš° maskingëœ ìë¦¬(mask=1)ì—ëŠ” (-inf)ì— í•´ë‹¹í•˜ëŠ” ì ˆëŒ“ê°’ì´ í° ìŒìˆ˜ -1e9(=-10ì–µ)ì„ ë”í•´ì¤ë‹ˆë‹¤.\n",
        "    ê·¸ ê°’ì— softmaxë¥¼ ì·¨í•´ì£¼ë©´ ê±°ì˜ 0ì— ê°€ê¹Œìš´ ê°’ì´ ë‚˜ì˜µë‹ˆë‹¤. ê·¸ ë‹¤ìŒ value ê³„ì‚°ì‹œì— ë°˜ì˜ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
        "  \"\"\"\n",
        "    \n",
        "  # add the mask to the scaled tensor.\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)  \n",
        "\n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "  # add up to 1.\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "  return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OSVcyskH543"
      },
      "source": [
        "### Encoder-Decoder Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUGAg5ikSb_F"
      },
      "source": [
        "<img width=\"300\" alt=\"Encoder-Decoder_Attention\" src=\"https://user-images.githubusercontent.com/45377884/112809435-f8f12b80-90b4-11eb-96e1-3b0f7c530659.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wepMQd4oSdkE"
      },
      "source": [
        "ë””ì½”ë”ì—ì„œ Masked Self-Attention ì¸µì„ ì§€ë‚œ ë²¡í„°ëŠ” **Encoder-Decoder Attention** ì¸µìœ¼ë¡œ ë“¤ì–´ê°‘ë‹ˆë‹¤.<br/>\n",
        "ì¢‹ì€ ë²ˆì—­ì„ ìœ„í•´ì„œëŠ” ë²ˆì—­í•  ë¬¸ì¥ê³¼ ë²ˆì—­ëœ ë¬¸ì¥ ê°„ì˜ ê´€ê³„ ì—­ì‹œ ì¤‘ìš”í•©ë‹ˆë‹¤.<br/>\n",
        "ë²ˆì—­í•  ë¬¸ì¥ê³¼ ë²ˆì—­ë˜ëŠ” ë¬¸ì¥ì˜ ì •ë³´ ê´€ê³„ë¥¼ ì—®ì–´ì£¼ëŠ” ë¶€ë¶„ì´ ë°”ë¡œ ì´ ë¶€ë¶„ì…ë‹ˆë‹¤.\n",
        "\n",
        "ì´ ì¸µì—ì„œëŠ” **ë””ì½”ë” ë¸”ë¡ì˜** Masked Self-Attentionìœ¼ë¡œë¶€í„° ì¶œë ¥ëœ ë²¡í„°ë¥¼ **ì¿¼ë¦¬(Q)** ë²¡í„°ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.<br/>\n",
        "**í‚¤(K)ì™€ ë°¸ë¥˜(V)** ë²¡í„°ëŠ” ìµœìƒìœ„(=6ë²ˆì§¸) ì¸ì½”ë” ë¸”ë¡ì—ì„œ ì‚¬ìš©í–ˆë˜ ê°’ì„ ê·¸ëŒ€ë¡œ ê°€ì ¸ì™€ì„œ ì‚¬ìš©í•©ë‹ˆë‹¤.<br/>\n",
        "**`Encoder-Decoder Attention`** ì¸µì˜ ê³„ì‚° ê³¼ì •ì€ Self-Attention í–ˆë˜ ê²ƒê³¼ ë™ì¼í•©ë‹ˆë‹¤.\n",
        "\n",
        "ì•„ë˜ëŠ” **`Encoder-Decoder Attention`** ê°€ ì§„í–‰ë˜ëŠ” ìˆœì„œë¥¼ ë‚˜íƒ€ë‚¸ ì´ë¯¸ì§€ì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kawL4lmnSh0v"
      },
      "source": [
        "<img width=\"700\" alt=\"Encoder-Decoder_Attention_gif\" src=\"http://jalammar.github.io/images/t/transformer_decoding_1.gif\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOn_vpeyRyyT"
      },
      "source": [
        "### Linear & Softmax Layer\n",
        "\n",
        "ì´ì œ ëì…ë‹ˆë‹¤!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYcth4VySk4T"
      },
      "source": [
        "<img width=\"300\" alt=\"Linear_Softmax\" src=\"https://user-images.githubusercontent.com/45377884/112815762-994a4e80-90bb-11eb-9a57-a8be65c1a30b.png\">\n",
        "\n",
        "ë””ì½”ë”ì˜ ìµœìƒì¸µì„ í†µê³¼í•œ ë²¡í„°ë“¤ì€ Linear ì¸µì„ ì§€ë‚œ í›„ Softmaxë¥¼ í†µí•´ ì˜ˆì¸¡í•  ë‹¨ì–´ì˜ í™•ë¥ ì„ êµ¬í•˜ê²Œ ë©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBx1WzlmRwcM"
      },
      "source": [
        "### ì½”ë“œ ì‹¤ìŠµ 1\n",
        "\n",
        "(ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤. ì›í™œí•œ ì‹¤ìŠµì„ ìœ„í•´ì„œ epoch ìˆ˜ë¥¼ ì¤„ì´ê³  í•™ìŠµí•´ë„ ì¢‹ìŠµë‹ˆë‹¤.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjPRXOJtlNVz"
      },
      "source": [
        "í•„ìš”í•œ ëª¨ë“ˆì„ import í•´ì¤ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGHWGjRnAKuG"
      },
      "source": [
        "import pathlib\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5_6LDnLlQRn"
      },
      "source": [
        "í•™ìŠµíŒ” ë§ë­‰ì¹˜ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.<br/>\n",
        "ì•„ë˜ ì½”ë“œì—ì„œëŠ” ìŠ¤í˜ì¸ì–´ - ì˜ì–´ ë§ë­‰ì¹˜ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUsBQJDAALsO",
        "outputId": "e49e8cc4-fb8f-4098-da88-53b3a2d390c1"
      },
      "source": [
        "text_file = keras.utils.get_file(\n",
        "    fname=\"spa-eng.zip\",\n",
        "    origin=\"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\",\n",
        "    extract=True,\n",
        ")\n",
        "text_file = pathlib.Path(text_file).parent / \"spa-eng\" / \"spa.txt\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "2646016/2638744 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wksDH89elfgW"
      },
      "source": [
        "í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ ì ì ˆíˆ ì „ì²˜ë¦¬ë¥¼ í•´ì¤ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGcHrv5CATZl"
      },
      "source": [
        "with open(text_file) as f:\n",
        "    lines = f.read().split(\"\\n\")[:-1]\n",
        "text_pairs = []\n",
        "for line in lines:\n",
        "    eng, spa = line.split(\"\\t\")\n",
        "    spa = \"[start] \" + spa + \" [end]\"\n",
        "    text_pairs.append((eng, spa))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28DDN1TaleuC"
      },
      "source": [
        "ì „ì²˜ë¦¬ê°€ ì˜ ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤. <br/>\n",
        "ë²ˆì—­ë˜ëŠ” ë¬¸ì¥ì˜ ì•ì—ëŠ” [start] í† í°ì„ ìœ„ì¹˜ì‹œí‚¤ê³  ë’¤ì—ëŠ” [end] í† í°ì„ ìœ„ì¹˜ì‹œí‚µë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fbd1UkphAWU9",
        "outputId": "0f4c8458-fd54-4721-c56c-54461dcc2216"
      },
      "source": [
        "for _ in range(5):\n",
        "    print(random.choice(text_pairs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('You deserve a medal.', '[start] Te mereces una medalla. [end]')\n",
            "(\"Tom doesn't owe me anything.\", '[start] Tom no me debe nada. [end]')\n",
            "('I asked the boy to throw the ball back.', '[start] Le pedÃ­ al niÃ±o que me devolviera la pelota. [end]')\n",
            "('I drank from the tap.', '[start] He bebido del grifo. [end]')\n",
            "('Tom paid way too much for that old car.', '[start] Tom pagÃ³ demasiado por este carro viejo. [end]')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knX0pkeqmRW9"
      },
      "source": [
        "ë°ì´í„°ì…‹ì„ split í•´ì¤ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DX8hVKKAXwe",
        "outputId": "b1139086-ddf0-4934-a927-5986225db5f5"
      },
      "source": [
        "random.shuffle(text_pairs)\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples :]\n",
        "\n",
        "print(f\"{len(text_pairs)} total pairs\")\n",
        "print(f\"{len(train_pairs)} training pairs\")\n",
        "print(f\"{len(val_pairs)} validation pairs\")\n",
        "print(f\"{len(test_pairs)} test pairs\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "118964 total pairs\n",
            "83276 training pairs\n",
            "17844 validation pairs\n",
            "17844 test pairs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cqz8Noz4AZln"
      },
      "source": [
        "strip_chars = string.punctuation + \"Â¿\"\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "vocab_size = 15000\n",
        "sequence_length = 20\n",
        "batch_size = 64\n",
        "\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n",
        "\n",
        "\n",
        "eng_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size, output_mode=\"int\", output_sequence_length=sequence_length,\n",
        ")\n",
        "spa_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "train_eng_texts = [pair[0] for pair in train_pairs]\n",
        "train_spa_texts = [pair[1] for pair in train_pairs]\n",
        "eng_vectorization.adapt(train_eng_texts)\n",
        "spa_vectorization.adapt(train_spa_texts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKfCIzsxAbri"
      },
      "source": [
        "\n",
        "def format_dataset(eng, spa):\n",
        "    eng = eng_vectorization(eng)\n",
        "    spa = spa_vectorization(spa)\n",
        "    return ({\"encoder_inputs\": eng, \"decoder_inputs\": spa[:, :-1],}, spa[:, 1:])\n",
        "\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, spa_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    spa_texts = list(spa_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()\n",
        "\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELNse2GiAdf4",
        "outputId": "ab762b36-f635-4137-f896-bc34a92bf23d"
      },
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (64, 20)\n",
            "inputs[\"decoder_inputs\"].shape: (64, 20)\n",
            "targets.shape: (64, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aVtnel1AfUG"
      },
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super(TransformerEncoder, self).__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n",
        "        attention_output = self.attention(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
        "        )\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim\n",
        "        )\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
        "        super(TransformerDecoder, self).__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
        "        )\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "        return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
        "            axis=0,\n",
        "        )\n",
        "        return tf.tile(mask, mult)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KCsWiekAg72"
      },
      "source": [
        "embed_dim = 256\n",
        "latent_dim = 2048\n",
        "num_heads = 8\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
        "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
        "\n",
        "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "transformer = keras.Model(\n",
        "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxzP6SjtAk9Y",
        "outputId": "c6e8e32a-bb0d-46ea-f6e9-aafef2a91473"
      },
      "source": [
        "epochs = 30  # This should be at least 30 for convergence\n",
        "\n",
        "transformer.summary()\n",
        "transformer.compile(\n",
        "    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "transformer.fit(train_ds, epochs=epochs, validation_data=val_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "positional_embedding (Positiona (None, None, 256)    3845120     encoder_inputs[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "transformer_encoder (Transforme (None, None, 256)    3155456     positional_embedding[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "model_1 (Functional)            (None, None, 15000)  12959640    decoder_inputs[0][0]             \n",
            "                                                                 transformer_encoder[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 19,960,216\n",
            "Trainable params: 19,960,216\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/30\n",
            "1302/1302 [==============================] - 190s 143ms/step - loss: 0.9396 - accuracy: 0.6980 - val_loss: 1.0049 - val_accuracy: 0.6563\n",
            "Epoch 2/30\n",
            "1302/1302 [==============================] - 185s 142ms/step - loss: 0.9190 - accuracy: 0.7064 - val_loss: 1.0081 - val_accuracy: 0.6586\n",
            "Epoch 3/30\n",
            "1302/1302 [==============================] - 185s 142ms/step - loss: 0.9073 - accuracy: 0.7113 - val_loss: 1.0071 - val_accuracy: 0.6586\n",
            "Epoch 4/30\n",
            "1302/1302 [==============================] - 186s 143ms/step - loss: 0.8950 - accuracy: 0.7165 - val_loss: 1.0124 - val_accuracy: 0.6615\n",
            "Epoch 5/30\n",
            "1302/1302 [==============================] - 186s 143ms/step - loss: 0.8838 - accuracy: 0.7215 - val_loss: 1.0151 - val_accuracy: 0.6579\n",
            "Epoch 6/30\n",
            "1302/1302 [==============================] - 185s 142ms/step - loss: 0.8734 - accuracy: 0.7259 - val_loss: 1.0134 - val_accuracy: 0.6610\n",
            "Epoch 7/30\n",
            "1302/1302 [==============================] - 185s 142ms/step - loss: 0.8634 - accuracy: 0.7296 - val_loss: 1.0161 - val_accuracy: 0.6626\n",
            "Epoch 8/30\n",
            "1302/1302 [==============================] - 185s 142ms/step - loss: 0.8523 - accuracy: 0.7339 - val_loss: 1.0164 - val_accuracy: 0.6641\n",
            "Epoch 9/30\n",
            "1302/1302 [==============================] - 185s 142ms/step - loss: 0.8434 - accuracy: 0.7374 - val_loss: 1.0281 - val_accuracy: 0.6624\n",
            "Epoch 10/30\n",
            "1302/1302 [==============================] - 185s 142ms/step - loss: 0.8341 - accuracy: 0.7410 - val_loss: 1.0312 - val_accuracy: 0.6616\n",
            "Epoch 11/30\n",
            "1302/1302 [==============================] - 184s 141ms/step - loss: 0.8244 - accuracy: 0.7445 - val_loss: 1.0317 - val_accuracy: 0.6651\n",
            "Epoch 12/30\n",
            "1302/1302 [==============================] - 185s 142ms/step - loss: 0.8171 - accuracy: 0.7476 - val_loss: 1.0406 - val_accuracy: 0.6653\n",
            "Epoch 13/30\n",
            "1302/1302 [==============================] - 185s 142ms/step - loss: 0.8091 - accuracy: 0.7504 - val_loss: 1.0365 - val_accuracy: 0.6632\n",
            "Epoch 14/30\n",
            " 187/1302 [===>..........................] - ETA: 2:27 - loss: 0.7954 - accuracy: 0.7554"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8oTr__gAmjM"
      },
      "source": [
        "spa_vocab = spa_vectorization.get_vocabulary()\n",
        "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = eng_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = spa_vectorization([decoded_sentence])[:, :-1]\n",
        "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = spa_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence\n",
        "\n",
        "\n",
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "for _ in range(30):\n",
        "    input_sentence = random.choice(test_eng_texts)\n",
        "    translated = decode_sequence(input_sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXmedJR1AG1F"
      },
      "source": [
        "### ì½”ë“œ ì‹¤ìŠµ 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_-WgBYX5-4K"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX26HWbe6Cph"
      },
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_VY_WXJ6FdH"
      },
      "source": [
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvOXtcK76JV8"
      },
      "source": [
        "vocab_size = 20000  # Only consider the top 20k words\n",
        "maxlen = 200  # Only consider the first 200 words of each movie review\n",
        "(x_train, y_train), (x_val, y_val) = keras.datasets.imdb.load_data(num_words=vocab_size)\n",
        "print(len(x_train), \"Training sequences\")\n",
        "print(len(x_val), \"Validation sequences\")\n",
        "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_val = keras.preprocessing.sequence.pad_sequences(x_val, maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py_M438h6OPe"
      },
      "source": [
        "embed_dim = 32  # Embedding size for each token\n",
        "num_heads = 2  # Number of attention heads\n",
        "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
        "\n",
        "inputs = layers.Input(shape=(maxlen,))\n",
        "embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
        "x = embedding_layer(inputs)\n",
        "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "x = transformer_block(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = layers.Dense(20, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y38uKp96TQf"
      },
      "source": [
        "model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "history = model.fit(\n",
        "    x_train, y_train, batch_size=32, epochs=2, validation_data=(x_val, y_val)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb-St9gHFVQX"
      },
      "source": [
        "## 2.GPT, BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8H7r5ROz8rYM"
      },
      "source": [
        "ë‹¤ìŒìœ¼ë¡œ GPTì™€ BERTì— ëŒ€í•´ì„œ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.<br/>\n",
        "\n",
        "GPTì™€ BERTëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ êµ¬ì¡°ë¥¼ ë³€í˜•í•˜ì—¬ ë§Œë“¤ì–´ì§„ ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤.<br/>\n",
        "ë‘ ëª¨ë¸ì€ **ì‚¬ì „ í•™ìŠµëœ ì–¸ì–´ ëª¨ë¸(Pre-trained Language Model)** ì´ë¼ëŠ” ê³µí†µì ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.<br/>\n",
        "ì‚¬ì „ í•™ìŠµì´ë€ ëŒ€ëŸ‰ì˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¯¸ë¦¬ í•™ìŠµí•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ì—¬ê¸°ì— í•„ìš”í•œ ë°ì´í„°ë¥¼ ì¶”ê°€ í•™ìŠµì‹œì¼œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ìµœì í™”í•©ë‹ˆë‹¤.<br/>\n",
        "ì´ëŸ° í•™ìŠµ ë°©ë²•ì„ ì „ì´ í•™ìŠµ(Transfer Learning)ì´ë¼ê³ ë„ í•©ë‹ˆë‹¤.<br/>\n",
        "ìµœê·¼ ë°œí‘œë˜ê³  ìˆëŠ” ì–¸ì–´ ëª¨ë¸ì€ ëª¨ë‘ ì „ì´ í•™ìŠµì„ ì ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yz7HMOrtGwJD"
      },
      "source": [
        "### GPT (2018.6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aiUjhboTxmy"
      },
      "source": [
        "<img width=\"300\" alt=\"Linear_Softmax\" src=\"https://openai.com/content/images/2019/05/openai-cover.png\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZdn1m3mTy87"
      },
      "source": [
        "**GPT**ëŠ” **G**enerative **P**re-trained **T**ransformer ì˜ ì•½ìë¡œ 2018ë…„ 6ì›”ì— OpenAIë¥¼ í†µí•´ ë°œí‘œë˜ì—ˆìŠµë‹ˆë‹¤.<br/>\n",
        "ì—°ì´ì–´ ë°œí‘œí•œ GPT-2(2019.2), GPT-3(2020.6)ê°€ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ë©´ì„œ ì„¸ê°„ì˜ ì£¼ëª©ì„ ë°›ì•˜ìŠµë‹ˆë‹¤.<br/>\n",
        "ì•„ë˜ëŠ” ê´€ë ¨ ê¸°ì‚¬ì´ë‹ˆ ì„¸ì…˜ì´ ëë‚˜ê³  ì¶”ê°€ì ìœ¼ë¡œ ì½ì–´ë³´ì‹œë©´ ì¢‹ê² ìŠµë‹ˆë‹¤. \n",
        "\n",
        "- ì‹¬í™”ë‚´ìš© : Generativeë€? (ë‹¹ì¥ì€ ì´í•´í•˜ì§€ ëª»í•˜ì…”ë„ ì¢‹ìŠµë‹ˆë‹¤) - [discriminative vs generative](https://ratsgo.github.io/generative%20model/2017/12/17/compare/)\n",
        "\n",
        "- GPT2 ê¸°ì‚¬\n",
        "    - [The AI that was too dangerous to release](https://blog.floydhub.com/gpt2/)\n",
        "    - [OpenAI, ê³µìœ í•˜ê¸°ì—ëŠ” ë„ˆë¬´ ìœ„í—˜í•œ â€˜í…ìŠ¤íŠ¸ ìƒì„± AIâ€™ì˜ ì§„ì‹¤](http://www.aitimes.com/news/articleView.html?idxno=121589)\n",
        "\n",
        "- GPT3 ê¸°ì‚¬\n",
        "    - [A GPT-3 bot posted comments on Reddit for a week and no one noticed](https://www.technologyreview.com/2020/10/08/1009845/a-gpt-3-bot-posted-comments-on-reddit-for-a-week-and-no-one-noticed/)\n",
        "    - [GPT3ê°€ ì“´ ë‰´ìŠ¤ê°€ ë­í‚¹ 1ìœ„, ì‚¬ëŒì„ ì´ê²¼ë‹¤](http://www.aitimes.com/news/articleView.html?idxno=131593)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqhHhR8r8NLF"
      },
      "source": [
        "GPT-1, GPT-2, GPT-3 ì˜ êµ¬ì¡°ê°€ ì „ë¶€ ë™ì¼í•˜ì§€ëŠ” ì•Šì§€ë§Œ ê¸°ë³¸ì ì¸ ë¼ˆëŒ€ëŠ” ë™ì¼í•©ë‹ˆë‹¤.\n",
        "\n",
        "GPTì˜ êµ¬ì¡°ë¥¼ ë³¸ê²©ì ìœ¼ë¡œ ì•Œì•„ë³´ê¸°ì— ì•ì„œ ê¸°ë³¸ì´ ë˜ëŠ” ì•„ì´ë””ì–´ì¸ **ì‚¬ì „ í•™ìŠµ(Pre-training)**ì— ëŒ€í•´ì„œ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIvqSVD4wMnW"
      },
      "source": [
        "- **ì‚¬ì „ í•™ìŠµëœ ì–¸ì–´ ëª¨ë¸ (Pre-trained LM)**\n",
        "\n",
        "í˜¹ì‹œ ì•„ë˜ì™€ ê°™ì€ ì¼€ì´ìŠ¤ë¥¼ ë³¸ ì  ìˆìœ¼ì‹ ê°€ìš”?\n",
        "\n",
        "<img width=\"500\" alt=\"pre-train\" src=\"https://user-images.githubusercontent.com/45377884/112774307-3e413900-9074-11eb-94ab-f3bc000ff95e.png\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkf1OJv6U8Gq"
      },
      "source": [
        "ìˆ˜ëŠ¥ êµ­ì–´ ì‹œí—˜ì—ì„œ ì±…ì„ ë§ì´ ì½ì€ í•™ìƒì€ ì¡°ê¸ˆë§Œ ê³µë¶€í•´ë„ ìƒìœ„ê¶Œ ì„±ì ì„ ìœ ì§€í•˜ëŠ” ê²½ìš°ê°€ ì¢…ì¢… ìˆìŠµë‹ˆë‹¤.<br/> GPTì—ì„œ ì‚¬ìš©ëœ **ì‚¬ì „ í•™ìŠµ**ì´ë¼ëŠ” ì•„ì´ë””ì–´ë„ ìœ ì‚¬í•œ ìƒê°ì—ì„œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.<br/>ì•„ë˜ ê·¸ë¦¼ì„ ë³´ë©° ì‚¬ì „ í•™ìŠµ ì–¸ì–´ ëª¨ë¸ì— ëŒ€í•´ì„œ ì„¤ëª…ì„ ì´ì–´ë‚˜ê°€ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ue0QaxvK63RP"
      },
      "source": [
        "<img width=\"700\" alt=\"Pre-training\" src=\"https://user-images.githubusercontent.com/45377884/112943247-35cc2980-916c-11eb-99be-2fa7657507d2.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSoHE5F8U-d2"
      },
      "source": [
        "ì‚¬ì „ í•™ìŠµ ì–¸ì–´ ëª¨ë¸ì€ í¬ê²Œ 2ê°€ì§€ ê³¼ì •ì„ í†µí•´ ì™„ì„±ë©ë‹ˆë‹¤. ì²« ë²ˆì§¸ê°€ **ì‚¬ì „ í•™ìŠµ(Pre-training)**ì…ë‹ˆë‹¤. \n",
        "\n",
        "ì¡´ì¬í•˜ëŠ” ìì—°ì–´ ì¤‘ì—ëŠ” ì±…(Book corpus)ì´ë‚˜ ìœ„í‚¤í”¼ë””ì•„(Wiki corpus) ë“± ë ˆì´ë¸”ë§ ë˜ì§€ ì•Šì€ ë°ì´í„°ê°€ ë” ë§ìŠµë‹ˆë‹¤.<br/>\n",
        "ì—¬ëŸ¬ë¶„ì´ ì§€ê¸ˆ ì½ê³  ìˆëŠ” ê°•ì˜ ë…¸íŠ¸ ì—­ì‹œ ë ˆì´ë¸”ë§ ë˜ì§€ ì•Šì€ ìì—°ì–´ ë°ì´í„° ì…ë‹ˆë‹¤.<br/>\n",
        "ì±…ì„ ë§ì´ ì½ëŠ” ê²ƒì²˜ëŸ¼ ë ˆì´ë¸”ë§ ë˜ì§€ ì•Šì€ ë°ì´í„°ë¥¼ ëª¨ë¸ì´ í•™ìŠµí•˜ë„ë¡ í•˜ëŠ” ê³¼ì •ì„ **ì‚¬ì „ í•™ìŠµ** ì´ë¼ê³  í•©ë‹ˆë‹¤.\n",
        "\n",
        "ì‚¬ì „ í•™ìŠµì´ ëë‚œ ëª¨ë¸ì— ìš°ë¦¬ê°€ í•˜ê³ ìí•˜ëŠ” íƒœìŠ¤í¬ì— íŠ¹í™”ëœ(Task specific) ë°ì´í„°ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.<br/>\n",
        "ì´ë¥¼ **Fine-tuning** ì´ë¼ê³  í•©ë‹ˆë‹¤.<br/> Fine-tuningì—ì„œëŠ” í•™ìŠµì‹œ ë ˆì´ë¸”ë§ ëœ ë°ì´í„° [Ex) ê°ì„± ë¶„ì„, ìì—°ì–´ ì¶”ë¡ (NLI), ì§ˆì˜ ì‘ë‹µ(QA)] ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4zkV_8d6TbJ"
      },
      "source": [
        "- **ëª¨ë¸ êµ¬ì¡° (ê·¸ë¦¼ì€ 6ê°œì˜ ë””ì½”ë” ë¸”ë¡ì„ ì‚¬ìš©í•˜ì§€ë§Œ GPTëŠ” 12ê°œì˜ ë¸”ë¡ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.)**\n",
        "\n",
        "<img width=\"700\" alt=\"Pre-training\" src=\"http://jalammar.github.io/images/xlnet/transformer-decoder-intro.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1N5Jgrt9GNx"
      },
      "source": [
        "GPTì—ì„œëŠ” ì¸ì½”ë”ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ë””ì½”ë” ë¸”ë¡ë‚´ì— **2ê°œì˜ Sub-layer**ë§Œ ìˆìŠµë‹ˆë‹¤.<br/>\n",
        "íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ë””ì½”ë” ë¸”ë¡ì—ëŠ” Masked Self-Attention, Encoder-Decoder Attention, Feed-Forward ì¸µì´ ìˆì—ˆìŠµë‹ˆë‹¤.<br/>\n",
        "í•˜ì§€ë§Œ GPTëŠ” ì¸ì½”ë”ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— Encoder-Decoder Attention ì¸µì´ ë¹ ì§€ê²Œ ë©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqFHif7m8vR8"
      },
      "source": [
        "- **ì‚¬ì „ í•™ìŠµ(Pre-training)**\n",
        "\n",
        "ë ˆì´ë¸”ë§ ë˜ì§€ ì•Šì€ ëŒ€ëŸ‰ì˜ ë§ë­‰ì¹˜ $U = (u_1, \\cdots , u_n)$ ì— ëŒ€í•´ ë¡œê·¸ ìš°ë„ $L_1$ ì„ ìµœëŒ€í™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµë©ë‹ˆë‹¤.<br/>\n",
        "ì§€ë‚œ ë…¸íŠ¸ì—ì„œ ë°°ì› ë˜ ì–¸ì–´ ëª¨ë¸ì²˜ëŸ¼ ë‹¤ìŒì— ì˜¬ ë‹¨ì–´ë¥¼ ê³„ì†í•´ì„œ ë§ì¶”ëŠ” ë°©ì‹ìœ¼ë¡œ í•™ìŠµí•©ë‹ˆë‹¤.\n",
        "\n",
        "$$\n",
        "L_1(U) = \\sum_i \\log P(u_i \\vert u_{i-k}, \\cdots, u_{i-1}; \\Theta)\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOjb7lmd96FT"
      },
      "source": [
        "- **Fine-tuning**\n",
        "\n",
        "ê¸°ì¡´ ëª¨ë¸ì—ì„œëŠ” íƒœìŠ¤í¬ì— ë§ì¶° ëª¨ë¸ êµ¬ì¡°ë¥¼ ë³€ê²½í•´ì£¼ê³  í•™ìŠµì„ ì§„í–‰ì‹œì¼°ìŠµë‹ˆë‹¤.\n",
        "\n",
        "í•˜ì§€ë§Œ GPTì™€ ê°™ì€ ì‚¬ì „ í•™ìŠµ ì–¸ì–´ ëª¨ë¸ì€ Fine-tuning ê³¼ì •ì—ì„œ ë°ì´í„°ì˜ ì…ë ¥ ë°©ì‹ë§Œì„ ë³€í˜•ì‹œí‚¤ê³  ëª¨ë¸ êµ¬ì¡°ëŠ” ì¼ì •í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_0mywdu-ydy"
      },
      "source": [
        "<img width=\"600\" alt=\"fine-tune_structure\" src=\"https://user-images.githubusercontent.com/45377884/112949500-408abc80-9174-11eb-8090-4f0be34db572.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KKJNSrp-0Uk"
      },
      "source": [
        "\n",
        "Fine-tuningì€ ë ˆì´ë¸”ë§ ëœ ë§ë­‰ì¹˜ $C = (x_1, \\cdots , x_m)$ ì— ëŒ€í•˜ì—¬ ë¡œê·¸ ìš°ë„ $L_2$ ë¥¼ ìµœëŒ€í™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµí•©ë‹ˆë‹¤.\n",
        "\n",
        "$$\n",
        "L_2(C) = \\sum_{(x,y)} \\log P(y \\vert x_1, \\cdots , x_m)\n",
        "$$\n",
        "\n",
        "GPTì˜ ê²½ìš° Fine-tuningì—ì„œ í•™ìŠµí•˜ëŠ” ë°ì´í„°ì…‹ì´ í´ ë•ŒëŠ” ë³´ì¡° ëª©ì í•¨ìˆ˜ë¡œ $L_1$ ì„ ì¶”ê°€í•˜ì—¬ $L_3$ë¡œ í•™ìŠµí•˜ë©´ í•™ìŠµì´ ë” ì˜ ì§„í–‰ë©ë‹ˆë‹¤.\n",
        "\n",
        "$$\n",
        "L_3(C) = L_2(C) + \\lambda \\cdot L_1(C)\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8E47CeLkDkb-"
      },
      "source": [
        "- **ê²°ê³¼ & ê²°ë¡ **\n",
        "\n",
        "LSTM, GRUë¥¼ ì‚¬ìš©í•œ ê¸°ì¡´ ëª¨ë¸ë³´ë‹¤ ìì—°ì–´ ì¶”ë¡ (NLI), ì§ˆì˜ ì‘ë‹µ(QA), ë¶„ë¥˜(Classification) ë“±ì˜ íƒœìŠ¤í¬ì—ì„œ ë†’ì€ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ì˜€ìŠµë‹ˆë‹¤.<br/>GPTëŠ” ì‚¬ì „ í•™ìŠµëœ ì–¸ì–´ ëª¨ë¸ì„ ë°”íƒ•ìœ¼ë¡œ ì¢‹ì€ ì„±ëŠ¥ì„ í™•ë³´í•  ìˆ˜ ìˆë‹¤ëŠ” ì ê³¼ ì‚¬ì „ í•™ìŠµ ëª¨ë¸ì— Transformer êµ¬ì¡°ê°€ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì„ì„ ì•Œ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aHDyu6nq5ir"
      },
      "source": [
        "### BERT (2018.10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6PsrQKgAmyz"
      },
      "source": [
        "<img width=\"600\" alt=\"model_name\" src=\"https://user-images.githubusercontent.com/45377884/112963631-88184500-9182-11eb-8c87-f470e25d7567.png\">\n",
        "\n",
        "> [ë‹¤ì–‘í•œ ìºë¦­í„° ì´ë¦„ì„ ë”´ NLP ëª¨ë¸](https://towardsdatascience.com/machine-learnings-obsession-with-kids-tv-show-characters-728edfb43b3c) : ì¬ë¯¸(?)ë¡œ ì½ì–´ë³´ì„¸ìš” :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWjBLUwWAoay"
      },
      "source": [
        "**BERT**(**B**idirectional **E**ncoder **R**epresentation by **T**ransformer)ëŠ” 2018ë…„ 10ì›” êµ¬ê¸€ì—ì„œ ë°œí‘œí•œ ëª¨ë¸ì…ë‹ˆë‹¤.\n",
        "\n",
        "ëª¨ë¸ ì´ë¦„ì—ì„œ ì•Œ ìˆ˜ ìˆë“¯ BERTëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ì¸ì½”ë”ë§Œì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ë§¥ì„ ì–‘ë°©í–¥(Bidirectional)ìœ¼ë¡œ ì½ì–´ëƒ…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJV0Z4s3dn1a"
      },
      "source": [
        "- **BERTì˜ êµ¬ì¡°**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wo4epFbAqp7"
      },
      "source": [
        "GPTê°€ íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ë””ì½”ë” ë¸”ë¡ì„ 12ê°œ ìŒ“ì•„ì˜¬ë¦° ëª¨ë¸ì´ì—ˆë‹¤ë©´ **BERTëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ì¸ì½”ë” ë¸”ë¡**ì„ 12ê°œ ìŒ“ì•„ì˜¬ë¦° ëª¨ë¸ì…ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpUIL_WuAspc"
      },
      "source": [
        "<img width=\"500\" alt=\"model_name\" src=\"http://jalammar.github.io/images/bert-base-bert-large-encoders.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kKMKIVO50Ja"
      },
      "source": [
        "- **BERTì˜ Special Token ([CLS], [SEP])ê³¼ ì…ë ¥ ë²¡í„°ë¥¼ ì•Œì•„ë´…ì‹œë‹¤**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqTvtPuU7QVa"
      },
      "source": [
        "ì´ë²ˆì—ëŠ” BERTì—ë§Œ ìˆëŠ” íŠ¹ë³„í•œ í† í°ê³¼ ì´ì— ë”°ë¼ ì…ë ¥ë˜ëŠ” ë²¡í„°ê°€ ì–´ë–»ê²Œ êµ¬ì„±ë˜ëŠ” ì§€ì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64f6K2PS7B8x"
      },
      "source": [
        "<img width=\"600\" alt=\"bert_input\" src=\"https://imgur.com/iW77E5Q.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5km_XLzr8Pjr"
      },
      "source": [
        "1. Special Token : **`[CLS]`**, **`[SEP]`**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFWF0U2CEGyo"
      },
      "source": [
        "BERTì—ëŠ” **`[CLS]`**ì™€ **`[SEP]`**ì´ë¼ëŠ” ë‘ ê°€ì§€ Special Tokenì´ ìˆìŠµë‹ˆë‹¤.<br/>\n",
        "\n",
        "> **`[CLS]`** : Classification <br/>\n",
        "\n",
        "[CLS] í† í°ì€ ì…ë ¥ì˜ ë§¨ ì•ì— ìœ„ì¹˜í•˜ëŠ” í† í°ì…ë‹ˆë‹¤.<br/>\n",
        "ì•„ë˜ì—ì„œ ë“±ì¥í•  NSP(Next Sentence Prediction)ì´ë¼ëŠ” í•™ìŠµì„ ìœ„í•´ ì¡´ì¬í•©ë‹ˆë‹¤.\n",
        "\n",
        "> **`[SEP]`** : Separation <br/>\n",
        "\n",
        "BERTëŠ” ì‚¬ì „ í•™ìŠµ ì‹œì— í…ìŠ¤íŠ¸ë¥¼ 2ë¶€ë¶„ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ë„£ê²Œ ë©ë‹ˆë‹¤.<br/>\n",
        "**`[SEP]`** í† í°ì€ ì²« ë²ˆì§¸ ë¶€ë¶„ì˜ ëìë¦¬ì™€ ë‘ ë²ˆì§¸ ë¶€ë¶„ì˜ ëìë¦¬ì— ìœ„ì¹˜í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dC2GjhtsJDMS"
      },
      "source": [
        "<img width=\"600\" alt=\"bert_input\" src=\"https://imgur.com/iW77E5Q.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6ci4mylGvJH"
      },
      "source": [
        "2. Input Vector : Token Embeddings, Segment Embeddings, Position Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5ew-0NMG5fl"
      },
      "source": [
        "BERTëŠ” 3ì¢…ë¥˜ì˜ ì„ë² ë”© ë²¡í„°ë¥¼ ëª¨ë‘ ë”í•˜ì—¬ ëª¨ë¸ì— ì…ë ¥í•©ë‹ˆë‹¤.\n",
        "\n",
        "- Token Embeddings : ë‹¨ì–´ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì„ë² ë”©ì…ë‹ˆë‹¤. Word2Vec, GloVe, FastText ë“±ìœ¼ë¡œ ì‚¬ì „ í•™ìŠµëœ ì„ë² ë”© ë²¡í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.<br/>\n",
        "- Segment Embeddings : ì²« ë²ˆì§¸ ë¶€ë¶„ê³¼ ë‘ ë²ˆì§¸ ë¶€ë¶„ì„ êµ¬ë¶„í•˜ê¸° ìœ„í•œ ì„ë² ë”©ì…ë‹ˆë‹¤.<br/>**`[CLS]`** ë¶€í„° ì²« ë²ˆì§¸ **`[SEP]`** ê¹Œì§€ ë™ì¼í•œ ë²¡í„°ë¥¼ ì ìš©í•˜ê³ , ë‹¤ìŒ í† í°ë¶€í„° ë‘ ë²ˆì§¸ **`[SEP]`** ê¹Œì§€ ë™ì¼í•œ ë²¡í„°ë¥¼ ì ìš©í•©ë‹ˆë‹¤.\n",
        "- Positional Embeddings : ë‹¨ì–´ì˜ ìœ„ì¹˜ë¥¼ ë‚˜íƒ€ë‚´ê¸° ìœ„í•œ ì„ë² ë”©ì…ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGnMfe2efIMd"
      },
      "source": [
        "- **BERTì˜ ì‚¬ì „ í•™ìŠµ(Pre-training) ë°©ë²•ë“¤**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx9sXm0F5-tU"
      },
      "source": [
        "BERT ì—­ì‹œ Pre-trained Language Modelì´ê¸° ë•Œë¬¸ì— ì‚¬ì „ í•™ìŠµ ì´í›„ì— Fine-tuningì„ ì§„í–‰í•˜ê²Œ ë©ë‹ˆë‹¤.<br/>\n",
        "ì•„ë˜ì—ì„œëŠ” BERTì˜ ì‚¬ì „ í•™ìŠµ ë°©ì‹ì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.<br/>\n",
        "BERTëŠ” GPTì™€ ë‹¤ë¥¸ ë°©ì‹ì˜ ì‚¬ì „ í•™ìŠµì´ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.<br/>\n",
        "BERTì˜ ì‚¬ì „ í•™ìŠµì—ì„œ ì‚¬ìš©ë˜ëŠ” **2ê°€ì§€ ë°©ë²•(MLM, NSP)**ì„ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEIRSx5vV_Pt"
      },
      "source": [
        "> **MLM(Masked Language Model)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RHHJKmVBrJV"
      },
      "source": [
        "ì²« ë²ˆì§¸ëŠ” MLM(Masked Language Model) ì…ë‹ˆë‹¤. í˜¹ì‹œ ì•„ë˜ì™€ ê°™ì€ ë¬¸ì œë¥¼ í’€ì–´ë³´ì‹  ê²½í—˜ì´ ìˆìœ¼ì‹ ê°€ìš”?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAkoYiM-Bsmu"
      },
      "source": [
        "<img width=\"300\" alt=\"mlm\" src=\"https://thumb.mt.co.kr/06/2013/11/2013110718224659109_1.jpg/dims/optimize/\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40WZ-DudWEva"
      },
      "source": [
        "ì˜ì–´ ì‹œí—˜ì„ í•œ ë²ˆì¯¤ ì¤€ë¹„í•´ë³´ì‹  ë¶„ì´ë¼ë©´ ë¹ˆì¹¸ ì±„ìš°ê¸° ìœ í˜• ë¬¸ì œë¥¼ í’€ì–´ë³´ì‹  ì ì´ ìˆì„ ê²ƒì…ë‹ˆë‹¤.<br/>\n",
        "ìœ„ì™€ ê°™ì€ ë¬¸ì œì—ì„œ ë³´í†µì€ ë¹ˆì¹¸ì— ë¬¸ë²•ì /ì˜ë¯¸ì ìœ¼ë¡œ ì˜¬ë°”ë¥¸ ë‹¨ì–´ë¥¼ ì±„ìš°ê²Œ ë©ë‹ˆë‹¤.\n",
        "\n",
        "BERTë„ ì´ì²˜ëŸ¼ **ë¹ˆì¹¸ ì±„ìš°ê¸°**ë¥¼ í•˜ë©´ì„œ ë‹¨ì–´ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.<br/>\n",
        "BERTëŠ” ì‚¬ì „ í•™ìŠµ ê³¼ì •ì—ì„œ ë ˆì´ë¸”ë§ ë˜ì§€ ì•Šì€ ë§ë­‰ì¹˜ ì¤‘ì—ì„œ ëœë¤ìœ¼ë¡œ 15\\%ê°€ëŸ‰ì˜ ë‹¨ì–´ë¥¼ ë§ˆìŠ¤í‚¹í•©ë‹ˆë‹¤.<br/>\n",
        "ê·¸ë¦¬ê³  ë§ˆìŠ¤í‚¹ëœ ìœ„ì¹˜ì— ì›ë˜ ìˆë˜ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGQkOv6YWJjB"
      },
      "source": [
        "<img width=\"600\" alt=\"mlm_example\" src=\"http://jalammar.github.io/images/BERT-language-modeling-masked-lm.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFqu5WuaDgJY"
      },
      "source": [
        "MLMì€ ì–‘ìª½ì˜ ë¬¸ë§¥ì„ ë™ì‹œì— ë³¼ ìˆ˜ ìˆë‹¤ëŠ” ì¥ì ì´ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì•„ë˜ ê·¸ë¦¼ì€ GPTì™€ BERTì˜ í•™ìŠµ ë°©í–¥ì„ ë¹„êµí•˜ì—¬ ë‚˜íƒ€ë‚¸ ê·¸ë¦¼ì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a3g9iZEDkg-"
      },
      "source": [
        "<img width=\"300\" alt=\"gpt_vs_bert\" src=\"https://user-images.githubusercontent.com/45377884/113259927-a445ee80-9308-11eb-8fbd-95d5f553480a.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTT-rlIaDlw7"
      },
      "source": [
        "GPTëŠ” ***'ê±°ê¸°'*** ë¼ëŠ” ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•  ë•Œ 'ì–´ì œ ì¹´í˜ ê°”ì—ˆì–´'ì˜ ì •ë³´ë§Œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.<br/>\n",
        "í•˜ì§€ë§Œ BERTëŠ” ë¹ˆì¹¸ì— ë“¤ì–´ê°ˆ ***'ê±°ê¸°'*** ë¼ëŠ” ë‹¨ì–´ë¥¼ ì˜ˆì¸¡ í•  ë•Œ 'ì–´ì œ ì¹´í˜ ê°”ì—ˆì–´'ë¿ë§Œ ì•„ë‹ˆë¼ 'ì‚¬ëŒ ë§ë”ë¼'ì˜ ì •ë³´ë„ ì°¸ê³ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.<br/>\n",
        "ì´ë ‡ê²Œ ì–‘ë°©í–¥ìœ¼ë¡œ í•™ìŠµí•  ê²½ìš° ë‹¨ì–´ê°€ ë¬¸ë§¥ ì‚¬ì´ì—ì„œ ê°€ì§„ ì˜ë¯¸ë¥¼ ìµœëŒ€ë¡œ í•™ìŠµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "MLMì€ ë‹¤ì†Œ ê°„ë‹¨í•œ ì•„ì´ë””ì–´ì´ì§€ë§Œ ë‹¨ì–´ì˜ ë¬¸ë§¥ì  ì˜ë¯¸ë¥¼ ìµœëŒ€ë¡œ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ í•¨ìœ¼ë¡œì¨ BERTê°€ ë†’ì€ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ëŠ” ë°ì— ì»¤ë‹¤ë€ ì—­í• ì„ í•˜ì˜€ìŠµë‹ˆë‹¤.<br/>ë‹¤ìŒìœ¼ë¡œ 2ë²ˆì§¸ ë°©ë²•ì¸ NSPì— ëŒ€í•´ì„œ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JmCxVxFWB4d"
      },
      "source": [
        "> **NSP(Next Sentence Prediction)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6Xt904dG11P"
      },
      "source": [
        "BERTëŠ” NSP(Next Sentence Prediction) ë°©ì‹ìœ¼ë¡œë„ í•™ìŠµí•©ë‹ˆë‹¤. ë™ë¬¸ì„œë‹µì´ë¼ëŠ” ì‚¬ìì„±ì–´ ì•Œê³  ê³„ì‹ ê°€ìš”?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVdPbkU2G6uG"
      },
      "source": [
        "<img width=\"350\" alt=\"nsp_idea\" src=\"https://thx.sfo2.cdn.digitaloceanspaces.com/wr/hanja_images/%E6%9D%B1%E5%95%8F%E8%A5%BF%E7%AD%94_800.jpg\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEcsClhSXw95"
      },
      "source": [
        "NSPëŠ” ëª¨ë¸ì´ ë¬¸ë§¥ì— ë§ëŠ” ì´ì•¼ê¸°ë¥¼ í•˜ëŠ”ì§€ ì•„ë‹ˆë©´ ë™ë¬¸ì„œë‹µì„ í•˜ëŠ”ì§€ë¥¼ íŒë‹¨í•˜ë©° í•™ìŠµí•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.<br/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMJ0csCoIJSn"
      },
      "source": [
        "ìœ„ì—ì„œ ì•Œì•„ë³¸ **`[SEP]`** í† í° ì™¼ìª½ì˜ ë¬¸ì¥ê³¼ ì˜¤ë¥¸ìª½ì˜ ë¬¸ì¥ì´ ë°”ë¡œ ì´ì–´ì§€ëŠ” ë¬¸ì¥ì¼ ê²½ìš° **`[CLS]`** í† í°ì˜ ì¶œë ¥ì´ **`IsNext`** ë¡œ ë˜ë„ë¡ í•™ìŠµí•©ë‹ˆë‹¤.<br/> \n",
        "ë‘ ë¬¸ì¥ì´ ì´ì–´ì§€ì§€ ì•ŠëŠ” ìŒì¼ ê²½ìš°ì—ëŠ” ì¶œë ¥ ë²¡í„°ê°€ **`NotNext`** ë¡œ ë‚˜ì˜¤ë„ë¡ í•™ìŠµí•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwnji699X1LR"
      },
      "source": [
        "<img width=\"500\" alt=\"nsp_1\" src=\"http://jalammar.github.io/images/bert-next-sentence-prediction.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtNsNQHFInjv"
      },
      "source": [
        "ì•„ë˜ëŠ” ë“œë¼ë§ˆ ëŒ€ë³¸ì„ ì˜ˆì‹œë¡œ NSPê°€ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ” ì§€ë¥¼ ë‚˜íƒ€ë‚¸ ê·¸ë¦¼ì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id8g1fpoX-yl"
      },
      "source": [
        "<img width=\"500\" alt=\"nsp_2\" src=\"https://user-images.githubusercontent.com/45377884/86514846-d0067780-be4f-11ea-9809-c3e43b8ad3f9.png\">     \n",
        "\n",
        "<img width=\"500\" alt=\"nsp_3\" src=\"https://user-images.githubusercontent.com/45377884/86514847-d137a480-be4f-11ea-82be-d229bf75fbf8.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrXfjo2MX4RZ"
      },
      "source": [
        "NSP ì—­ì‹œ ê°„ë‹¨í•œ ì•„ì´ë””ì–´ì…ë‹ˆë‹¤.<br/>\n",
        "ëª¨ë¸ì´ ë¬¸ì¥ê³¼ ë¬¸ì¥ ì‚¬ì´ì˜ ê´€ê³„ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ í•¨ìœ¼ë¡œì¨ ì§ˆì˜ì‘ë‹µ(QA), ìì—°ì–´ ì¶”ë¡ (NLI) ë“±,<br/>\n",
        "ë¬¸ì¥ ê´€ê³„ë¥¼ ì´í•´í•´ì•¼ë§Œ í•˜ëŠ” ë³µì¡í•œ íƒœìŠ¤í¬ì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚˜íƒ€ë‚´ëŠ” ì—­í• ì„ í•˜ì˜€ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8sUh3xCxv_U"
      },
      "source": [
        "- **Fine-tuning**\n",
        "\n",
        "BERT ì—­ì‹œ ëª¨ë¸ì˜ êµ¬ì¡°ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€í•œ ì±„ ë°ì´í„°ë¥¼ ì…ë ¥í•˜ëŠ” í˜•íƒœë§Œ ë°”ê¾¸ì–´ì„œ Fine-tuningì„ ì‹¤ì‹œí•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6cB2PLbMZc9"
      },
      "source": [
        "<img width=\"700\" alt=\"nsp_2\" src=\"http://jalammar.github.io/images/bert-tasks.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYDed3TaYB_c"
      },
      "source": [
        "(a)ëŠ” â€œSentenceâ€ ìŒì„ ë¶„ë¥˜í•˜ëŠ” íƒœìŠ¤í¬ì…ë‹ˆë‹¤. `[SEP]`ìœ¼ë¡œ ë‚˜ëˆ ì§„ â€œSentenceâ€ ìŒì„ ì…ë ¥ë°›ì•„ `[CLS]`ê°€ ì¶œë ¥í•˜ëŠ” í´ë˜ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
        "\n",
        "(b)ëŠ” ê°ì„±ë¶„ì„ ë“± í•˜ë‚˜ì˜ ë¬¸ì¥ì„ ì…ë ¥í•˜ì—¬ `[CLS]`ë¡œ í•´ë‹¹ ë¬¸ì¥ì„ ë¶„ë¥˜í•˜ëŠ” íƒœìŠ¤í¬ì…ë‹ˆë‹¤.\n",
        "\n",
        "(c)ëŠ” ì§ˆì˜ ì‘ë‹µ íƒœìŠ¤í¬ì…ë‹ˆë‹¤. ì§ˆë¬¸ê³¼ ë³¸ë¬¸ì— í•´ë‹¹í•˜ëŠ” ë‹¨ë½ì„ `[SEP]` í† í°ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì…ë ¥í•˜ë©´ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì„ ì¶œë ¥í•˜ë„ë¡ í•©ë‹ˆë‹¤.\n",
        "\n",
        "(d)ëŠ” í’ˆì‚¬ íƒœê¹…(POS tagging)ì´ë‚˜ ê°œì²´ëª… ì¸ì‹(Named Entity Recognition, NER) ë“±ì˜ íƒœìŠ¤í¬ì…ë‹ˆë‹¤. ì…ë ¥ë°›ì€ ê° í† í°ë§ˆë‹¤ ë‹µì„ ì¶œë ¥í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc45Gcc80eXj"
      },
      "source": [
        "- **ê²°ê³¼ & ê²°ë¡ **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i70diS5cMfR2"
      },
      "source": [
        "BERTëŠ” ê°„ë‹¨í•œ ì‚¬ì „ í•™ìŠµ ì•„ì´ë””ì–´ë¡œ ë§ì€ íƒœìŠ¤í¬ì—ì„œ SOTAë¥¼ ë‹¬ì„±í•˜ì˜€ìŠµë‹ˆë‹¤.<br/>ë‹¨ìˆœí•œ ì•„ì´ë””ì–´ë¥¼ í†µí•´ ì—„ì²­ë‚œ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ì˜€ê¸°ì— ë‹¹ì‹œ ë§ì€ ì¶©ê²©ì„ ì£¼ì—ˆìŠµë‹ˆë‹¤. ì´í›„ë¡œë„ BERTë¥¼ ê°œì„ í•˜ê¸° ìœ„í•œ ì—°êµ¬ê°€ ë§ì´ ì§„í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "íŠ¹íˆ MLMì„ í†µí•´ BERTê°€ ì¢‹ì€ ì„±ëŠ¥ì„ ë‹¬ì„±í•œ ë’¤ë¡œ í…ìŠ¤íŠ¸ì— ë…¸ì´ì¦ˆë¥¼ ì¤€ í›„ì— ì´ë¥¼ ë‹¤ì‹œ ë§ì¶”ëŠ”(Denoising) ë°©ë²•ì— ëŒ€í•´ ë§ì€ ì—°êµ¬ê°€ ì§„í–‰ë˜ì—ˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gweObbaTGpqX"
      },
      "source": [
        "## 3. Post BERT (ìµœê·¼ NLP ì—°êµ¬ ë°©í–¥ì— ëŒ€í•´ì„œ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FfDoAT7Neng"
      },
      "source": [
        "### 1) ë” í° ëª¨ë¸ ë§Œë“¤ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQLXjCffdLj9"
      },
      "source": [
        "<img width=\"700\" alt=\"getting_bigger\" src=\"https://www.microsoft.com/en-us/research/uploads/prod/2020/02/TurningNGL_Model__1400x788.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caGYeYHZdN3Z"
      },
      "source": [
        "GPT(2018.6)ì™€ BERT(2018.10) ì´í›„ë¡œë„ ìˆ˜ë§ì€ ëª¨ë¸ì´ ë°œí‘œë˜ì–´ ì™”ìŠµë‹ˆë‹¤.<br/>\n",
        "ë‘ ëª¨ë¸ ì´í›„ë¡œ ë°œí‘œë˜ê³  ìˆëŠ” ëª¨ë¸ì˜ ì£¼ìš” ê²½í–¥ì„± ì¤‘ í•˜ë‚˜ëŠ” **ëª¨ë¸ í¬ê¸° í‚¤ìš°ê¸°** ì…ë‹ˆë‹¤.<br/>\n",
        "ìœ„ ê·¸ë¦¼ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯  GPT ì™€ BERTì´í›„ ë°œí‘œë˜ëŠ” ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„° ìˆ˜ëŠ” ê¸°í•˜ê¸‰ìˆ˜ì ìœ¼ë¡œ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "íŠ¹íˆ 2020ë…„ 6ì›”ì— ë°œí‘œëœ GPT-3ì˜ íŒŒë¼ë¯¸í„° ê°œìˆ˜ëŠ” ì•½ 1750ì–µ ê°œë¡œ ìœ„ ê·¸ë¦¼ì— ë‚˜ì™€ìˆëŠ” T-NLGë³´ë‹¤ë„ 10ë°°ë‚˜ ë§ìŠµë‹ˆë‹¤.<br/>\n",
        "ë§ì€ ëª¨ë¸ì´ í¬ê¸°ë¥¼ í‚¤ìš¸ìˆ˜ë¡ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ê³  ìˆê¸° ë•Œë¬¸ì— ê° ê¸°ì—…ì—ì„œëŠ” ëª¨ë¸ í¬ê¸°ë¥¼ ê³„ì†í•´ì„œ í‚¤ìš°ê³  ìˆëŠ” ìƒí™©ì…ë‹ˆë‹¤.<br/>\n",
        "\n",
        "í•˜ì§€ë§Œ í¬ê¸°ê°€ ì»¤ì§€ë©´ ì‚¬ì „ í•™ìŠµì— ë”°ë¥¸ ë¹„ìš©ì´ ë§ì´ ë“¤ê³  ê·¸ë§Œí¼ ë§ì€ í•™ìŠµ ë°ì´í„°ë¥¼ í™•ë³´í•´ì•¼ í•©ë‹ˆë‹¤.<br/>\n",
        "ì´ëŸ° ì œì•½ì‚¬í•­ ë•Œë¬¸ì— ì´ˆëŒ€í˜• ëª¨ë¸ì€ í•™ê³„ë³´ë‹¤ëŠ” êµ¬ê¸€, í˜ì´ìŠ¤ë¶ ë“±ê³¼ ê°™ì€ ëŒ€ê¸°ì—…ì—ì„œë§Œ ì´ë£¨ì–´ì§€ê³  ìˆìŠµë‹ˆë‹¤.<br/>\n",
        "í° ëª¨ë¸ì— ë¹„í•´ ê·¸ë ‡ì§€ ëª»í•œ ëª¨ë¸ì´ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¥í•˜ì§€ ëª»í•˜ê³  ìˆê¸° ë•Œë¬¸ì—, í•™ê³„ì—ì„œëŠ” ìƒëŒ€ì ìœ¼ë¡œ ë’¤ì²˜ì§ˆ ìˆ˜ë°–ì— ì—†ê²Œë©ë‹ˆë‹¤.<br/>\n",
        "ì´ëŸ° ì‚¬íƒœê°€ ê³„ì†ë˜ë©´ì„œ í¬ê¸°ë§Œ ì»¤ì§€ëŠ” ëª¨ë¸ì— ëŒ€í•œ ìš°ë ¤ì˜ ì‹œê°ë„ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ENRgv7ZdQGv"
      },
      "source": [
        "<img width=\"400\" alt=\"getting_bigger_gpt3\" src=\"https://miro.medium.com/max/1164/1*C-KNWQC_wXh-Q2wc6VPK1g.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8iDUH8WsW36"
      },
      "source": [
        "### 2) ë” ì¢‹ì€ í•™ìŠµ ë°©ë²• ì ìš©í•˜ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQw_pUUAdXA8"
      },
      "source": [
        "ì—¬ì „íˆ ë” ì¢‹ì€ í•™ìŠµ ë°©ë²•ì„ ì—°êµ¬í•˜ê³ ì í•˜ëŠ” ì›€ì§ì„ë„ ê³„ì†ë˜ê³  ìˆìŠµë‹ˆë‹¤.<br/>\n",
        "íŠ¹íˆ ê¸°ì¡´ GPTë‚˜ BERTì˜ ë‹¨ì ì„ ë³´ì™„í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ë§ì€ ì—°êµ¬ê°€ ì§„í–‰ë˜ê³  ìˆìŠµë‹ˆë‹¤.<br/>\n",
        "\n",
        "íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ë””ì½”ë” ë¸”ë¡ë§Œì„ ì‚¬ìš©í•œ GPTëŠ” ìƒëŒ€ì ìœ¼ë¡œ ìì—°ì–´ ìƒì„±ê³¼ ê´€ë ¨ëœ íƒœìŠ¤í¬ì—,<br/>\n",
        "ì¸ì½”ë” ë¸”ë¡ë§Œì„ ì‚¬ìš©í•œ BERTëŠ” ìì—°ì–´ ì´í•´ì™€ ê´€ë ¨ëœ íƒœìŠ¤í¬ì— íŠ¹í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.<br/>\n",
        "GPTì™€ ê°™ì´ ìˆœì°¨ì ìœ¼ë¡œ ìì—°ì–´ë¥¼ ìƒì„±í•˜ëŠ” ëª¨ë¸ì—ëŠ” AR(Auto-Regressive)í•œ ë°©ë²•ì´ ì ìš©ë˜ì—ˆë‹¤ê³  í•˜ê³ ,<br/>\n",
        "BERTì™€ ê°™ì´ ë…¸ì´ì¦ˆë¥¼ ë§ì¶”ì–´ê°€ëŠ” ë°©ì‹ìœ¼ë¡œ ìì—°ì–´ë¥¼ ì´í•´í•˜ëŠ” ëª¨ë¸ì—ëŠ” AE(Auto-Encoder)í•œ ë°©ë²•ì´ ì ìš©ë˜ì—ˆë‹¤ê³  í•©ë‹ˆë‹¤.\n",
        "\n",
        "**ë‘ ëª¨ë¸ì´ ì‚¬ìš©í–ˆë˜ ë°©ë²•ì„ ê²°í•©(AE+AR)**í•œ ëª¨ë¸ë¡œ XLNetì´ë‚˜ BARTê°€ ìˆìŠµë‹ˆë‹¤.<br/>\n",
        "ë‘ ëª¨ë¸ ëª¨ë‘ ìì—°ì–´ ì´í•´ì™€ ìƒì„± ëª¨ë‘ì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ë©° íŠ¹íˆ BARTëŠ” ìš”ì•½ íƒœìŠ¤í¬ì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.<br/>\n",
        "\n",
        "**ë‹¤ë¥¸ ë°©í–¥ì˜ ê°œì„ ìœ¼ë¡œëŠ” BERTì˜ Noising ë°©ë²•ì„ ì–´ë µê²Œ** ë§Œë“  ëª¨ë¸ë“¤ì´ ìˆìŠµë‹ˆë‹¤.<br/>\n",
        "ëŒ€í‘œì ì¸ ëª¨ë¸ë¡œ Masking ë°©ë²•ì— ë³€í™”ë¥¼ ì£¼ëŠ” SpanBERT, RoBERTaì™€ ê°™ì€ ëª¨ë¸ì´ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIQ7NpPpdZOX"
      },
      "source": [
        "ì•„ë˜ëŠ” BART ëª¨ë¸ì„ ë‚˜íƒ€ë‚´ëŠ” ê·¸ë¦¼ì…ë‹ˆë‹¤.\n",
        "\n",
        "<img width=\"500\" alt=\"bart\" src=\"https://miro.medium.com/max/1400/0*MeyyeTYxwtSZJPiL\">   \n",
        "\n",
        "ìœ„ ê·¸ë¦¼ì²˜ëŸ¼ AE ì™€ ARì´ ëª¨ë‘ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.<br/>\n",
        "ê²Œë‹¤ê°€ BARTëŠ” Masking ë¿ë§Œ ì•„ë‹ˆë¼ Permutation, Infilling ë“± ë‹¤ì–‘í•œ Noising ë°©ë²•ì´ ì ìš©ë˜ì—ˆë‹¤ëŠ” íŠ¹ì§•ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. \n",
        "\n",
        "<img width=\"500\" alt=\"bart_noising\" src=\"https://www.weak-learner.com/assets/img/blog/personal/bart_transformations.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H18wrk9LAemy"
      },
      "source": [
        "### 3) ë³´ë‹¤ ê°€ë²¼ìš´ ëª¨ë¸ ë§Œë“¤ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKxqVIoxAiUb"
      },
      "source": [
        "GPTì™€ BERT ê¸°ë³¸ ëª¨ë¸ì´ë¼ë„ í¬ê¸°ê°€ ê½¤ í¬ë‹¤ ë³´ë‹ˆ ì‚¬ì´ì¦ˆë¥¼ ì¤„ì´ë˜ ì„±ëŠ¥ì€ ë³´ì „í•˜ëŠ” ê²½ëŸ‰í™”ë¡œë„ ë§ì€ ì—°êµ¬ê°€ ì§„í–‰ë˜ê³  ìˆìŠµë‹ˆë‹¤.<br/>\n",
        "DistillBERT, ALBERT(A Light BERT) ë‚˜ ELECTRAê°€ ì´ëŸ° ë°©í–¥ìœ¼ë¡œ ì—°êµ¬ëœ ëŒ€í‘œì ì¸ ëª¨ë¸ì´ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì„¸ ëª¨ë¸ ëª¨ë‘ ê°ìë§Œì˜ ë°©ë²•ì„ ì´ìš©í•´ì„œ BERTì˜ í¬ê¸°(=íŒŒë¼ë¯¸í„° ìˆ˜)ë¥¼ ë§ì´ ì¤„ì´ê³  ì„±ëŠ¥ì€ ì–´ëŠì •ë„ ë³´ì¡´í•¨ìœ¼ë¡œì¨ ëª¨ë¸ íš¨ìœ¨ì„±ì„ ë†’ì˜€ìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì•„ë˜ëŠ” ELECTRAì˜ ëª¨ë¸ êµ¬ì¡°ì…ë‹ˆë‹¤.<br/>\n",
        "ë‹¤ìŒ ì‹œê°„ì— ë°°ìš¸ GANì— ë“±ì¥í•˜ëŠ” ë°©ë²•ë¡ ì„ ì ìš©í•˜ì—¬ BERTë³´ë‹¤ ì ì€ ë¦¬ì†ŒìŠ¤ë¥¼ í™œìš©í•˜ì—¬ ë” ë†’ì€ ì„±ëŠ¥ì„ ê¸°ë¡í•˜ì˜€ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8aukuXxAka2"
      },
      "source": [
        "<img width=\"500\" alt=\"bart_noising\" src=\"https://1.bp.blogspot.com/-sHybc03nJRo/XmfLongdVYI/AAAAAAAAFbI/a0t5w_zOZ-UtxYaoQlVkmTRsyFJyFddtQCLcBGAsYHQ/s1600/image1.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Op5Ou_RsBB2"
      },
      "source": [
        "### ì—¬ëŸ¬ ë°©ë©´ì—ì„œì˜ ë‹¤ì–‘í•œ ì‹œë„"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yrvpfJNAobj"
      },
      "source": [
        "- **ë‹¤ì–‘í•œ íƒœìŠ¤í¬ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ (Meta Learning)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJSbrN17d25l"
      },
      "source": [
        "T5ë‚˜ GPT-3ì™€ ê°™ì€ ëª¨ë¸ì€ í•˜ë‚˜ì˜ ëª¨ë¸ë¡œ ë‹¤ì–‘í•œ íƒœìŠ¤í¬ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì…ë‹ˆë‹¤.<br/>\n",
        "íŠ¹íˆ GPT-3ëŠ” Few-shot learning ë°©ë²•ë¡ ì„ ì ìš©í•œ ëª¨ë¸ë¡œ ì ë‹¹í•œ ê¸¸ì´ì˜ ì œì‹œë¬¸ë§Œ ì£¼ì–´ì£¼ë©´ **Fine-tuning ì—†ì´ë„** ì—„ì²­ë‚˜ê²Œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
        "\n",
        "N-shot learning ì— ëŒ€í•´ì„œëŠ” ì•„ë˜ ìë£Œë¥¼ ì°¸ê³ í•˜ì‹œë©´ ë˜ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQp0fL9EeWqL"
      },
      "source": [
        "1. ***íŒŒì¸íŠœë‹(finetuning)*** : ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ íƒœìŠ¤í¬ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„° ì „ì²´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ëª¨ë¸ ì „ì²´ë¥¼ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ë°ì´í„°ì— ë§ê²Œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\n",
        "\n",
        "2. ***ì œë¡œìƒ·ëŸ¬ë‹(zero-shot learning)*** : ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ íƒœìŠ¤í¬ ë°ì´í„°ë¥¼ ì „í˜€ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ëª¨ë¸ì´ ë°”ë¡œ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ íƒœìŠ¤í¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
        "\n",
        "3. ***ì›ìƒ·ëŸ¬ë‹(one-shot learning)*** : ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ íƒœìŠ¤í¬ ë°ì´í„°ë¥¼ í•œ ê±´ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤. ëª¨ë¸ ì „ì²´ë¥¼ 1ê±´ì˜ ë°ì´í„°ì— ë§ê²Œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤. ì—…í…Œì´íŠ¸ ì—†ì´ ìˆ˜í–‰í•˜ëŠ” ì›ìƒ·ëŸ¬ë‹ë„ ìˆìŠµë‹ˆë‹¤. ëª¨ë¸ì´ 1ê±´ì˜ ë°ì´í„°ê°€ ì–´ë–»ê²Œ ìˆ˜í–‰ë˜ëŠ”ì§€ ì°¸ê³ í•œ ë’¤ ë°”ë¡œ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ íƒœìŠ¤í¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
        "\n",
        "4. ***í“¨ìƒ·ëŸ¬ë‹(few-shot learning)*** : ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ íƒœìŠ¤í¬ ë°ì´í„°ë¥¼ ëª‡ ê±´ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤. ëª¨ë¸ ì „ì²´ë¥¼ ëª‡ ê±´ì˜ ë°ì´í„°ì— ë§ê²Œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤. ì—…ë°ì´íŠ¸ ì—†ì´ ìˆ˜í–‰í•˜ëŠ” í“¨ì‚¿ëŸ¬ë‹ë„ ìˆìŠµë‹ˆë‹¤. ëª¨ë¸ì´ ëª‡ ê±´ì˜ ë°ì´í„°ê°€ ì–´ë–»ê²Œ ìˆ˜í–‰ë˜ëŠ”ì§€ ì°¸ê³ í•œ ë’¤ ë°”ë¡œ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ íƒœìŠ¤í¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flHZHetOAwE_"
      },
      "source": [
        "- **ë‹¤êµ­ì–´(Multilingual) ëª¨ë¸**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16QSbKw43OKP"
      },
      "source": [
        "**ë‹¤êµ­ì–´ ëª¨ë¸** ì—­ì‹œ ì—´ì‹¬íˆ ì—°êµ¬ë˜ê³  ìˆëŠ” ë¶„ì•¼ì…ë‹ˆë‹¤.<br/>\n",
        "ì¼ë°˜ì ì¸ ì–¸ì–´ ëª¨ë¸ì˜ ê²½ìš° ë‹¨ì¼ ë§ë­‰ì¹˜ë¡œë§Œ ì‚¬ì „ í•™ìŠµì„ ì§„í–‰í•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.<br/>\n",
        "ê·¸ë ‡ê¸° ë•Œë¬¸ì— ì‚¬ì „ í•™ìŠµëœ ì–¸ì–´ ì™¸ì— ë‹¤ë¥¸ ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ë©´ ì„±ëŠ¥ì´ ê¸‰ê²©íˆ ì €í•˜ë˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì˜ˆë¥¼ ë“¤ì–´, ì˜ì–´ë¡œ í•™ìŠµëœ GPT-3 ëª¨ë¸ì— í•œêµ­ì–´ë¥¼ ì§‘ì–´ë„£ìœ¼ë©´ ê±°ì˜ ì´í•´í•˜ì§€ ëª»í•˜ê²Œ ë©ë‹ˆë‹¤.<br/> \n",
        "ì´ëŸ¬í•œ ë¬¸ì œë¥¼ ë›°ì–´ë„˜ê¸° ìœ„í•´ ë‹¤ì–‘í•œ ì–¸ì–´ë¥¼ ë„˜ë‚˜ë“¤ë©° ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì´ ì—°êµ¬ë˜ê³  ìˆëŠ”ë° ì´ë¥¼ ë‹¤êµ­ì–´ ëª¨ë¸ ì´ë¼ê³  í•©ë‹ˆë‹¤.\n",
        "\n",
        "ëŒ€í‘œì ì¸ ë‹¤êµ­ì–´ ëª¨ë¸ë¡œëŠ” mBART(multi-lingual BART), mT5(multi-lingual T5) ë“±ì´ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgo-SuX4A7hG"
      },
      "source": [
        "- **ìì—°ì–´ë¥¼ ë„˜ì–´(1) : ì»´í“¨í„° ë¹„ì „(Computer Vision, CV)ì—ì„œì˜ íŠ¸ëœìŠ¤í¬ë¨¸**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGso37M9NNDY"
      },
      "source": [
        "íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ì›ë˜ ìì—°ì–´ì²˜ë¦¬ ì¤‘ ë²ˆì—­ íƒœìŠ¤í¬ì— ì ìš©í•˜ê¸° ìœ„í•´ì„œ ë‚˜ì˜¨ ëª¨ë¸ì´ì—ˆìŠµë‹ˆë‹¤.<br/>\n",
        "í•˜ì§€ë§Œ ìµœê·¼ì—ëŠ” ì»´í“¨í„° ë¹„ì „ íƒœìŠ¤í¬ì¸ ì´ë¯¸ì§€ ì²˜ë¦¬ì—ì„œë„ íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ ì ìš©í•˜ê³ ì í•˜ëŠ” ì›€ì§ì„ì´ ë‚˜íƒ€ë‚˜ê³  ìˆìŠµë‹ˆë‹¤.<br/>\n",
        "\n",
        "[ViT(Vision in Transformer)](https://arxiv.org/abs/2010.11929) ë…¼ë¬¸ì—ì„œëŠ” ì»´í“¨í„° ë¹„ì „ ë¶„ì•¼ì—ì„œ SOTAì¸ CNN ê³„ì—´ ëª¨ë¸ë³´ë‹¤ íŠ¸ëœìŠ¤í¬ë¨¸ê°€ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë‚˜íƒ€ëƒˆë‹¤ê³  ë§í•˜ê³  ìˆìŠµë‹ˆë‹¤.<br/>\n",
        "(CNN ëª¨ë¸ì´ ë¬´ì—‡ì¸ì§€ ë‹¹ì¥ì€ ëª°ë¼ë„ ì¢‹ìŠµë‹ˆë‹¤. Sprint 3ì—ì„œ ìì„¸íˆ ë°°ìš°ê²Œ ë  ê²ƒì…ë‹ˆë‹¤.)\n",
        "\n",
        "ì•„ì§ ì»´í“¨í„° ë¹„ì „ ë¶„ì•¼ì—ì„œëŠ” CNNì— ë¹„í•´ ê°œë°œ ì†ë„ê°€ ë”ë”˜ í¸ì´ì§€ë§Œ,<br/>\n",
        "íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ì „ê³¼ ìì—°ì–´ ëª¨ë‘ ì •ë³µí•˜ê¸° ìœ„í•œ ë‹¤ì–‘í•œ ì‹œë„ê°€ ì§€ê¸ˆë„ ì§„í–‰ë˜ê³  ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nu5-IIIgP1x5"
      },
      "source": [
        "- **ìì—°ì–´ë¥¼ ë„˜ì–´(2) : ë©€í‹° ëª¨ë‹¬(Multi-modal) ëª¨ë¸**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wia-8pdid6k9"
      },
      "source": [
        "ì§€ë‚œ 1ì›”ì—ëŠ” GPTë¥¼ ë°œí‘œí–ˆë˜ OpenAIì—ì„œ DALL-E ì™€ CLIP ì´ë¼ëŠ” ì¬ë¯¸ìˆëŠ” ëª¨ë¸ì„ ë°œí‘œí–ˆìŠµë‹ˆë‹¤.<br/>\n",
        "ì´ ëª¨ë¸ì€ í…ìŠ¤íŠ¸(ë¬¸ì¥)ë¥¼ ì…ë ¥ë°›ì•„ ìƒì‘í•˜ëŠ” ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "\n",
        "ì•„ë˜ëŠ” DALL-E ê°€ _\"an armchair in the shape of an avocado\"_ ë¼ëŠ” ë¬¸ì¥ì„ ì…ë ¥ë°›ì€ ë’¤ ì¶œë ¥í•œ ì´ë¯¸ì§€ì…ë‹ˆë‹¤.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObY9pMs2d8Sh"
      },
      "source": [
        "<img width=\"700\" alt=\"dall-e\" src=\"https://user-images.githubusercontent.com/45377884/113083201-b9425500-9216-11eb-989a-3e5f28a794e5.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MTLzwNZQRI7"
      },
      "source": [
        "ì´ë ‡ê²Œ ìì—°ì–´ë¥¼ ë„˜ì–´ ë‹¤ì–‘í•œ ë§¤ì²´ë¡œ ê¸°ê³„ì™€ ì†Œí†µí•˜ëŠ” íƒœìŠ¤í¬ë¥¼ **ë©€í‹°ëª¨ë‹¬(Multi-Modal)**ì´ë¼ê³  í•©ë‹ˆë‹¤.<br/>\n",
        "íŠ¸ëœìŠ¤í¬ë¨¸ê°€ ìì—°ì–´ì²˜ë¦¬ ë¿ë§Œ ì•„ë‹ˆë¼ ì»´í“¨í„° ë¹„ì „ì— ëŒ€í•´ì„œë„ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ê¸° ë•Œë¬¸ì— íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ í™œìš©í•œ ë©€í‹°ëª¨ë‹¬ ì—°êµ¬ë„ í™œë°œí•˜ê²Œ ì§„í–‰ë˜ê³  ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPgdtKE03lGX"
      },
      "source": [
        "## Review\n",
        "\n",
        "í•™ìŠµ ëª©í‘œì— ëŒ€í•´ ë‹¤ì‹œ ìƒê°í•´ë´…ì‹œë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t22B1RW63zTq"
      },
      "source": [
        "- Attentionì˜ ì¥ì ì— ëŒ€í•´ì„œ ìƒê°í•˜ê³  ì„¤ëª…í•´ë´…ë‹ˆë‹¤.\n",
        "\n",
        "    - RNN ëª¨ë¸ì˜ ë‹¨ì  2ê°€ì§€\n",
        "    - ì¥ê¸° ì˜ì¡´ì„±(Long-term dependency)\n",
        "    - Attentionì˜ ì¥ì "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMlh3bET4NRZ"
      },
      "source": [
        "- Transformerì˜ ì¥ì ê³¼ êµ¬ì¡°ì— ëŒ€í•´ì„œ ìƒê°í•˜ê³  ì„¤ëª…í•´ë´…ë‹ˆë‹¤.\n",
        "    - \"Attention is All You Need\" (ì™œ ë…¼ë¬¸ ì œëª©ì„ ì´ë ‡ê²Œ ì§€ì—ˆì„ì§€ì— ëŒ€í•´ì„œ ìƒê°í•´ë´…ì‹œë‹¤)\n",
        "    - Positional Encoding\n",
        "    - Self-Attention\n",
        "    - Masked Self-Attention\n",
        "    - Encoder-Decoder Attention\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XOZcD7x6SR2"
      },
      "source": [
        "- GPT & BERT\n",
        "    - ì‚¬ì „ í•™ìŠµ ì–¸ì–´ ëª¨ë¸(Pretrained Language Model), ì „ì´ í•™ìŠµ(Transfer Learning)\n",
        "        - ì‚¬ì „ í•™ìŠµ(Pre-training)\n",
        "        - Fine-tuning\n",
        "    - GPTì˜ êµ¬ì¡°\n",
        "    - BERTì˜ êµ¬ì¡°\n",
        "        - MLM(Masked Langauge Model)\n",
        "        - NSP(Next Sentence Prediction)\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQlhRzWQsQN1"
      },
      "source": [
        "## ì°¸ê³  ìë£Œ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHL_Cr3IA0IL"
      },
      "source": [
        "- íŠ¸ëœìŠ¤í¬ë¨¸ì— ëŒ€í•´ ì¡°ê¸ˆ ë” ìì„¸í•˜ê²Œ ì•Œê³  ì‹¶ë‹¤ë©´\n",
        "    - [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/)\n",
        "    - [ë²ˆì—­](https://nlpinkorean.github.io/illustrated-transformer/)\n",
        "    - [Paper](https://arxiv.org/pdf/1706.03762.pdf) (Attention is All You Need)\n",
        "\n",
        "- GPTì— ëŒ€í•´ ë” ìì„¸í•˜ê²Œ ì•Œê³  ì‹¶ë‹¤ë©´\n",
        "    - [The Illustrated GPT-2](http://jalammar.github.io/illustrated-gpt2/) (Visualizing Transformer Language Models)\n",
        "    - [Paper](https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf) (Improving Language Understanding by Generative Pre-Training)\n",
        "\n",
        "- BERTì— ëŒ€í•´ ë” ìì„¸í•˜ê²Œ ì•Œê³  ì‹¶ë‹¤ë©´\n",
        "    - [The Illustrated BERT, ELMo, and co.](http://jalammar.github.io/illustrated-bert/) (How NLP Cracked Transfer Learning)\n",
        "    - [ë²ˆì—­](https://nlpinkorean.github.io/illustrated-bert/)\n",
        "    - [Paper](https://arxiv.org/pdf/1810.04805.pdf) (Pre-training of Deep Bidirectional Transformers for\n",
        "Language Understanding)"
      ]
    }
  ]
}