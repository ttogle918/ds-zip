{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "N411_References.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jub-GSrlhpo"
      },
      "source": [
        "<img src='https://user-images.githubusercontent.com/6457691/90080969-0f758d00-dd47-11ea-8191-fa12fd2054a7.png' width = '200' align = 'right'>\n",
        "\n",
        "## *AIB / SECTION 4 / SPRINT 1 / NOTE 1*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fT2Ijg7XeVzJ"
      },
      "source": [
        "## 신경망 구현하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LO1WA5bedpa"
      },
      "source": [
        "\n",
        "우리가 구현할 신경망은 아래와 같이 생겼습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_6_XmQrgNSt"
      },
      "source": [
        "<img src=\"https://www.researchgate.net/profile/Haohan_Wang/publication/282997080/figure/fig4/AS:305939199610886@1449952997594/A-typical-two-layer-neural-network-Input-layer-does-not-count-as-the-number-of-layers-of.png\" width=\"400\" alt=\"A typical two layer neural network. Input layer does not count as the number of layers of a network\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mKphOX06ofj"
      },
      "source": [
        "1. **먼저 초기 상태를 설정합니다.**\n",
        "\n",
        "가중치와 편향의 값은 일단 임의의 값으로 지정해줍니다.<br/>\n",
        "(아래 코드에서는 직접 임의의 값을 넣어 주었습니다.)\n",
        "\n",
        "아래 코드에서 가중치와 편향의 값보다는 배열(array)의 `shape` 을 주의 깊게 보도록 합시다.\n",
        "\n",
        "> ❓ ***왜 `shape`을 저렇게 지정해 준 것일까요? 위 그림을 보면서 각자 생각해보도록 합시다***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXXwQhkXd3b4"
      },
      "source": [
        "# 네트워크 구조 생성 함수 정의\n",
        "def init_network():\n",
        "    \"\"\"\n",
        "    W1,W2 : 가중치\n",
        "    B1,B2 : 편향\n",
        "    값은 일단 마음대로 지정한 값이니 신경쓰지 않으셔도 됩니다.\n",
        "    \"\"\"\n",
        "    network = {}\n",
        "    network['W1'] = np.array([[0.1, 0.3, 0.5, 0.7], [0.1, 0.3, 0.3, 0.7], [0.2, 0.1, 0.6, 0.8]]) # 3 x 4\n",
        "    network['B1'] = np.array([0.11, 0.12, 0.13, 0.14])\n",
        "    network['W2'] = np.array([[0.1, 0.5], [0.2, 0.6], [0.3, 0.4], [0.35, 0.35]]) # 4 x 2\n",
        "    network['B2'] = np.array([0.1, 0.5])\n",
        "\n",
        "    return network"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgIT6ykD7Tpv"
      },
      "source": [
        "2. **순전파(Feed Forward) 함수를 정의합니다.**\n",
        "\n",
        "**<font color=\"ff6f61\">순전파는 가중치와 편향의 연산을 반복하며 입력값을 받아 출력값으로 반환하는 과정</font>**입니다.\n",
        "\n",
        "> ❗️ ***당장 코드를 이해하지 못해도 좋습니다.<br/>\n",
        "어려운 코드는 아니니 반복해서 보시면 익숙해질 것입니다.***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoH7O82pgUuY"
      },
      "source": [
        "# 순전파 함수 정의\n",
        "def forward(network, x):\n",
        "  W1, W2 = network['W1'], network['W2']\n",
        "  b1, b2 = network['B1'], network['B2']\n",
        "\n",
        "  a1 = np.dot(x, W1) + b1\n",
        "  z1 = sigmoid(a1)\n",
        "  a2 = np.dot(z1, W2) + b2\n",
        "  \n",
        "  y = a2\n",
        "  return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijTjP-q979Qc"
      },
      "source": [
        "3. **정의한 함수와 입력 데이터를 바탕으로 계산한 값을 출력해봅시다.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxkTkiuXgl1_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46cc0952-cada-4ecf-e2de-06baa2b5b1d6"
      },
      "source": [
        "# 네트워크 제작\n",
        "network = init_network()\n",
        "\n",
        "# 샘플 입력 데이터\n",
        "x = np.array([1, 0.5, 0.7])\n",
        "\n",
        "# 순전파 실행\n",
        "y = forward(network, x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.81956037 1.7977893 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-fRWGaohh8Q"
      },
      "source": [
        "위 코드로 구현한 것은 학습없이 단순히 입력 값에 가중치를 연산하여 출력을 내는, 즉 한 번의 순전파가 일어나는 간단한 신경망입니다.\n",
        "\n",
        "위와 같은 신경망에서 가중치 행렬과 입력 신호의 연산이 어떻게 일어나는지 아래 그림을 통해 알아보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xH593HSh7VU"
      },
      "source": [
        "<img src='http://jalammar.github.io/images/NNs_formula_no_bias.png' width='400'>\n",
        "\n",
        "<img src=\"https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/etc/note_image/matdim.png\" width=700>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_Z6FC8wkcPk"
      },
      "source": [
        "위와 같이 신경망은 노드가 가중치로 연결되어 입력 신호와 연산한 뒤에 출력값으로 내보내는 함수라고도 할 수 있습니다.<br/>\n",
        "가중치를 지속하여 수정하면서 **<font color=\"ff6f61\">적절한 가중치를 찾는 과정을 학습(Training, Learning)**</font>이라고 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydz8HxeclTQs"
      },
      "source": [
        "실제로 사용되는 신경망은 아래와 같이 조금 더 복잡하게 생겼습니다.<br/>\n",
        "[THE NEURAL NETWORK ZOO](https://www.asimovinstitute.org/neural-network-zoo/) 에서 여러 가지 신경망 구조에 대해서 알아볼 수 있습니다.\n",
        "\n",
        "> ❗️ ***아래에 나오는 신경망 구조를 다 알지 못해도 되며, 오늘은 맨 앞에 나오는 두 개만 알아도 충분합니다.<br/>\n",
        "일단 둘러만 보도록 합시다. 앞으로도 여기 등장하는 신경망 전부를 공부하지는 않을 것입니다.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPDunbIegnhW"
      },
      "source": [
        "<img src=\"https://www.asimovinstitute.org/wp-content/uploads/2019/04/NeuralNetworkZoo20042019.png\" width=800>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzewtwaNnr4X"
      },
      "source": [
        "### 신경망의 각 층에 대해 알아봅시다\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FWrt4Nynxnh"
      },
      "source": [
        "신경망은 여러 층으로 구성이 됩니다. 크게 3가지 층으로 나눌 수 있는데요. <br/>\n",
        "다음 그림과 같이 **입력층, 은닉층, 출력층**으로 나뉩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nSbWx4un46Y"
      },
      "source": [
        "<img src=\"https://www.researchgate.net/profile/Haohan_Wang/publication/282997080/figure/fig4/AS:305939199610886@1449952997594/A-typical-two-layer-neural-network-Input-layer-does-not-count-as-the-number-of-layers-of.png\" width=\"400\" alt=\"A typical two layer neural network. Input layer does not count as the number of layers of a network\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e4zFdSKoPk-"
      },
      "source": [
        "각 층이 어떤 역할을 하는 지에 대해 알아보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioNoytfOoawE"
      },
      "source": [
        "- **<font color=\"ff6f61\">입력층(Input Layer)</font>**\n",
        "\n",
        "    입력층은 데이터셋이 입력되는 층입니다. 입력되는 **데이터셋의 특성(Feature)에 따라 입력층 노드의 수가 결정**됩니다.<br/>\n",
        "    보통 **입력층은 어떤 계산도 수행하지 않고** 그냥 값들을 전달하기만 하는 특징을 가지고 있습니다.<br/>\n",
        "    그렇기 때문에 **신경망의 층수(깊이, depth)를 셀 때 입력층은 포함하지 않습니다**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGByPuEFpdA7"
      },
      "source": [
        "- **<font color=\"ff6f61\">은닉층(Hidden Layers)</font>**\n",
        "\n",
        "    은닉층은 입력층으로부터 **입력된 신호가 가중치, 편향과 연산되는 층**입니다.<br/>\n",
        "    일반적으로 **입력층과 출력층 사이에 있는 층**을 은닉층이라고 부릅니다.<br/>\n",
        "    은닉층에서 일어나는 **계산의 결과를 사용자가 볼 수 없기 때문에** '은닉(Hidden)층' 이라는 이름이 붙었습니다.<br/>\n",
        "    은닉층은 입력 데이터셋의 특성 수와 상관 없이 노드 수를 구성할 수 있습니다.<br/>\n",
        "    \n",
        "    일반적으로 딥러닝(Deep Learning)이라고 하면 **2개 이상의 은닉층**을 가진 신경망을 말하는데요.<br/>\n",
        "    은닉층의 수가 늘어나고 더 좋은 학습 방법이 개발되면서 복잡한 데이터의 구조를 학습할 수 있게 되었습니다.<br/>\n",
        "    이렇게 복잡한 신경망이 다른 알고리즘이 세웠던 성능을 갱신하면서 딥러닝이 유명해졌습니다.\n",
        "\n",
        "    > ❓ 그렇다면 위에서 구현했던 신경망은 딥러닝에 해당한다고 할 수 있을까요?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0Yab5B7s70v"
      },
      "source": [
        "- **<font color=\"ff6f61\">출력층(Output Layer)</font>**\n",
        "\n",
        "    출력층은 **가장 마지막에 위치한 층이며 은닉층 연산을 마친 값이 출력되는 층**입니다.<br/>\n",
        "    **<font color=\"ff6f61\">우리가 풀어야 할 문제 종류에 따라서 출력층을 잘 설계하는 것이 중요</font>**한데요.<br/>\n",
        "    출력층이 어떻게 구성되는 지 알아보도록 하겠습니다.\n",
        "\n",
        "    - **이진 분류(Binary Classification)** : 활성화 함수로는 시그모이드(Sigmoid) 함수를 사용하며 출력층의 노드 수는 1로 설정합니다. <br/> 출력되는 값이 0과 1 사이의 확률값이 되도록 합니다.\n",
        "\n",
        "    - **다중 분류(Multi-class Classification)** : 활성화 함수로는 소프트맥스(Softmax) 함수를 사용하며 출력층의 노드 수는 레이블의 클래스(Class) 수와 동일하게 설정합니다.\n",
        "\n",
        "    - **회귀(Regression)** : 일반적으로는 활성화 함수를 지정해주지 않으며 출력층의 노드 수는 출력값의 특성(Feature) 수와 동일하게 설정합니다.<br/>\n",
        "    단순히 하나의 수를 예측하는 문제라면 1로 해주면 되겠죠?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLgxCdK5v_6e"
      },
      "source": [
        "## Tensorflow 신경망 예제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EyZNXRFwKZf"
      },
      "source": [
        "앞으로 4주 동안은 구글이 제공하는 딥러닝 프레임워크(Framework)인 텐서플로우(Tensorflow), 그리고 그 상위 API인 케라스(Keras)를 사용할 것입니다.<br/>\n",
        "가장 기본 예제인 MNIST를 통해 Tensorflow 와 Keras 의 사용법을 알아보도록 합시다.\n",
        "\n",
        "***아래에 등장하는 예제는 [Tensorflow Tutorial](https://https://www.tensorflow.org/tutorials/quickstart/beginner) 에서도 확인할 수 있습니다.***\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1FWYPJIwZgi"
      },
      "source": [
        "- **MNIST 손글씨 예제**\n",
        "\n",
        "    MNIST 손글씨 예제는 가장 기본적인 이미지 분류(Image Classification) 예제입니다.<br/>\n",
        "    사람이 **0-9까지 쓴 흑백 손글씨 숫자 이미지를 각 클래스로 분류**합니다.<br/>\n",
        "    데이터가 어떻게 생겼고 어떻게 분류되어야 하는지 이미지를 통해 알아보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiIv3kr-wVLo"
      },
      "source": [
        "<img src=\"https://abpaudel.com/assets/img/posts/mnist.png\" width=600>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0XNQxlr0KDF"
      },
      "source": [
        "> ❓ ***그렇다면 MNIST 예제는 이진 분류, 다중 분류, 회귀 중 어디에 속할까요? <br/>\n",
        "<font color=\"ff6f61\">항상 문제를 풀기 전에 자신이 풀고자 하는 문제가 어디에 속하는 지 생각</font>해보도록 합시다.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U-5CHMMyxqB"
      },
      "source": [
        "1. **먼저 필요한 패키지와 라이브러리를 불러옵니다.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gF7FoaBzlhZx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c437838-b423-4894-96fc-5b13fb7484b0"
      },
      "source": [
        "import pandas as pd\n",
        "!pip install tensorflow-gpu==2.0.0-rc1\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-gpu==2.0.0-rc1\n",
            "  Downloading tensorflow_gpu-2.0.0rc1-cp37-cp37m-manylinux2010_x86_64.whl (380.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 380.5 MB 10 kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.2.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.41.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (3.17.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.1.2)\n",
            "Collecting tb-nightly<1.15.0a20190807,>=1.15.0a20190806\n",
            "  Downloading tb_nightly-1.15.0a20190806-py3-none-any.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 36.7 MB/s \n",
            "\u001b[?25hCollecting tf-estimator-nightly<1.14.0.dev2019080602,>=1.14.0.dev2019080601\n",
            "  Downloading tf_estimator_nightly-1.14.0.dev2019080601-py2.py3-none-any.whl (501 kB)\n",
            "\u001b[K     |████████████████████████████████| 501 kB 46.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.37.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.4.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0-rc1) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (4.8.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow-gpu==2.0.0-rc1) (1.5.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (3.6.0)\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, keras-applications, tensorflow-gpu\n",
            "Successfully installed keras-applications-1.0.8 tb-nightly-1.15.0a20190806 tensorflow-gpu-2.0.0rc1 tf-estimator-nightly-1.14.0.dev2019080601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaoMRF6gy1jL"
      },
      "source": [
        "2. **데이터셋을 불러온 후 학습 데이터셋(Train Dataset)과 시험 데이터셋(Test Dataset)으로 나누어(Split)줍니다.**\n",
        "\n",
        "    이미지 데이터에서는 정규화하는 과정이 중요합니다. 빼먹지 않도록 주의해주세요!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_N35cHVjy8mh"
      },
      "source": [
        "# 라이브러리 데이터셋을 불러옵니다. \n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "# Training Set, Test Set을 분류해줍니다. \n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Value normalization을 수행합니다. \n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKW1Xn-hzLuG"
      },
      "source": [
        "3. **레이블이 어떻게 구성되어 있는 지 확인해봅니다.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHhhUaJtzLgj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a135e048-0987-422b-eec7-4330de36c21e"
      },
      "source": [
        "# 데이터의 레이블 구성 형태를 살펴봅니다.\n",
        "# 처음보는 데이터의 경우 데이터 자체를 디스플레이 하여 보면 도움이 됩니다.\n",
        "pd.unique(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 3, 6, 7, 8], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3kt2_77zPff"
      },
      "source": [
        "4. **이제 본격적으로 신경망 모델을 구축해보겠습니다.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYHRMmuczS-0"
      },
      "source": [
        "# 신경망 모델 구축\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(100, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2), # 다음 강의에서 설명이 될 component : 과적합(Overfitting)을 방지하는 역할을 합니다. (오늘은 이해하지 않고 넘어갑시다)\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86nL6_OM_htw"
      },
      "source": [
        "# 구축한 모델을 컴파일하며, 옵티마이저, loss function 등을 설정해줍니다.\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4S3QGSR_hoo",
        "outputId": "c68cbd23-6e7d-4051-b66f-7cdd4388f8fc"
      },
      "source": [
        "# 모델이 학습을 하는 부분입니다. 다음 시간에 배우게될 역전파에 대해서 이해를 하신다면 이 과정을 자세히 이해할 수 있을 것입니다. \n",
        "model.fit(x_train, y_train, epochs=5) # epoch의 수를 변화시키면 더 많이 학습하거나 적게 학습할 수 있습니다. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f210563dd40> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f210563dd40> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.3215 - accuracy: 0.9057\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 6s 96us/sample - loss: 0.1596 - accuracy: 0.9524\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 6s 93us/sample - loss: 0.1219 - accuracy: 0.9640\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 6s 95us/sample - loss: 0.1014 - accuracy: 0.9691\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 6s 96us/sample - loss: 0.0872 - accuracy: 0.9727\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2105658d90>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec-MbSxv_hdY",
        "outputId": "05315a8a-4fcd-4afb-ae6d-5f405a79ae54"
      },
      "source": [
        "# 만들어진 모델을 이용하여 예측하는 부분입니다.\n",
        "model.evaluate(x_test,  y_test, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000/1 - 1s - loss: 0.0427 - accuracy: 0.9755\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.08104543879562989, 0.9755]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITf6XXoL_uid"
      },
      "source": [
        "만족스러운 결과가 나왔나요?<br/>\n",
        "이번 스프린트를 공부하면서는 단순히 신경망의 성능이나 결과값보다 구성 요소가 어떻게 이루어져 있는지 아는 것이 중요한데요.<br/>\n",
        "아래 질문에 스스로 대답해보며 예시 코드에서 사용한 신경망에 대한 이해를 높여보도록 합시다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOIIXS6ozoYb"
      },
      "source": [
        "- **예시 코드에서**\n",
        "\n",
        "> ❓ 1. **`Flatten`** 은 어떤 역할을 할까요? <br/>\n",
        "> ❓ 2. 마지막 **`Dense`** 층의 숫자는 왜 10일까요? <br/>\n",
        "> ❓ 3. 마지막 **`Dense`** 층의 **`activation`** 은 왜 **`softmax`** 로 해주었을까요? <br/>\n",
        "> ❓ 4. **`compile`** 이 있는 부분에서 **`loss`** 함수는 왜 저렇게 해준 것일까요?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY0NwUA1zW8q"
      },
      "source": [
        "모델에서 어떻게 학습이 이루어지는지 [텐서플로우 플레이그라운드](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.70910&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false) 에서 시각화 자료로 알아보도록 합시다.\n",
        "\n",
        "> ❗️ ***신경망의 자세한 학습 과정에 대해서는 오늘 당장 알 지 못해도 괜찮습니다!***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX9AU0Ya2CH2"
      },
      "source": [
        "### 신경망, 딥러닝은 왜 강력할까요?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dw7MKe6E3jtP"
      },
      "source": [
        "깊은 신경망, 즉 딥러닝은 복잡한 데이터셋에서도 패턴을 잘 찾아내어 분류, 회귀 등의 문제를 뛰어난 성능으로 풀어냅니다.<br/>\n",
        "신경망이 이렇게 잘 동작하는 이유는 무엇일까요?\n",
        "\n",
        "이미지, 텍스트 데이터와 같이 차원이 많고 복잡한 데이터에서 패턴을 찾으려면, 매우 복잡한 특성 조합이 필요합니다.<br/>\n",
        "아래 그림은 이미지 데이터입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeTWPzZV3mPA"
      },
      "source": [
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/5d/401_Gridlock.jpg/1200px-401_Gridlock.jpg\" width=400 alt=\"401 Gridlock.jpg\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiOSKJ6hQr5k"
      },
      "source": [
        "위 사진에는 수많은 자동차들과 다른 물체들이 섞여 있습니다.<br/>\n",
        "우리는 한 번에 이 물체가 자동차인지 아닌지 혹은 어떤 자동차인지 까지도 알 수 있는데요.\n",
        "\n",
        "이미지를 학습 데이터로 사용해 자동차를 탐지하는 모델을 만든다고 해보겠습니다.<br/>\n",
        "이미지 데이터에서는 pixel 값을 조합해서 데이터의 패턴을 찾아내야 하는데요.<br/>\n",
        "그렇다면 pixel 값을 어떻게 조합해야 자동차를 잘 구분할 수 있을까요?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2j4QmTBdQhci"
      },
      "source": [
        "- **<font color=\"ff6f61\">표현 학습(Representation Learning)</font>**\n",
        "\n",
        "    여러분이 머신러닝을 수행할 때에는 직접 데이터셋이 가진 특성(Feature)을 최대한 파악한 후 가장 중요한 특성만을 설계하고 찾아내야 했습니다.<br/>\n",
        "    그 과정이 바로 특성 공학(Feature Engineering)을 바탕으로 한 전처리였는데요.<br/>\n",
        "    이 전처리 이후에 머신러닝 모델에 넣어주어야 모델의 성능을 올릴 수 있었고 전처리를 생략한다면 성능이 잘 나오지 않았습니다.\n",
        "\n",
        "    반면에 **<font color=\"ff6f61\">신경망은 데이터에서 필요한 특성을 알아서 조합</font>하여 찾아냅니다!**<br/>\n",
        "    그렇기 때문에 우리가 최소한의 전처리만 해준 후에 모델에 넣어도 꽤 성능이 잘 나오게 됩니다.<br/>\n",
        "    즉, 심화된 특성 공학을 사용해 특성 간의 관계를 찾아낼 필요가 없는 것이죠.\n",
        "\n",
        "    딥러닝과 (딥러닝이 아닌)머신러닝의 차이는 바로 여기에 있습니다.<br/>\n",
        "    이렇게 스스로 특성 관계를 찾아내는 것을 **표현 학습(Representation learning)**이라고 하는데요.<br/>\n",
        "    신경망의 구조와 깊이를 변화시키면 데이터의 특성 관계를 더욱 유용하게 학습할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mQ3Uek4TRoI"
      },
      "source": [
        "> ❗️ ***아래 그림은 어떤 인공 신경망의 구조를 나타낸 그림입니다. 그림이 너무 복잡하다고 겁먹지 않으셔도 됩니다.<br/>\n",
        "`keras`에 익숙해진다면 여러분 모두가 직접 아래 그림보다 복잡한 신경망을 만들 수 있습니다.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twqcEu2A2CfD"
      },
      "source": [
        "<img src=\"https://www.researchgate.net/profile/Tugce_Karatas8/publication/331165395/figure/fig1/AS:727499755507719@1550460866636/A-graphical-visualization-of-a-Deep-Neural-Network-from-here.ppm\" alt=\"A graphical visualization of a Deep Neural Network from here\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32-FVtcWT7t8"
      },
      "source": [
        "> ❓ ***그렇다면 신경망의 구조를 어떻게 설계하는 것이 가장 좋을까요?<br/>\n",
        "좋은 신경망 구조란 무엇일지 각자 생각해보도록 합시다. 그리고 디스코드에서 서로 토론해봅시다.***"
      ]
    }
  ]
}