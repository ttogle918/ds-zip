{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ttogle918/ds-section4-sprint1/blob/master/n411/n411_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzIdLqSrQNwo"
      },
      "source": [
        "<img src='https://user-images.githubusercontent.com/6457691/90080969-0f758d00-dd47-11ea-8191-fa12fd2054a7.png' width = '200' align = 'right'>\n",
        "\n",
        "## *DATA SCIENCE / SECTION 4 / SPRINT 1 / NOTE 1 - assignmnet*\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# N411. 퍼셉트론(Perceptron)과 인공신경망(Artificial Neural Networks) 과제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XipoWCOTrsl"
      },
      "source": [
        "## 단층 퍼셉트론"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8lL5hrHTrsm"
      },
      "source": [
        "이진분류 태스크를 위한 예시 데이터를 생성해보겠습니다. X 데이터는 (x좌표, y좌표)로 이루어져 있으며, 타겟 데이터는 0과 1로 이루어져 있습니다.\n",
        "\n",
        "아래의 예시 생성 부분이 당장 이해 안가도 괜찮습니다. 넘파이를 활용해, 이런 다양한 일들을 할 수 있다는 점을 알아두시고, 궁금하신 분은 나중에 더 찾아보세요.\n",
        "\n",
        "- np.append, np.vstack, np.hstack의 각각의 차이점에 대해 더 찾아보세요!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ np.append\n",
        "+ np.vstack\n",
        "+ np.hstack"
      ],
      "metadata": {
        "id": "CVEBKuVbpADq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EH8ZO2DLTrsn",
        "outputId": "554c7933-ae28-4bf4-f5f8-af2f6bf327c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "np.random.seed(0)\n",
        "\n",
        "x11 = np.random.uniform(low=0, high=5, size=(50,))\n",
        "x12 = np.random.uniform(low=10, high=15, size=(50,))\n",
        "x21 = np.random.uniform(low=0, high=5, size=(50,))\n",
        "x22 = np.random.uniform(low=10, high=15, size=(50,))\n",
        "\n",
        "\n",
        "x1 = np.append(x11, x12)\n",
        "x2 = np.append(x21, x22)\n",
        "\n",
        "y11 = np.random.uniform(low=10, high=15, size=(50,))\n",
        "y12 = np.random.uniform(low=0, high=5, size=(50,))\n",
        "y21 = np.random.uniform(low=0, high=5, size=(50,))\n",
        "y22 = np.random.uniform(low=10, high=15, size=(50,))\n",
        "\n",
        "y1 = np.append(y11, y12)\n",
        "y2 = np.append(y21, y22)\n",
        "\n",
        "x_1 = np.vstack([x1, y1]).T\n",
        "x_2 = np.vstack([x2, y2]).T\n",
        "y_1 = np.ones_like(x_1[:, 0])\n",
        "y_2 = np.zeros_like(x_2[:, 0])\n",
        "x = np.vstack([x_1, x_2])\n",
        "y = np.hstack([y_1, y_2])\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (12,5))\n",
        "ax.plot(x_1[:, 0], x_1[:,1], 'bo')\n",
        "ax.plot(x_2[:,0], x_2[:,1], 'ro')\n",
        "ax.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwDCWk-BTrsp"
      },
      "source": [
        "### 문제 1-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hANX6KQgTrsp"
      },
      "source": [
        "단층 퍼셉트론으로 위의 문제를 해결할 수 없음을 확인해보겠습니다. 이진 분류를 위한 단층 퍼셉트론을 구현하기 위해 다음 빈칸에 들어갈 내용으로 알맞은 것은?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VPqCI_xkTrsq",
        "outputId": "6d1eed90-5f5a-4cd6-be63-f9547cd61627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "7/7 [==============================] - 1s 3ms/step - loss: 2.3601 - accuracy: 0.2950\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.8212 - accuracy: 0.3350\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.5304 - accuracy: 0.4050\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.3043 - accuracy: 0.4800\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.0947 - accuracy: 0.3900\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.9256 - accuracy: 0.4600\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.8246 - accuracy: 0.4350\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.7634 - accuracy: 0.5050\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7330 - accuracy: 0.6150\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7089 - accuracy: 0.5700\n",
            "--------------------\n",
            "[[0.46178332]\n",
            " [0.46054325]\n",
            " [0.46294722]\n",
            " [0.4650961 ]\n",
            " [0.4626588 ]\n",
            " [0.47357947]\n",
            " [0.44600368]\n",
            " [0.47660458]\n",
            " [0.4782951 ]\n",
            " [0.4373473 ]] (200, 1)\n",
            "\n",
            "-------------------\n",
            "[0.46178332 0.46054325 0.46294722 0.4650961  0.4626588  0.47357947\n",
            " 0.44600368 0.47660458 0.4782951  0.4373473 ] (200,)\n",
            "\n",
            "-------------------\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 0\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] (200,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x, y, epochs=10)\n",
        "\n",
        "# 각각의 변수 명을 모두 다르게 설정했습니다.\n",
        "# model.predict의 결과값 / preds_1d / pred_class 의 형태(shape)와 값들을 한번 직접 확인해보세요\n",
        "\n",
        "preds = model.predict(x)\n",
        "preds_1d = preds.flatten()\n",
        "pred_class = np.where(preds_1d > 0.5, 1 , 0)\n",
        "\n",
        "print('--------------------')\n",
        "print(preds[0:10], preds.shape)\n",
        "print('\\n-------------------')\n",
        "print(preds_1d[0:10], preds_1d.shape)\n",
        "print('\\n-------------------')\n",
        "print(pred_class, pred_class.shape)\n",
        "\n",
        "y_true = x[pred_class==1]\n",
        "y_false = x[pred_class==0]\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (12,5))\n",
        "ax.plot(y_true[:, 0], y_true[:,1], 'bo')\n",
        "ax.plot(y_false[:,0], y_false[:,1], 'ro')\n",
        "ax.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3bNmudFTrsr"
      },
      "source": [
        "### 문제 1-2\n",
        "비선형성이 추가되지 않은 단층 퍼셉트론이 어떠한 결정 경계를 만드나요?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "비선형성 == 곡선 이라고 가정하면,\n",
        "곡선이 추가되지 않은 단층 퍼셉트론이 어떠한 결정 경계를 만드나요?\n",
        "직선 결정 경계를 만든다."
      ],
      "metadata": {
        "id": "gM8s-7G1sMlT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvNvoQJk-xb-"
      },
      "source": [
        "## 문제2. 실제 데이터 과제\n",
        " - 아래 주어진 데이터를 신경망을 이용하여 Classification 문제를 풀어보세요.\n",
        " - 또한 머신러닝에서 배운 방법(배우지 않은 머신러닝 방법론(SVM 등)도 가능)을 이용하여 비교해보세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqOkgM9wnmNu"
      },
      "source": [
        "입력 데이터 샘플과 Features : 1077 샘플 x 69 Features (변수)\n",
        "\n",
        "데이터 label: 다운증후군 (1), 정상군 (2)\n",
        "\n",
        "데이터는 다운증후군과 정상군 마우스 피질의 핵 분획에서 검출 가능한 신호를 생성하는 69 개 단백질의 발현 수준으로 구성되어 있습니다.\n",
        "라벨로는 다운증후군 1, 정상군 2로 할당되어 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gULuO1ETO-6G"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_excel(\"https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/MouseProtein/mouse_protein_X.xls\", header=None)\n",
        "df_label = pd.read_excel(\"https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/MouseProtein/mouse_protein_label.xls\", header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "6I-8OQ_APLtG",
        "outputId": "a52726eb-2743-43f3-c852-a50e9d7b0617"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e1ae057a-6f8e-4d37-a840-e00c948cbc36\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.50364</td>\n",
              "      <td>0.74719</td>\n",
              "      <td>0.43018</td>\n",
              "      <td>2.8163</td>\n",
              "      <td>5.9902</td>\n",
              "      <td>0.21883</td>\n",
              "      <td>0.17757</td>\n",
              "      <td>2.3737</td>\n",
              "      <td>0.23222</td>\n",
              "      <td>1.7509</td>\n",
              "      <td>0.68791</td>\n",
              "      <td>0.30638</td>\n",
              "      <td>0.40270</td>\n",
              "      <td>0.29693</td>\n",
              "      <td>1.02210</td>\n",
              "      <td>0.60567</td>\n",
              "      <td>1.8777</td>\n",
              "      <td>2.3087</td>\n",
              "      <td>0.44160</td>\n",
              "      <td>0.85937</td>\n",
              "      <td>0.41629</td>\n",
              "      <td>0.36961</td>\n",
              "      <td>0.17894</td>\n",
              "      <td>1.8664</td>\n",
              "      <td>3.6852</td>\n",
              "      <td>1.5372</td>\n",
              "      <td>0.26453</td>\n",
              "      <td>0.31968</td>\n",
              "      <td>0.81387</td>\n",
              "      <td>0.16585</td>\n",
              "      <td>0.45391</td>\n",
              "      <td>3.0376</td>\n",
              "      <td>0.36951</td>\n",
              "      <td>0.45854</td>\n",
              "      <td>0.33534</td>\n",
              "      <td>0.82519</td>\n",
              "      <td>0.57692</td>\n",
              "      <td>0.44810</td>\n",
              "      <td>0.58627</td>\n",
              "      <td>0.39472</td>\n",
              "      <td>0.33957</td>\n",
              "      <td>0.48286</td>\n",
              "      <td>0.29417</td>\n",
              "      <td>0.18215</td>\n",
              "      <td>0.84273</td>\n",
              "      <td>0.19261</td>\n",
              "      <td>1.4431</td>\n",
              "      <td>0.29470</td>\n",
              "      <td>0.35460</td>\n",
              "      <td>1.3391</td>\n",
              "      <td>0.17012</td>\n",
              "      <td>0.15910</td>\n",
              "      <td>0.18885</td>\n",
              "      <td>0.10631</td>\n",
              "      <td>0.14499</td>\n",
              "      <td>0.17667</td>\n",
              "      <td>0.12519</td>\n",
              "      <td>0.11529</td>\n",
              "      <td>0.22804</td>\n",
              "      <td>0.14276</td>\n",
              "      <td>0.43096</td>\n",
              "      <td>0.24754</td>\n",
              "      <td>1.6033</td>\n",
              "      <td>2.0149</td>\n",
              "      <td>0.10823</td>\n",
              "      <td>1.04500</td>\n",
              "      <td>0.83156</td>\n",
              "      <td>0.18885</td>\n",
              "      <td>1.6757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.51462</td>\n",
              "      <td>0.68906</td>\n",
              "      <td>0.41177</td>\n",
              "      <td>2.7895</td>\n",
              "      <td>5.6850</td>\n",
              "      <td>0.21164</td>\n",
              "      <td>0.17282</td>\n",
              "      <td>2.2921</td>\n",
              "      <td>0.22697</td>\n",
              "      <td>1.5964</td>\n",
              "      <td>0.69501</td>\n",
              "      <td>0.29905</td>\n",
              "      <td>0.38599</td>\n",
              "      <td>0.28132</td>\n",
              "      <td>0.95668</td>\n",
              "      <td>0.58756</td>\n",
              "      <td>1.7258</td>\n",
              "      <td>2.0430</td>\n",
              "      <td>0.44522</td>\n",
              "      <td>0.83466</td>\n",
              "      <td>0.40036</td>\n",
              "      <td>0.35618</td>\n",
              "      <td>0.17368</td>\n",
              "      <td>1.7610</td>\n",
              "      <td>3.4853</td>\n",
              "      <td>1.5092</td>\n",
              "      <td>0.25573</td>\n",
              "      <td>0.30442</td>\n",
              "      <td>0.78050</td>\n",
              "      <td>0.15719</td>\n",
              "      <td>0.43094</td>\n",
              "      <td>2.9219</td>\n",
              "      <td>0.34228</td>\n",
              "      <td>0.42356</td>\n",
              "      <td>0.32483</td>\n",
              "      <td>0.76172</td>\n",
              "      <td>0.54510</td>\n",
              "      <td>0.42088</td>\n",
              "      <td>0.54510</td>\n",
              "      <td>0.36825</td>\n",
              "      <td>0.32196</td>\n",
              "      <td>0.45452</td>\n",
              "      <td>0.27643</td>\n",
              "      <td>0.18209</td>\n",
              "      <td>0.84761</td>\n",
              "      <td>0.19482</td>\n",
              "      <td>1.4395</td>\n",
              "      <td>0.29406</td>\n",
              "      <td>0.35455</td>\n",
              "      <td>1.3063</td>\n",
              "      <td>0.17143</td>\n",
              "      <td>0.15813</td>\n",
              "      <td>0.18457</td>\n",
              "      <td>0.10659</td>\n",
              "      <td>0.15047</td>\n",
              "      <td>0.17831</td>\n",
              "      <td>0.13428</td>\n",
              "      <td>0.11823</td>\n",
              "      <td>0.23807</td>\n",
              "      <td>0.14204</td>\n",
              "      <td>0.45716</td>\n",
              "      <td>0.25763</td>\n",
              "      <td>1.6717</td>\n",
              "      <td>2.0046</td>\n",
              "      <td>0.10975</td>\n",
              "      <td>1.00990</td>\n",
              "      <td>0.84927</td>\n",
              "      <td>0.20040</td>\n",
              "      <td>1.7436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.50918</td>\n",
              "      <td>0.73025</td>\n",
              "      <td>0.41831</td>\n",
              "      <td>2.6872</td>\n",
              "      <td>5.6221</td>\n",
              "      <td>0.20901</td>\n",
              "      <td>0.17572</td>\n",
              "      <td>2.2833</td>\n",
              "      <td>0.23025</td>\n",
              "      <td>1.5613</td>\n",
              "      <td>0.67735</td>\n",
              "      <td>0.29128</td>\n",
              "      <td>0.38100</td>\n",
              "      <td>0.28171</td>\n",
              "      <td>1.00360</td>\n",
              "      <td>0.60245</td>\n",
              "      <td>1.7319</td>\n",
              "      <td>2.0180</td>\n",
              "      <td>0.46767</td>\n",
              "      <td>0.81433</td>\n",
              "      <td>0.39985</td>\n",
              "      <td>0.36809</td>\n",
              "      <td>0.17390</td>\n",
              "      <td>1.7655</td>\n",
              "      <td>3.5715</td>\n",
              "      <td>1.5012</td>\n",
              "      <td>0.25961</td>\n",
              "      <td>0.31175</td>\n",
              "      <td>0.78515</td>\n",
              "      <td>0.16090</td>\n",
              "      <td>0.42319</td>\n",
              "      <td>2.9441</td>\n",
              "      <td>0.34370</td>\n",
              "      <td>0.42500</td>\n",
              "      <td>0.32485</td>\n",
              "      <td>0.75703</td>\n",
              "      <td>0.54362</td>\n",
              "      <td>0.40463</td>\n",
              "      <td>0.55299</td>\n",
              "      <td>0.36388</td>\n",
              "      <td>0.31309</td>\n",
              "      <td>0.44720</td>\n",
              "      <td>0.25665</td>\n",
              "      <td>0.18439</td>\n",
              "      <td>0.85617</td>\n",
              "      <td>0.20074</td>\n",
              "      <td>1.5244</td>\n",
              "      <td>0.30188</td>\n",
              "      <td>0.38609</td>\n",
              "      <td>1.2796</td>\n",
              "      <td>0.18546</td>\n",
              "      <td>0.14870</td>\n",
              "      <td>0.19053</td>\n",
              "      <td>0.10830</td>\n",
              "      <td>0.14533</td>\n",
              "      <td>0.17621</td>\n",
              "      <td>0.13256</td>\n",
              "      <td>0.11776</td>\n",
              "      <td>0.24482</td>\n",
              "      <td>0.14244</td>\n",
              "      <td>0.51047</td>\n",
              "      <td>0.25534</td>\n",
              "      <td>1.6635</td>\n",
              "      <td>2.0168</td>\n",
              "      <td>0.10820</td>\n",
              "      <td>0.99685</td>\n",
              "      <td>0.84671</td>\n",
              "      <td>0.19368</td>\n",
              "      <td>1.9264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.44211</td>\n",
              "      <td>0.61708</td>\n",
              "      <td>0.35863</td>\n",
              "      <td>2.4669</td>\n",
              "      <td>4.9795</td>\n",
              "      <td>0.22289</td>\n",
              "      <td>0.17646</td>\n",
              "      <td>2.1523</td>\n",
              "      <td>0.20700</td>\n",
              "      <td>1.5951</td>\n",
              "      <td>0.58328</td>\n",
              "      <td>0.29673</td>\n",
              "      <td>0.37709</td>\n",
              "      <td>0.31383</td>\n",
              "      <td>0.87539</td>\n",
              "      <td>0.52029</td>\n",
              "      <td>1.5669</td>\n",
              "      <td>2.1328</td>\n",
              "      <td>0.47767</td>\n",
              "      <td>0.72770</td>\n",
              "      <td>0.38564</td>\n",
              "      <td>0.36297</td>\n",
              "      <td>0.17945</td>\n",
              "      <td>1.2863</td>\n",
              "      <td>2.9701</td>\n",
              "      <td>1.4197</td>\n",
              "      <td>0.25954</td>\n",
              "      <td>0.27922</td>\n",
              "      <td>0.73449</td>\n",
              "      <td>0.16221</td>\n",
              "      <td>0.41061</td>\n",
              "      <td>2.5002</td>\n",
              "      <td>0.34451</td>\n",
              "      <td>0.42921</td>\n",
              "      <td>0.33012</td>\n",
              "      <td>0.74698</td>\n",
              "      <td>0.54676</td>\n",
              "      <td>0.38686</td>\n",
              "      <td>0.54785</td>\n",
              "      <td>0.36677</td>\n",
              "      <td>0.32849</td>\n",
              "      <td>0.44265</td>\n",
              "      <td>0.39853</td>\n",
              "      <td>0.16177</td>\n",
              "      <td>0.76023</td>\n",
              "      <td>0.18417</td>\n",
              "      <td>1.6124</td>\n",
              "      <td>0.29638</td>\n",
              "      <td>0.29068</td>\n",
              "      <td>1.1988</td>\n",
              "      <td>0.15980</td>\n",
              "      <td>0.16611</td>\n",
              "      <td>0.18532</td>\n",
              "      <td>0.10318</td>\n",
              "      <td>0.14066</td>\n",
              "      <td>0.16380</td>\n",
              "      <td>0.12321</td>\n",
              "      <td>0.11744</td>\n",
              "      <td>0.23495</td>\n",
              "      <td>0.14507</td>\n",
              "      <td>0.43100</td>\n",
              "      <td>0.25110</td>\n",
              "      <td>1.4846</td>\n",
              "      <td>1.9572</td>\n",
              "      <td>0.11988</td>\n",
              "      <td>0.99022</td>\n",
              "      <td>0.83328</td>\n",
              "      <td>0.19211</td>\n",
              "      <td>1.7006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.43494</td>\n",
              "      <td>0.61743</td>\n",
              "      <td>0.35880</td>\n",
              "      <td>2.3658</td>\n",
              "      <td>4.7187</td>\n",
              "      <td>0.21311</td>\n",
              "      <td>0.17363</td>\n",
              "      <td>2.1340</td>\n",
              "      <td>0.19216</td>\n",
              "      <td>1.5042</td>\n",
              "      <td>0.55096</td>\n",
              "      <td>0.28696</td>\n",
              "      <td>0.36350</td>\n",
              "      <td>0.27796</td>\n",
              "      <td>0.86491</td>\n",
              "      <td>0.50799</td>\n",
              "      <td>1.4801</td>\n",
              "      <td>2.0137</td>\n",
              "      <td>0.48342</td>\n",
              "      <td>0.68779</td>\n",
              "      <td>0.36753</td>\n",
              "      <td>0.35531</td>\n",
              "      <td>0.17484</td>\n",
              "      <td>1.3247</td>\n",
              "      <td>2.8963</td>\n",
              "      <td>1.3599</td>\n",
              "      <td>0.25070</td>\n",
              "      <td>0.27367</td>\n",
              "      <td>0.70270</td>\n",
              "      <td>0.15483</td>\n",
              "      <td>0.39855</td>\n",
              "      <td>2.4566</td>\n",
              "      <td>0.32913</td>\n",
              "      <td>0.40876</td>\n",
              "      <td>0.31341</td>\n",
              "      <td>0.69196</td>\n",
              "      <td>0.53686</td>\n",
              "      <td>0.36082</td>\n",
              "      <td>0.51282</td>\n",
              "      <td>0.35155</td>\n",
              "      <td>0.31221</td>\n",
              "      <td>0.41909</td>\n",
              "      <td>0.39345</td>\n",
              "      <td>0.16020</td>\n",
              "      <td>0.76811</td>\n",
              "      <td>0.18572</td>\n",
              "      <td>1.6458</td>\n",
              "      <td>0.29683</td>\n",
              "      <td>0.30935</td>\n",
              "      <td>1.2070</td>\n",
              "      <td>0.16465</td>\n",
              "      <td>0.16069</td>\n",
              "      <td>0.18822</td>\n",
              "      <td>0.10478</td>\n",
              "      <td>0.14198</td>\n",
              "      <td>0.16771</td>\n",
              "      <td>0.13684</td>\n",
              "      <td>0.11605</td>\n",
              "      <td>0.25553</td>\n",
              "      <td>0.14087</td>\n",
              "      <td>0.48123</td>\n",
              "      <td>0.25177</td>\n",
              "      <td>1.5348</td>\n",
              "      <td>2.0091</td>\n",
              "      <td>0.11952</td>\n",
              "      <td>0.99777</td>\n",
              "      <td>0.87867</td>\n",
              "      <td>0.20560</td>\n",
              "      <td>1.8397</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1ae057a-6f8e-4d37-a840-e00c948cbc36')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e1ae057a-6f8e-4d37-a840-e00c948cbc36 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e1ae057a-6f8e-4d37-a840-e00c948cbc36');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        0        1        2       3   ...       65       66       67      68\n",
              "0  0.50364  0.74719  0.43018  2.8163  ...  1.04500  0.83156  0.18885  1.6757\n",
              "1  0.51462  0.68906  0.41177  2.7895  ...  1.00990  0.84927  0.20040  1.7436\n",
              "2  0.50918  0.73025  0.41831  2.6872  ...  0.99685  0.84671  0.19368  1.9264\n",
              "3  0.44211  0.61708  0.35863  2.4669  ...  0.99022  0.83328  0.19211  1.7006\n",
              "4  0.43494  0.61743  0.35880  2.3658  ...  0.99777  0.87867  0.20560  1.8397\n",
              "\n",
              "[5 rows x 69 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# 샘플당 100개의 특성(feature)을 가진 데이터\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrIvw52rPdx4",
        "outputId": "38fa852b-e75e-4e01-9b8d-d12bcd78aacf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   0\n",
            "0  1\n",
            "1  1\n",
            "2  1\n",
            "3  1\n",
            "4  1\n",
            "      0\n",
            "1072  2\n",
            "1073  2\n",
            "1074  2\n",
            "1075  2\n",
            "1076  2\n"
          ]
        }
      ],
      "source": [
        "print(df_label.head())\n",
        "print(df_label.tail())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "print(list(df.isna().sum()))"
      ],
      "metadata": {
        "id": "gwLBCCf79SDr",
        "outputId": "6c8a7276-03ab-4b91-878f-7404556e3a5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yilj1IY3M4Zr"
      },
      "source": [
        "---\n",
        "\n",
        "4-1. 사용한 모델을 입력합니다. \n",
        "\n",
        "4-2. Accuracy를 입력합니다. \n",
        "\n",
        "4-3. Precision 을 입력합니다. \n",
        "\n",
        "4-4. Recall 을 입력합니다.\n",
        "\n",
        "4-5. F1 score 를 입력합니다. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recall(y_target, y_pred):\n",
        "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
        "    # round : 반올림한다\n",
        "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
        "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
        "\n",
        "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
        "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
        "\n",
        "    # (True Positive + False Negative) = 실제 값이 1(Positive) 전체\n",
        "    count_true_positive_false_negative = K.sum(y_target_yn)\n",
        "\n",
        "    # Recall =  (True Positive) / (True Positive + False Negative)\n",
        "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
        "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
        "\n",
        "    # return a single tensor value\n",
        "    return recall\n",
        "\n",
        "\n",
        "def precision(y_target, y_pred):\n",
        "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
        "    # round : 반올림한다\n",
        "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
        "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
        "\n",
        "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
        "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
        "\n",
        "    # (True Positive + False Positive) = 예측 값이 1(Positive) 전체\n",
        "    count_true_positive_false_positive = K.sum(y_pred_yn)\n",
        "\n",
        "    # Precision = (True Positive) / (True Positive + False Positive)\n",
        "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
        "    precision = count_true_positive / (count_true_positive_false_positive + K.epsilon())\n",
        "\n",
        "    # return a single tensor value\n",
        "    return precision\n",
        "\n",
        "\n",
        "def f1score(y_target, y_pred):\n",
        "    _recall = recall(y_target, y_pred)\n",
        "    _precision = precision(y_target, y_pred)\n",
        "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
        "    _f1score = ( 2 * _recall * _precision) / (_recall + _precision+ K.epsilon())\n",
        "    \n",
        "    # return a single tensor value\n",
        "    return _f1score"
      ],
      "metadata": {
        "id": "2KYWbmZ_Ff-s"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(df, df_label, train_size=0.80, test_size=0.20, random_state=2)\n",
        "x_train.shape,  x_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "XaaGbFUj2Bga",
        "outputId": "e86d4c67-35c0-45c9-b1e5-54bc10a8e2d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((861, 69), (216, 69), (861, 1), (216, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy', precision, recall, f1score])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10)"
      ],
      "metadata": {
        "id": "i05NX6Z3wvq9",
        "outputId": "5a659732-1ef6-4e53-c99d-290eab77060e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "27/27 [==============================] - 2s 2ms/step - loss: -5.2876 - accuracy: 0.5250 - precision: 1.0000 - recall: 0.9826 - f1score: 0.9887\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -50.8590 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -447.2094 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -3935.3293 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -34706.3945 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -305516.3125 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -2689878.2500 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -23615912.0000 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -207423152.0000 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -1823031296.0000 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f204a7c0550>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_add_relu = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_add_relu.compile(optimizer='sgd',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy', precision, recall, f1score])\n",
        "\n",
        "model_add_relu.fit(x_train, y_train, epochs=10)"
      ],
      "metadata": {
        "id": "0TgZu8_LN-6Z",
        "outputId": "14e3d3cd-4d25-4613-80c8-48976137a026",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "27/27 [==============================] - 1s 2ms/step - loss: -4.6603 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -44.4881 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -391.3629 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -3446.7720 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -30305.5996 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -266524.6250 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -2341602.0000 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 0s 3ms/step - loss: -20574774.0000 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -180377904.0000 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -1590354688.0000 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f20484cd490>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_relu_adam = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_relu_adam.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy', precision, recall, f1score])\n",
        "\n",
        "model_relu_adam.fit(x_train, y_train, epochs=10)"
      ],
      "metadata": {
        "id": "jutZo5xKOBpW",
        "outputId": "2cf02f0b-516f-48b7-f6d3-243faf25d48b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "27/27 [==============================] - 1s 2ms/step - loss: -2.6538 - accuracy: 0.5308 - precision: 1.0000 - recall: 0.9954 - f1score: 0.9975\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -9.3997 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -18.9818 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -32.6252 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -50.6550 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -73.3298 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -100.6865 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -132.6868 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 0s 3ms/step - loss: -169.8381 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -211.0421 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2049cf6d10>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model, sigmoid\n",
        "preds = model.predict(x_test)\n",
        "\n",
        "results = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(\"test loss, test acc,  precision, recall, f1score:\", results)"
      ],
      "metadata": {
        "id": "n8NZPTZaxUBP",
        "outputId": "d5751669-f0a1-4b35-93a0-21c8c476ff41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 - 0s - loss: -4.8982e+09 - accuracy: 0.5185 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - 278ms/epoch - 40ms/step\n",
            "test loss, test acc,  precision, recall, f1score: [-4898209280.0, 0.5185185074806213, 1.0, 1.0, 1.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_add_relu\n",
        "# model : relu, sigmoid\n",
        "# activation : sgd\n",
        "preds = model_add_relu.predict(x_test)\n",
        "\n",
        "results = model_add_relu.evaluate(x_test, y_test, verbose=2)\n",
        "print(\"test loss, test acc,  precision, recall, f1score:\", results)"
      ],
      "metadata": {
        "id": "8pYnbDcWNijh",
        "outputId": "ea4a3420-5164-4e06-ce48-3986e293c33d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 - 0s - loss: -4.2668e+09 - accuracy: 0.5185 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - 247ms/epoch - 35ms/step\n",
            "test loss, test acc,  precision, recall, f1score: [-4266772224.0, 0.5185185074806213, 1.0, 1.0, 1.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_add_relu, relu, sigmoid\n",
        "# model : relu, sigmoid\n",
        "# activation : adam\n",
        "\n",
        "preds = model_add_relu.predict(x_test)\n",
        "\n",
        "results = model_add_relu.evaluate(x_test, y_test, verbose=2)\n",
        "print(\"test loss, test acc,  precision, recall, f1score:\", results)"
      ],
      "metadata": {
        "id": "G8sOxPzAOIGt",
        "outputId": "2266afda-e3a9-4f3d-d9db-2a8ae480ebdc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 - 0s - loss: -4.2668e+09 - accuracy: 0.5185 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - 26ms/epoch - 4ms/step\n",
            "test loss, test acc,  precision, recall, f1score: [-4266772224.0, 0.5185185074806213, 1.0, 1.0, 1.0]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "ds_cs_N421a.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}