{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ttogle918/ds-section4-sprint1/blob/master/n411/n411_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzIdLqSrQNwo"
      },
      "source": [
        "<img src='https://user-images.githubusercontent.com/6457691/90080969-0f758d00-dd47-11ea-8191-fa12fd2054a7.png' width = '200' align = 'right'>\n",
        "\n",
        "## *DATA SCIENCE / SECTION 4 / SPRINT 1 / NOTE 1 - assignmnet*\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# N411. 퍼셉트론(Perceptron)과 인공신경망(Artificial Neural Networks) 과제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XipoWCOTrsl"
      },
      "source": [
        "## 단층 퍼셉트론"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8lL5hrHTrsm"
      },
      "source": [
        "이진분류 태스크를 위한 예시 데이터를 생성해보겠습니다. X 데이터는 (x좌표, y좌표)로 이루어져 있으며, 타겟 데이터는 0과 1로 이루어져 있습니다.\n",
        "\n",
        "아래의 예시 생성 부분이 당장 이해 안가도 괜찮습니다. 넘파이를 활용해, 이런 다양한 일들을 할 수 있다는 점을 알아두시고, 궁금하신 분은 나중에 더 찾아보세요.\n",
        "\n",
        "- np.append, np.vstack, np.hstack의 각각의 차이점에 대해 더 찾아보세요!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ np.append\n",
        "+ np.vstack\n",
        "+ np.hstack"
      ],
      "metadata": {
        "id": "CVEBKuVbpADq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "EH8ZO2DLTrsn",
        "outputId": "c61c0ebe-aa0b-4850-f4d2-737a351406dd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "np.random.seed(0)\n",
        "\n",
        "x11 = np.random.uniform(low=0, high=5, size=(50,))\n",
        "x12 = np.random.uniform(low=10, high=15, size=(50,))\n",
        "x21 = np.random.uniform(low=0, high=5, size=(50,))\n",
        "x22 = np.random.uniform(low=10, high=15, size=(50,))\n",
        "\n",
        "\n",
        "x1 = np.append(x11, x12)\n",
        "x2 = np.append(x21, x22)\n",
        "\n",
        "y11 = np.random.uniform(low=10, high=15, size=(50,))\n",
        "y12 = np.random.uniform(low=0, high=5, size=(50,))\n",
        "y21 = np.random.uniform(low=0, high=5, size=(50,))\n",
        "y22 = np.random.uniform(low=10, high=15, size=(50,))\n",
        "\n",
        "y1 = np.append(y11, y12)\n",
        "y2 = np.append(y21, y22)\n",
        "\n",
        "x_1 = np.vstack([x1, y1]).T\n",
        "x_2 = np.vstack([x2, y2]).T\n",
        "y_1 = np.ones_like(x_1[:, 0])\n",
        "y_2 = np.zeros_like(x_2[:, 0])\n",
        "x = np.vstack([x_1, x_2])\n",
        "y = np.hstack([y_1, y_2])\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (12,5))\n",
        "ax.plot(x_1[:, 0], x_1[:,1], 'bo')\n",
        "ax.plot(x_2[:,0], x_2[:,1], 'ro')\n",
        "ax.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwDCWk-BTrsp"
      },
      "source": [
        "### 문제 1-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hANX6KQgTrsp"
      },
      "source": [
        "단층 퍼셉트론으로 위의 문제를 해결할 수 없음을 확인해보겠습니다. 이진 분류를 위한 단층 퍼셉트론을 구현하기 위해 다음 빈칸에 들어갈 내용으로 알맞은 것은?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VPqCI_xkTrsq",
        "outputId": "192e706b-e2ba-46a1-b1f7-32c02853d9a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "7/7 [==============================] - 1s 5ms/step - loss: 1.7230 - accuracy: 0.3050\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.2017 - accuracy: 0.3350\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.9672 - accuracy: 0.4200\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.8563 - accuracy: 0.3700\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.7661 - accuracy: 0.3900\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.7428 - accuracy: 0.5450\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.7118 - accuracy: 0.5100\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6996 - accuracy: 0.4600\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.7013 - accuracy: 0.5100\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.7010 - accuracy: 0.4650\n",
            "--------------------\n",
            "[[0.52595586]\n",
            " [0.5315632 ]\n",
            " [0.52698797]\n",
            " [0.5241732 ]\n",
            " [0.5217623 ]\n",
            " [0.5229445 ]\n",
            " [0.53057414]\n",
            " [0.52879936]\n",
            " [0.5301067 ]\n",
            " [0.53333336]] (200, 1)\n",
            "\n",
            "-------------------\n",
            "[0.52595586 0.5315632  0.52698797 0.5241732  0.5217623  0.5229445\n",
            " 0.53057414 0.52879936 0.5301067  0.53333336] (200,)\n",
            "\n",
            "-------------------\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 1\n",
            " 0 0 0 1 0 1 1 1 1 0 0 0 0 0 1 1 1 0 0 0 1 0 1 1 1 0 1 1 0 1 0 1 0 1 0 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] (200,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x, y, epochs=10)\n",
        "\n",
        "# 각각의 변수 명을 모두 다르게 설정했습니다.\n",
        "# model.predict의 결과값 / preds_1d / pred_class 의 형태(shape)와 값들을 한번 직접 확인해보세요\n",
        "\n",
        "preds = model.predict(x)\n",
        "preds_1d = preds.flatten()\n",
        "pred_class = np.where(preds_1d > 0.5, 1 , 0)\n",
        "\n",
        "print('--------------------')\n",
        "print(preds[0:10], preds.shape)\n",
        "print('\\n-------------------')\n",
        "print(preds_1d[0:10], preds_1d.shape)\n",
        "print('\\n-------------------')\n",
        "print(pred_class, pred_class.shape)\n",
        "\n",
        "y_true = x[pred_class==1]\n",
        "y_false = x[pred_class==0]\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (12,5))\n",
        "ax.plot(y_true[:, 0], y_true[:,1], 'bo')\n",
        "ax.plot(y_false[:,0], y_false[:,1], 'ro')\n",
        "ax.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3bNmudFTrsr"
      },
      "source": [
        "### 문제 1-2\n",
        "비선형성이 추가되지 않은 단층 퍼셉트론이 어떠한 결정 경계를 만드나요?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "비선형성 == 곡선 이라고 가정하면,\n",
        "곡선이 추가되지 않은 단층 퍼셉트론이 어떠한 결정 경계를 만드나요?\n",
        "직선 결정 경계를 만든다."
      ],
      "metadata": {
        "id": "gM8s-7G1sMlT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvNvoQJk-xb-"
      },
      "source": [
        "## 문제2. 실제 데이터 과제\n",
        " - 아래 주어진 데이터를 신경망을 이용하여 Classification 문제를 풀어보세요.\n",
        " - 또한 머신러닝에서 배운 방법(배우지 않은 머신러닝 방법론(SVM 등)도 가능)을 이용하여 비교해보세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqOkgM9wnmNu"
      },
      "source": [
        "입력 데이터 샘플과 Features : 1077 샘플 x 69 Features (변수)\n",
        "\n",
        "데이터 label: 다운증후군 (1), 정상군 (2)\n",
        "\n",
        "데이터는 다운증후군과 정상군 마우스 피질의 핵 분획에서 검출 가능한 신호를 생성하는 69 개 단백질의 발현 수준으로 구성되어 있습니다.\n",
        "라벨로는 다운증후군 1, 정상군 2로 할당되어 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gULuO1ETO-6G"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_excel(\"https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/MouseProtein/mouse_protein_X.xls\", header=None)\n",
        "df_label = pd.read_excel(\"https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/MouseProtein/mouse_protein_label.xls\", header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "6I-8OQ_APLtG",
        "outputId": "b20a47d6-7886-4942-e402-362aaf142a04"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d1ab6b09-bf66-44cb-992a-84de23d75859\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.50364</td>\n",
              "      <td>0.74719</td>\n",
              "      <td>0.43018</td>\n",
              "      <td>2.8163</td>\n",
              "      <td>5.9902</td>\n",
              "      <td>0.21883</td>\n",
              "      <td>0.17757</td>\n",
              "      <td>2.3737</td>\n",
              "      <td>0.23222</td>\n",
              "      <td>1.7509</td>\n",
              "      <td>0.68791</td>\n",
              "      <td>0.30638</td>\n",
              "      <td>0.40270</td>\n",
              "      <td>0.29693</td>\n",
              "      <td>1.02210</td>\n",
              "      <td>0.60567</td>\n",
              "      <td>1.8777</td>\n",
              "      <td>2.3087</td>\n",
              "      <td>0.44160</td>\n",
              "      <td>0.85937</td>\n",
              "      <td>0.41629</td>\n",
              "      <td>0.36961</td>\n",
              "      <td>0.17894</td>\n",
              "      <td>1.8664</td>\n",
              "      <td>3.6852</td>\n",
              "      <td>1.5372</td>\n",
              "      <td>0.26453</td>\n",
              "      <td>0.31968</td>\n",
              "      <td>0.81387</td>\n",
              "      <td>0.16585</td>\n",
              "      <td>0.45391</td>\n",
              "      <td>3.0376</td>\n",
              "      <td>0.36951</td>\n",
              "      <td>0.45854</td>\n",
              "      <td>0.33534</td>\n",
              "      <td>0.82519</td>\n",
              "      <td>0.57692</td>\n",
              "      <td>0.44810</td>\n",
              "      <td>0.58627</td>\n",
              "      <td>0.39472</td>\n",
              "      <td>0.33957</td>\n",
              "      <td>0.48286</td>\n",
              "      <td>0.29417</td>\n",
              "      <td>0.18215</td>\n",
              "      <td>0.84273</td>\n",
              "      <td>0.19261</td>\n",
              "      <td>1.4431</td>\n",
              "      <td>0.29470</td>\n",
              "      <td>0.35460</td>\n",
              "      <td>1.3391</td>\n",
              "      <td>0.17012</td>\n",
              "      <td>0.15910</td>\n",
              "      <td>0.18885</td>\n",
              "      <td>0.10631</td>\n",
              "      <td>0.14499</td>\n",
              "      <td>0.17667</td>\n",
              "      <td>0.12519</td>\n",
              "      <td>0.11529</td>\n",
              "      <td>0.22804</td>\n",
              "      <td>0.14276</td>\n",
              "      <td>0.43096</td>\n",
              "      <td>0.24754</td>\n",
              "      <td>1.6033</td>\n",
              "      <td>2.0149</td>\n",
              "      <td>0.10823</td>\n",
              "      <td>1.04500</td>\n",
              "      <td>0.83156</td>\n",
              "      <td>0.18885</td>\n",
              "      <td>1.6757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.51462</td>\n",
              "      <td>0.68906</td>\n",
              "      <td>0.41177</td>\n",
              "      <td>2.7895</td>\n",
              "      <td>5.6850</td>\n",
              "      <td>0.21164</td>\n",
              "      <td>0.17282</td>\n",
              "      <td>2.2921</td>\n",
              "      <td>0.22697</td>\n",
              "      <td>1.5964</td>\n",
              "      <td>0.69501</td>\n",
              "      <td>0.29905</td>\n",
              "      <td>0.38599</td>\n",
              "      <td>0.28132</td>\n",
              "      <td>0.95668</td>\n",
              "      <td>0.58756</td>\n",
              "      <td>1.7258</td>\n",
              "      <td>2.0430</td>\n",
              "      <td>0.44522</td>\n",
              "      <td>0.83466</td>\n",
              "      <td>0.40036</td>\n",
              "      <td>0.35618</td>\n",
              "      <td>0.17368</td>\n",
              "      <td>1.7610</td>\n",
              "      <td>3.4853</td>\n",
              "      <td>1.5092</td>\n",
              "      <td>0.25573</td>\n",
              "      <td>0.30442</td>\n",
              "      <td>0.78050</td>\n",
              "      <td>0.15719</td>\n",
              "      <td>0.43094</td>\n",
              "      <td>2.9219</td>\n",
              "      <td>0.34228</td>\n",
              "      <td>0.42356</td>\n",
              "      <td>0.32483</td>\n",
              "      <td>0.76172</td>\n",
              "      <td>0.54510</td>\n",
              "      <td>0.42088</td>\n",
              "      <td>0.54510</td>\n",
              "      <td>0.36825</td>\n",
              "      <td>0.32196</td>\n",
              "      <td>0.45452</td>\n",
              "      <td>0.27643</td>\n",
              "      <td>0.18209</td>\n",
              "      <td>0.84761</td>\n",
              "      <td>0.19482</td>\n",
              "      <td>1.4395</td>\n",
              "      <td>0.29406</td>\n",
              "      <td>0.35455</td>\n",
              "      <td>1.3063</td>\n",
              "      <td>0.17143</td>\n",
              "      <td>0.15813</td>\n",
              "      <td>0.18457</td>\n",
              "      <td>0.10659</td>\n",
              "      <td>0.15047</td>\n",
              "      <td>0.17831</td>\n",
              "      <td>0.13428</td>\n",
              "      <td>0.11823</td>\n",
              "      <td>0.23807</td>\n",
              "      <td>0.14204</td>\n",
              "      <td>0.45716</td>\n",
              "      <td>0.25763</td>\n",
              "      <td>1.6717</td>\n",
              "      <td>2.0046</td>\n",
              "      <td>0.10975</td>\n",
              "      <td>1.00990</td>\n",
              "      <td>0.84927</td>\n",
              "      <td>0.20040</td>\n",
              "      <td>1.7436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.50918</td>\n",
              "      <td>0.73025</td>\n",
              "      <td>0.41831</td>\n",
              "      <td>2.6872</td>\n",
              "      <td>5.6221</td>\n",
              "      <td>0.20901</td>\n",
              "      <td>0.17572</td>\n",
              "      <td>2.2833</td>\n",
              "      <td>0.23025</td>\n",
              "      <td>1.5613</td>\n",
              "      <td>0.67735</td>\n",
              "      <td>0.29128</td>\n",
              "      <td>0.38100</td>\n",
              "      <td>0.28171</td>\n",
              "      <td>1.00360</td>\n",
              "      <td>0.60245</td>\n",
              "      <td>1.7319</td>\n",
              "      <td>2.0180</td>\n",
              "      <td>0.46767</td>\n",
              "      <td>0.81433</td>\n",
              "      <td>0.39985</td>\n",
              "      <td>0.36809</td>\n",
              "      <td>0.17390</td>\n",
              "      <td>1.7655</td>\n",
              "      <td>3.5715</td>\n",
              "      <td>1.5012</td>\n",
              "      <td>0.25961</td>\n",
              "      <td>0.31175</td>\n",
              "      <td>0.78515</td>\n",
              "      <td>0.16090</td>\n",
              "      <td>0.42319</td>\n",
              "      <td>2.9441</td>\n",
              "      <td>0.34370</td>\n",
              "      <td>0.42500</td>\n",
              "      <td>0.32485</td>\n",
              "      <td>0.75703</td>\n",
              "      <td>0.54362</td>\n",
              "      <td>0.40463</td>\n",
              "      <td>0.55299</td>\n",
              "      <td>0.36388</td>\n",
              "      <td>0.31309</td>\n",
              "      <td>0.44720</td>\n",
              "      <td>0.25665</td>\n",
              "      <td>0.18439</td>\n",
              "      <td>0.85617</td>\n",
              "      <td>0.20074</td>\n",
              "      <td>1.5244</td>\n",
              "      <td>0.30188</td>\n",
              "      <td>0.38609</td>\n",
              "      <td>1.2796</td>\n",
              "      <td>0.18546</td>\n",
              "      <td>0.14870</td>\n",
              "      <td>0.19053</td>\n",
              "      <td>0.10830</td>\n",
              "      <td>0.14533</td>\n",
              "      <td>0.17621</td>\n",
              "      <td>0.13256</td>\n",
              "      <td>0.11776</td>\n",
              "      <td>0.24482</td>\n",
              "      <td>0.14244</td>\n",
              "      <td>0.51047</td>\n",
              "      <td>0.25534</td>\n",
              "      <td>1.6635</td>\n",
              "      <td>2.0168</td>\n",
              "      <td>0.10820</td>\n",
              "      <td>0.99685</td>\n",
              "      <td>0.84671</td>\n",
              "      <td>0.19368</td>\n",
              "      <td>1.9264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.44211</td>\n",
              "      <td>0.61708</td>\n",
              "      <td>0.35863</td>\n",
              "      <td>2.4669</td>\n",
              "      <td>4.9795</td>\n",
              "      <td>0.22289</td>\n",
              "      <td>0.17646</td>\n",
              "      <td>2.1523</td>\n",
              "      <td>0.20700</td>\n",
              "      <td>1.5951</td>\n",
              "      <td>0.58328</td>\n",
              "      <td>0.29673</td>\n",
              "      <td>0.37709</td>\n",
              "      <td>0.31383</td>\n",
              "      <td>0.87539</td>\n",
              "      <td>0.52029</td>\n",
              "      <td>1.5669</td>\n",
              "      <td>2.1328</td>\n",
              "      <td>0.47767</td>\n",
              "      <td>0.72770</td>\n",
              "      <td>0.38564</td>\n",
              "      <td>0.36297</td>\n",
              "      <td>0.17945</td>\n",
              "      <td>1.2863</td>\n",
              "      <td>2.9701</td>\n",
              "      <td>1.4197</td>\n",
              "      <td>0.25954</td>\n",
              "      <td>0.27922</td>\n",
              "      <td>0.73449</td>\n",
              "      <td>0.16221</td>\n",
              "      <td>0.41061</td>\n",
              "      <td>2.5002</td>\n",
              "      <td>0.34451</td>\n",
              "      <td>0.42921</td>\n",
              "      <td>0.33012</td>\n",
              "      <td>0.74698</td>\n",
              "      <td>0.54676</td>\n",
              "      <td>0.38686</td>\n",
              "      <td>0.54785</td>\n",
              "      <td>0.36677</td>\n",
              "      <td>0.32849</td>\n",
              "      <td>0.44265</td>\n",
              "      <td>0.39853</td>\n",
              "      <td>0.16177</td>\n",
              "      <td>0.76023</td>\n",
              "      <td>0.18417</td>\n",
              "      <td>1.6124</td>\n",
              "      <td>0.29638</td>\n",
              "      <td>0.29068</td>\n",
              "      <td>1.1988</td>\n",
              "      <td>0.15980</td>\n",
              "      <td>0.16611</td>\n",
              "      <td>0.18532</td>\n",
              "      <td>0.10318</td>\n",
              "      <td>0.14066</td>\n",
              "      <td>0.16380</td>\n",
              "      <td>0.12321</td>\n",
              "      <td>0.11744</td>\n",
              "      <td>0.23495</td>\n",
              "      <td>0.14507</td>\n",
              "      <td>0.43100</td>\n",
              "      <td>0.25110</td>\n",
              "      <td>1.4846</td>\n",
              "      <td>1.9572</td>\n",
              "      <td>0.11988</td>\n",
              "      <td>0.99022</td>\n",
              "      <td>0.83328</td>\n",
              "      <td>0.19211</td>\n",
              "      <td>1.7006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.43494</td>\n",
              "      <td>0.61743</td>\n",
              "      <td>0.35880</td>\n",
              "      <td>2.3658</td>\n",
              "      <td>4.7187</td>\n",
              "      <td>0.21311</td>\n",
              "      <td>0.17363</td>\n",
              "      <td>2.1340</td>\n",
              "      <td>0.19216</td>\n",
              "      <td>1.5042</td>\n",
              "      <td>0.55096</td>\n",
              "      <td>0.28696</td>\n",
              "      <td>0.36350</td>\n",
              "      <td>0.27796</td>\n",
              "      <td>0.86491</td>\n",
              "      <td>0.50799</td>\n",
              "      <td>1.4801</td>\n",
              "      <td>2.0137</td>\n",
              "      <td>0.48342</td>\n",
              "      <td>0.68779</td>\n",
              "      <td>0.36753</td>\n",
              "      <td>0.35531</td>\n",
              "      <td>0.17484</td>\n",
              "      <td>1.3247</td>\n",
              "      <td>2.8963</td>\n",
              "      <td>1.3599</td>\n",
              "      <td>0.25070</td>\n",
              "      <td>0.27367</td>\n",
              "      <td>0.70270</td>\n",
              "      <td>0.15483</td>\n",
              "      <td>0.39855</td>\n",
              "      <td>2.4566</td>\n",
              "      <td>0.32913</td>\n",
              "      <td>0.40876</td>\n",
              "      <td>0.31341</td>\n",
              "      <td>0.69196</td>\n",
              "      <td>0.53686</td>\n",
              "      <td>0.36082</td>\n",
              "      <td>0.51282</td>\n",
              "      <td>0.35155</td>\n",
              "      <td>0.31221</td>\n",
              "      <td>0.41909</td>\n",
              "      <td>0.39345</td>\n",
              "      <td>0.16020</td>\n",
              "      <td>0.76811</td>\n",
              "      <td>0.18572</td>\n",
              "      <td>1.6458</td>\n",
              "      <td>0.29683</td>\n",
              "      <td>0.30935</td>\n",
              "      <td>1.2070</td>\n",
              "      <td>0.16465</td>\n",
              "      <td>0.16069</td>\n",
              "      <td>0.18822</td>\n",
              "      <td>0.10478</td>\n",
              "      <td>0.14198</td>\n",
              "      <td>0.16771</td>\n",
              "      <td>0.13684</td>\n",
              "      <td>0.11605</td>\n",
              "      <td>0.25553</td>\n",
              "      <td>0.14087</td>\n",
              "      <td>0.48123</td>\n",
              "      <td>0.25177</td>\n",
              "      <td>1.5348</td>\n",
              "      <td>2.0091</td>\n",
              "      <td>0.11952</td>\n",
              "      <td>0.99777</td>\n",
              "      <td>0.87867</td>\n",
              "      <td>0.20560</td>\n",
              "      <td>1.8397</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1ab6b09-bf66-44cb-992a-84de23d75859')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d1ab6b09-bf66-44cb-992a-84de23d75859 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d1ab6b09-bf66-44cb-992a-84de23d75859');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        0        1        2       3   ...       65       66       67      68\n",
              "0  0.50364  0.74719  0.43018  2.8163  ...  1.04500  0.83156  0.18885  1.6757\n",
              "1  0.51462  0.68906  0.41177  2.7895  ...  1.00990  0.84927  0.20040  1.7436\n",
              "2  0.50918  0.73025  0.41831  2.6872  ...  0.99685  0.84671  0.19368  1.9264\n",
              "3  0.44211  0.61708  0.35863  2.4669  ...  0.99022  0.83328  0.19211  1.7006\n",
              "4  0.43494  0.61743  0.35880  2.3658  ...  0.99777  0.87867  0.20560  1.8397\n",
              "\n",
              "[5 rows x 69 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# 샘플당 100개의 특성(feature)을 가진 데이터\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrIvw52rPdx4",
        "outputId": "4ab8eb46-9d99-43b7-f6cf-03bd7f399aa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   0\n",
            "0  1\n",
            "1  1\n",
            "2  1\n",
            "3  1\n",
            "4  1\n",
            "      0\n",
            "1072  2\n",
            "1073  2\n",
            "1074  2\n",
            "1075  2\n",
            "1076  2\n"
          ]
        }
      ],
      "source": [
        "print(df_label.head())\n",
        "print(df_label.tail())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "print(list(df.isna().sum()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwLBCCf79SDr",
        "outputId": "555b5330-183c-4323-ca91-520852e821bd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yilj1IY3M4Zr"
      },
      "source": [
        "---\n",
        "\n",
        "4-1. 사용한 모델을 입력합니다. \n",
        "\n",
        "4-2. Accuracy를 입력합니다. \n",
        "\n",
        "4-3. Precision 을 입력합니다. \n",
        "\n",
        "4-4. Recall 을 입력합니다.\n",
        "\n",
        "4-5. F1 score 를 입력합니다. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recall(y_target, y_pred):\n",
        "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
        "    # round : 반올림한다\n",
        "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
        "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
        "\n",
        "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
        "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
        "\n",
        "    # (True Positive + False Negative) = 실제 값이 1(Positive) 전체\n",
        "    count_true_positive_false_negative = K.sum(y_target_yn)\n",
        "\n",
        "    # Recall =  (True Positive) / (True Positive + False Negative)\n",
        "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
        "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
        "\n",
        "    # return a single tensor value\n",
        "    return recall\n",
        "\n",
        "\n",
        "def precision(y_target, y_pred):\n",
        "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
        "    # round : 반올림한다\n",
        "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
        "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
        "\n",
        "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
        "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
        "\n",
        "    # (True Positive + False Positive) = 예측 값이 1(Positive) 전체\n",
        "    count_true_positive_false_positive = K.sum(y_pred_yn)\n",
        "\n",
        "    # Precision = (True Positive) / (True Positive + False Positive)\n",
        "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
        "    precision = count_true_positive / (count_true_positive_false_positive + K.epsilon())\n",
        "\n",
        "    # return a single tensor value\n",
        "    return precision\n",
        "\n",
        "\n",
        "def f1score(y_target, y_pred):\n",
        "    _recall = recall(y_target, y_pred)\n",
        "    _precision = precision(y_target, y_pred)\n",
        "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
        "    _f1score = ( 2 * _recall * _precision) / (_recall + _precision+ K.epsilon())\n",
        "    \n",
        "    # return a single tensor value\n",
        "    return _f1score"
      ],
      "metadata": {
        "id": "2KYWbmZ_Ff-s"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(df, df_label, train_size=0.80, test_size=0.20, random_state=2)\n",
        "x_train.shape,  x_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaaGbFUj2Bga",
        "outputId": "037d42a1-9668-4f46-be2a-42aa1490dcc0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((861, 69), (216, 69), (861, 1), (216, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy', precision, recall, f1score])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i05NX6Z3wvq9",
        "outputId": "c936e039-8674-4901-c8f3-51f5f86b0b6a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "27/27 [==============================] - 1s 2ms/step - loss: -4.1454 - accuracy: 0.5017 - precision: 0.9630 - recall: 0.9456 - f1score: 0.9516            \n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -41.8933 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 0s 3ms/step - loss: -368.2450 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -3238.7812 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -28569.6543 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -251605.2969 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 0s 3ms/step - loss: -2211006.2500 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -19429876.0000 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -170912944.0000 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -1504488832.0000 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdd250ddb50>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_add_relu = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_add_relu.compile(optimizer='sgd',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy', precision, recall, f1score])\n",
        "\n",
        "model_add_relu.fit(x_train, y_train, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TgZu8_LN-6Z",
        "outputId": "dfa1bef8-9eb8-4172-ae76-6ef817c97e0f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "27/27 [==============================] - 1s 2ms/step - loss: -5.9567 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -57.4477 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -507.1549 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -4462.3037 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -39077.0625 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 0s 3ms/step - loss: -343753.2500 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -3030039.7500 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -26614398.0000 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -234280256.0000 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 0s 3ms/step - loss: -2057794944.0000 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdd248159d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_relu_adam = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_relu_adam.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy', precision, recall, f1score])\n",
        "\n",
        "model_relu_adam.fit(x_train, y_train, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jutZo5xKOBpW",
        "outputId": "a4a0fb46-295e-495b-8a76-1f8d21c85c0d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "27/27 [==============================] - 1s 2ms/step - loss: -1.6608 - accuracy: 0.4901 - precision: 0.9630 - recall: 0.9155 - f1score: 0.9250\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -6.8109 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -15.0347 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -27.3547 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -44.2132 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -65.7093 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -92.5058 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -123.8944 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -160.4648 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 0s 2ms/step - loss: -201.1001 - accuracy: 0.5319 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdd246befd0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model, sigmoid\n",
        "# activation : sgd\n",
        "# fit에서 epoch를 늘렸을 때, loss만 늘어난다.\n",
        "preds = model.predict(x_test)\n",
        "\n",
        "results = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(\"test [loss, acc,  precision, recall, f1score] :\", results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8NZPTZaxUBP",
        "outputId": "e7dabff0-2281-4e69-c6dd-3d2e33d90ce9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 - 0s - loss: -4.0344e+09 - accuracy: 0.5185 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - 272ms/epoch - 39ms/step\n",
            "test [loss, acc,  precision, recall, f1score] : [-4034381056.0, 0.5185185074806213, 1.0, 1.0, 1.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_add_relu\n",
        "# model : relu, sigmoid\n",
        "# activation : sgd\n",
        "preds = model_add_relu.predict(x_test)\n",
        "\n",
        "results = model_add_relu.evaluate(x_test, y_test, verbose=2)\n",
        "print(\"test [loss, acc,  precision, recall, f1score]\", results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pYnbDcWNijh",
        "outputId": "937e3df7-2c90-40ef-ec02-4d3bb78c1c65"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 - 0s - loss: -5.5410e+09 - accuracy: 0.5185 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - 241ms/epoch - 34ms/step\n",
            "test [loss, acc,  precision, recall, f1score] [-5541036544.0, 0.5185185074806213, 1.0, 1.0, 1.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_add_relu, relu, sigmoid\n",
        "# model : relu, sigmoid\n",
        "# activation : adam\n",
        "\n",
        "preds = model_relu_adam.predict(x_test)\n",
        "\n",
        "results = model_relu_adam.evaluate(x_test, y_test, verbose=2)\n",
        "print(\"test [loss, test acc,  precision, recall, f1score]\", results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8sOxPzAOIGt",
        "outputId": "6376deea-e6be-4b44-eef2-4a78b39b8b06"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 - 0s - loss: -2.3489e+02 - accuracy: 0.5185 - precision: 1.0000 - recall: 1.0000 - f1score: 1.0000 - 227ms/epoch - 32ms/step\n",
            "test [loss, test acc,  precision, recall, f1score] [-234.88844299316406, 0.5185185074806213, 1.0, 1.0, 1.0]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "ds_cs_N421a.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}