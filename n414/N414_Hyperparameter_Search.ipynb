{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "N414_Hyperparameters.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEjsZ-UJyd-J"
      },
      "source": [
        "<img align=\"right\" src=\"https://ds-cs-images.s3.ap-northeast-2.amazonaws.com/Codestates_Fulllogo_Color.png\" width=100>\n",
        "\n",
        "## *AIB / SECTION 4 / SPRINT 1 / NOTE 4*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2psQ6JRyfPA"
      },
      "source": [
        "# N414. Hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PI1IG0h6byq"
      },
      "source": [
        "## 하이퍼파라미터(Hyperparameter) 튜닝으로 성능 올리기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kM-SsRyN60Va"
      },
      "source": [
        "신경망에서는 신경써야 할 **<font color=\"ff6f61\">하이퍼파라미터(Hyperparameter)</font>**가 굉장히 많습니다.<br/>\n",
        "지금까지 다뤄온 머신러닝 알고리즘은 많아야 20개 정도의 하이퍼파라미터를 탐색하면 되었습니다.<br/>\n",
        "하지만 신경망은 층을 깊게 쌓을수록 조정해주어야 할 하이퍼파라미터가 훨씬 더 많아지게 됩니다.\n",
        "\n",
        "**하이퍼파라미터 조정(Tuning)**은 모델 성능에 엄청난 영향을 끼치는 요소이기 때문에 시간이 많이 소요되더라도 반드시 해주어야 합니다.<br/>\n",
        "좋은 하이퍼파라미터를 찾기란 결코 쉽지 않습니다.<br/>\n",
        "운좋게도 임의로 입력한 하이퍼파라미터가 만족스런 성능을 보일 수는 있지만 **'기도메타'가 언제나 우리에게 성공을 보장하지는 않죠.**<br/>\n",
        "그렇다면 결정한 하이퍼파라미터로 구축한 모델이 좋은 성능을 보이는지를 어떻게 알 수 있을까요?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://i.imgur.com/1MMrBS5.png\" height = \"200\"/>\n"
      ],
      "metadata": {
        "id": "wVHHFQrh-9A-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "지난 강의에서 위 그림을 보며 '딥러닝도 머신러닝'임을 말씀드렸는데요.\n",
        "\n",
        "머신러닝 알고리즘을 다룰 때에 일반적인 모델의 성능을 평가하기 위해서 **<font color=\"ff6f61\">교차 검증(Cross-Validation)</font>**을 사용했던 것처럼<br/>\n",
        "신경망도 교차 검증을 사용하여 일반화 성능을 평가할 수 있습니다.\n",
        "\n",
        "아래 코드를 통해 신경망에 교차 검증을 적용하는 방법에 대해 알아보겠습니다."
      ],
      "metadata": {
        "id": "nHb17Vrt_DK8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KurGphTOjUoa"
      },
      "source": [
        "### 신경망으로 Boston 집값 데이터 예제 해결하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAxXZWvzzNB3"
      },
      "source": [
        "보스턴 집값 데이터셋(**`boston_housing`**) 예제를 신경망으로 풀어보겠습니다.<br/>\n",
        "문제를 푸는 과정에서 교차 검증을 적용하여 풀어보도록 하겠습니다!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cerYfDfyEhHL"
      },
      "source": [
        "1. **데이터셋을 불러옵니다.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6ZsMjdQyPmX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ff2fd10-faa8-41ea-ab6c-a80c1763c50c"
      },
      "source": [
        "from tensorflow.keras.datasets import boston_housing\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57344/57026 [==============================] - 0s 0us/step\n",
            "65536/57026 [==================================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mJIYb08pwrR"
      },
      "source": [
        "### 신경망에 교차 검증(Cross-Validation) 적용해보기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TG_q669kzQO4"
      },
      "source": [
        "> ❗️ ***머신러닝에서 배운 교차 검증이 기억이 잘 안난다면 Section 2 로 돌아가 해당 내용을 복습해주세요!***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiGuKDqWEmCz"
      },
      "source": [
        "2. **필요한 라이브러리를 import 합니다.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qAKKzvpzUQ7"
      },
      "source": [
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aNBG2G8E_XK"
      },
      "source": [
        "3. **`KFold`를 통해 학습 데이터셋을 몇 개(k)로 나눌지를 결정합니다.**\n",
        "\n",
        "아래에서는 많이 사용되는 k인 5로 설정해보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4A7XVMcQEzNf",
        "outputId": "e556a07b-abb0-4731-dbb7-aebca265c583"
      },
      "source": [
        "kf = KFold(n_splits = 5)\n",
        "skf = StratifiedKFold(n_splits = 5, random_state = 42, shuffle = True) \n",
        "\n",
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(404, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUXqIKI4FSfp"
      },
      "source": [
        "> ❓ ***`KFold`와 `StratifiedKFold`의 차이는 무엇일지 다시 떠올려봅시다.<br/>\n",
        "어떤 경우에 `KFold`가 아닌 `StratifiedKFold`를 써주어야 할까요?***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ki-Bk4Z-zZHI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ad83335-809e-411d-9c49-232ee0d793cc"
      },
      "source": [
        "y_train[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([15.2, 42.3, 50. , 21.1, 17.7])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lliEB-aNzSnI"
      },
      "source": [
        "> ❗️ ***아래부터 등장하는 코드는 고의적으로 에러를 발생하도록 쓰여 있습니다. 설명을 충분히 읽으면서 실행해 주세요!***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1WAKAjnzbVC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "df83ee76-6253-476b-de24-ddcae2e5d621"
      },
      "source": [
        "training_data = x_train.iloc[train_index]\n",
        "validation_data = x_train.iloc[val_index]\n",
        "\n",
        "# for train_index, val_index in kf.split(np.zeros(x_train.shape[0]),y_train):\n",
        "#   training_data = x_train.iloc[train_index]\n",
        "#   validation_data = x_train.iloc[val_index]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-53c6661f6ff4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# for train_index, val_index in kf.split(np.zeros(x_train.shape[0]),y_train):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#   training_data = x_train.iloc[train_index]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'iloc'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p420wHyzzd33"
      },
      "source": [
        "위처럼 **Numpy array 에서는 `.iloc` 을 쓸 수 없겠죠?**<br/>\n",
        "그러니 **`pd.DataFrame()`** 을 이용해보겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh4JEEryzhTU"
      },
      "source": [
        "x_train = pd.DataFrame(x_train)\n",
        "y_train = pd.DataFrame(y_train)\n",
        "\n",
        "for train_index, val_index in kf.split(np.zeros(x_train.shape[0]), y_train):\n",
        "    training_data = x_train.iloc[train_index]\n",
        "    validation_data = x_train.iloc[val_index]\n",
        "    training_y = y_train.iloc[train_index]\n",
        "    validation_y = y_train.iloc[val_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ol9ACHSxzkl8"
      },
      "source": [
        "아래 코드에서는 모델을 불러오는데 에러가 납니다! 무엇 때문에 나는 에러일까요?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-s8hCNrzmlZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "5b669949-17c5-4109-b402-62d9f33e6d10"
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-82ef346ff754>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgWBVQRVzort"
      },
      "source": [
        "에러명을 살펴보면 `NameError: name 'Sequential' is not defined` 입니다.<br/>\n",
        "**`Sequential`이 defined 되지 않았다는 뜻이므로 해당 패키지(`Sequential`)를 import** 해주어 해결해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HouKt58HzqW0"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "model = Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEvnNciwzuj_"
      },
      "source": [
        "이번에는 Dense를 추가해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axPe91tuzwJv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "821bdebb-1d41-445e-d50a-e7e8e86454c3"
      },
      "source": [
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-8a2b07a9a70f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Dense' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhs-b8Alzw5L"
      },
      "source": [
        "에러명 `NameError: name 'Dense' is not defined` 을 살펴보니 동일한 에러임을 알 수 있습니다.<br/>\n",
        "**같은 유형의 에러이므로 같은 방법으로 해결**해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_A4RfxG9zyUI"
      },
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "\n",
        "model.compile(loss='mean_squared_logarithmic_error',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOLwqWJdz0hh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "640d4c12-e765-4ff0-afc3-d1f187bd2d0b"
      },
      "source": [
        "model.fit(training_data, training_y, epochs=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "11/11 [==============================] - 1s 3ms/step - loss: 0.6799 - accuracy: 0.0000e+00\n",
            "Epoch 2/2\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1771 - accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff577b95f10>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcKgNETVzz8U"
      },
      "source": [
        "위 코드까지 모델이 잘 돌아가는 것을 확인하였습니다.\n",
        "\n",
        "이제는 **교차 검증(Cross-Validation)을 적용할 차례**입니다.<br/>\n",
        "다시 학습 데이터셋(**`x_train, y_train`**)을 k개 의 set으로 나누어주겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LO7GJKEFz0YZ"
      },
      "source": [
        "x_train = pd.DataFrame(x_train)\n",
        "y_train = pd.DataFrame(y_train)\n",
        "\n",
        "for train_index, val_index in kf.split(np.zeros(x_train.shape[0]),y_train):\n",
        "    training_data = x_train.iloc[train_index, :]\n",
        "    training_data_label = y_train.iloc[train_index]\n",
        "    validation_data = x_train.iloc[val_index, :]\n",
        "    validation_data_label = y_train.iloc[val_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSjaGn8LISTq"
      },
      "source": [
        "다시 모델을 학습시켜줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jAr9QxQz7G_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b9c147e-70e4-4b9c-d82b-08e4d8801bec"
      },
      "source": [
        "model.fit(training_data, training_data_label,\n",
        "\t\t\tepochs=10,\n",
        "            batch_size=64,\n",
        "\t\t\tvalidation_data=(validation_data, validation_data_label),\n",
        "          )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.1255 - accuracy: 0.0000e+00 - val_loss: 0.1453 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1206 - accuracy: 0.0000e+00 - val_loss: 0.0984 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1060 - accuracy: 0.0000e+00 - val_loss: 0.0939 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0924 - accuracy: 0.0000e+00 - val_loss: 0.0979 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0957 - accuracy: 0.0000e+00 - val_loss: 0.0948 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0881 - accuracy: 0.0000e+00 - val_loss: 0.0916 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0888 - accuracy: 0.0000e+00 - val_loss: 0.1016 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0856 - accuracy: 0.0000e+00 - val_loss: 0.0930 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0910 - accuracy: 0.0000e+00 - val_loss: 0.0816 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0963 - accuracy: 0.0000e+00 - val_loss: 0.0933 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff577b1bb90>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTE8_O53z9tc"
      },
      "source": [
        "데이터가 잘 나누어져 들어갔는지 확인해봅니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYhxLVWDz9in",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edbd7245-8da6-423e-cd2d-640daf95f638"
      },
      "source": [
        "print(training_data[:2])\n",
        "print(training_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        0     1     2    3      4   ...   8      9     10      11     12\n",
            "0  1.23247   0.0  8.14  0.0  0.538  ...  4.0  307.0  21.0  396.90  18.72\n",
            "1  0.02177  82.5  2.03  0.0  0.415  ...  2.0  348.0  14.7  395.38   3.11\n",
            "\n",
            "[2 rows x 13 columns]\n",
            "(324, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUzUjOoG0Bft",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "93abb1db-34c4-44f3-dd07-1272261f79d4"
      },
      "source": [
        "training_data_label[:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>42.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0\n",
              "0  15.2\n",
              "1  42.3"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6XOWNZL0BdF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5b9c789-dc3d-49a8-e1c5-b8f9a4c50d3a"
      },
      "source": [
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.fit(training_data, training_data_label,\n",
        "          epochs=10,\n",
        "          batch_size=32,\n",
        "          )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 89.6655\n",
            "Epoch 2/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 57.5176\n",
            "Epoch 3/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 55.1179\n",
            "Epoch 4/10\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 48.7623\n",
            "Epoch 5/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 45.9350\n",
            "Epoch 6/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 48.0356\n",
            "Epoch 7/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 57.1652\n",
            "Epoch 8/10\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 48.8794\n",
            "Epoch 9/10\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 55.9871\n",
            "Epoch 10/10\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 52.9977\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff577a54fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJsu0llu0EJF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e827d78a-de27-45d5-f4c2-ee08523015aa"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "model.fit(training_data, training_data_label,\n",
        "          epochs=10,\n",
        "          batch_size=32,\n",
        "          )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "11/11 [==============================] - 0s 3ms/step - loss: -321.4154\n",
            "Epoch 2/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: -321.4153\n",
            "Epoch 3/10\n",
            "11/11 [==============================] - 0s 4ms/step - loss: -321.4153\n",
            "Epoch 4/10\n",
            "11/11 [==============================] - 0s 3ms/step - loss: -321.4153\n",
            "Epoch 5/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: -321.4153\n",
            "Epoch 6/10\n",
            "11/11 [==============================] - 0s 2ms/step - loss: -321.4154\n",
            "Epoch 7/10\n",
            "11/11 [==============================] - 0s 3ms/step - loss: -321.4153\n",
            "Epoch 8/10\n",
            "11/11 [==============================] - 0s 3ms/step - loss: -321.4153\n",
            "Epoch 9/10\n",
            "11/11 [==============================] - 0s 4ms/step - loss: -321.4153\n",
            "Epoch 10/10\n",
            "11/11 [==============================] - 0s 3ms/step - loss: -321.4153\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff577ad16d0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQIBr1tn0GhB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e97ae257-8530-4dd8-d516-9c34b1d4092c"
      },
      "source": [
        "results = model.evaluate(x_test, y_test, batch_size=32)\n",
        "print(\"test loss, test mse:\", results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 4ms/step - loss: -336.6793\n",
            "test loss, test mse: -336.67926025390625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPAM9RT-0IJK"
      },
      "source": [
        "이제 한 번에 테스트를 수행해보겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX9WoRHF0IbT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9ae3ec4-05fe-431c-f2b8-728f8e994fb1"
      },
      "source": [
        "x_train = pd.DataFrame(x_train)\n",
        "y_train = pd.DataFrame(y_train)\n",
        "\n",
        "for train_index, val_index in kf.split(np.zeros(x_train.shape[0])):\n",
        "    training_data = x_train.iloc[train_index, :]\n",
        "    training_data_label = y_train.iloc[train_index]\n",
        "    validation_data = x_train.iloc[val_index, :]\n",
        "    validation_data_label = y_train.iloc[val_index]\n",
        "\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    model.fit(x_train, y_train,\n",
        "              epochs=10,\n",
        "              batch_size=32,\n",
        "              validation_data = (validation_data, validation_data_label),\n",
        "              )\n",
        "    \n",
        "    results = model.evaluate(x_test, y_test, batch_size=32)\n",
        "    print(\"test loss, test mse:\", results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "13/13 [==============================] - 1s 15ms/step - loss: 87.9968 - val_loss: 61.2588\n",
            "Epoch 2/10\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 56.3914 - val_loss: 65.1370\n",
            "Epoch 3/10\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 48.1239 - val_loss: 51.5774\n",
            "Epoch 4/10\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 45.7609 - val_loss: 35.4846\n",
            "Epoch 5/10\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 40.3047 - val_loss: 35.9572\n",
            "Epoch 6/10\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 40.5311 - val_loss: 35.7054\n",
            "Epoch 7/10\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 42.6978 - val_loss: 35.1698\n",
            "Epoch 8/10\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 41.6586 - val_loss: 39.4655\n",
            "Epoch 9/10\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 41.4178 - val_loss: 45.0892\n",
            "Epoch 10/10\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 41.3757 - val_loss: 35.8233\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 47.9519\n",
            "test loss, test mse: 47.95186996459961\n",
            "Epoch 1/10\n",
            "13/13 [==============================] - 1s 17ms/step - loss: 70.2954 - val_loss: 44.1809\n",
            "Epoch 2/10\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 40.2878 - val_loss: 40.0316\n",
            "Epoch 3/10\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 37.6616 - val_loss: 33.0579\n",
            "Epoch 4/10\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 34.8139 - val_loss: 36.4646\n",
            "Epoch 5/10\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 36.2531 - val_loss: 34.6442\n",
            "Epoch 6/10\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 34.1468 - val_loss: 42.0404\n",
            "Epoch 7/10\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 35.0177 - val_loss: 30.1739\n",
            "Epoch 8/10\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 37.0729 - val_loss: 30.0031\n",
            "Epoch 9/10\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 41.0808 - val_loss: 30.0008\n",
            "Epoch 10/10\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 37.3331 - val_loss: 31.3298\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 37.5463\n",
            "test loss, test mse: 37.54630661010742\n",
            "Epoch 1/10\n",
            "13/13 [==============================] - 1s 18ms/step - loss: 66.5721 - val_loss: 31.2368\n",
            "Epoch 2/10\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 49.1700 - val_loss: 23.7471\n",
            "Epoch 3/10\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 42.6045 - val_loss: 32.9881\n",
            "Epoch 4/10\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 41.1242 - val_loss: 33.7323\n",
            "Epoch 5/10\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 32.3226 - val_loss: 21.7318\n",
            "Epoch 6/10\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 32.9825 - val_loss: 20.3873\n",
            "Epoch 7/10\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 32.9742 - val_loss: 20.5657\n",
            "Epoch 8/10\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 35.4239 - val_loss: 20.3823\n",
            "Epoch 9/10\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 32.2412 - val_loss: 50.2622\n",
            "Epoch 10/10\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 38.6016 - val_loss: 24.7091\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 45.4481\n",
            "test loss, test mse: 45.448123931884766\n",
            "Epoch 1/10\n",
            "13/13 [==============================] - 1s 15ms/step - loss: 70.9410 - val_loss: 54.9981\n",
            "Epoch 2/10\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 36.3371 - val_loss: 46.9481\n",
            "Epoch 3/10\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 37.9756 - val_loss: 40.6945\n",
            "Epoch 4/10\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 39.4673 - val_loss: 51.1177\n",
            "Epoch 5/10\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 41.5804 - val_loss: 51.0971\n",
            "Epoch 6/10\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 40.7072 - val_loss: 39.4216\n",
            "Epoch 7/10\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 43.1723 - val_loss: 48.4722\n",
            "Epoch 8/10\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 32.0034 - val_loss: 43.1345\n",
            "Epoch 9/10\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 29.8398 - val_loss: 39.4038\n",
            "Epoch 10/10\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 31.9838 - val_loss: 37.0965\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 33.0050\n",
            "test loss, test mse: 33.0049934387207\n",
            "Epoch 1/10\n",
            "13/13 [==============================] - 1s 16ms/step - loss: 64.6336 - val_loss: 79.1749\n",
            "Epoch 2/10\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 42.2127 - val_loss: 40.4887\n",
            "Epoch 3/10\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 34.2667 - val_loss: 34.4311\n",
            "Epoch 4/10\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 31.0104 - val_loss: 34.6364\n",
            "Epoch 5/10\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 31.4630 - val_loss: 40.5060\n",
            "Epoch 6/10\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 33.2068 - val_loss: 33.1018\n",
            "Epoch 7/10\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 32.9864 - val_loss: 32.6729\n",
            "Epoch 8/10\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 28.8199 - val_loss: 32.6436\n",
            "Epoch 9/10\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 28.2797 - val_loss: 34.6721\n",
            "Epoch 10/10\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 30.7854 - val_loss: 33.9466\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 33.0198\n",
            "test loss, test mse: 33.01980972290039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYfuwjWG0Lje"
      },
      "source": [
        "교차 검증을 통해서 모델을 돌릴 수 있는 것까지 확인해보았습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0vEpSw0eRjM"
      },
      "source": [
        "## 신경망에서의 하이퍼 파라미터 튜닝"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "교차 검증 방법을 익혔으니 이제 본격적으로 하이퍼파라미터 튜닝을 시도해보겠습니다.<br/>\n",
        "머신러닝(Section 2)에서 공부하셨던 것처럼 흔히 사용되는 하이퍼파라미터 튜닝 방법에는 아래와 같은 것들이 있습니다."
      ],
      "metadata": {
        "id": "BMPHCQK08h4H"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQyAVWcHgMHJ"
      },
      "source": [
        "### 하이퍼파라미터 튜닝 방식의 종류"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8hBYEoueZWH"
      },
      "source": [
        "1. **\"Babysitting\"(육아) 혹은 \"Grad Student Descent\"(대학원생 갈아넣기)**\n",
        "\n",
        "    다윈의 진화론을 아시나요? 진화론에서는 '자연 선택'이란 단어가 진화를 주도했다고 말하곤 합니다.<br/>\n",
        "하지만 하이퍼 파라미터 선택은 자연이 해주지 않습니다. 그렇다면 우리가 직접 하는 수 밖에 없겠죠?<br/>\n",
        "이전 프로젝트나 이번 스프린트에서 모델 성능을 높이기 위해 여러 숫자를 직접 넣어보며 하이퍼 파라미터를 수없이 조정했다면,<br/>\n",
        "첫 번째 방법을 수행했다고 말할 수 있겠습니다.\n",
        "\n",
        "    100% **<font color=\"ff6f61\">수작업(Manual)</font>**으로 파라미터를 수정하는 방법입니다.<br/>\n",
        "학계에서 논문을 출간할 수 있을 정도로 놀라운 정확도를 보여주는 하이퍼파라미터의 수치를 찾아내기 위해 쓰는 방법이죠.<br/>\n",
        "이를 위해서 실험자의 경험이나 도메인 지식이 필요하기도 합니다.<br/>\n",
        "~~*(물론 지도교수님들이 이 걸 직접 하시진 않습니다, 교수님의 시간은 소중하니까요...)*~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmebMkiqhadz"
      },
      "source": [
        "2. **Grid Search**\n",
        "\n",
        "    하지만 언제까지나 이렇게 하나하나 수작업으로만 시도해 볼 수는 없겠죠.<br/>\n",
        "1번 방식을 자동화한 방법이 바로 **<font color=\"ff6f61\">\"Grid Search\"</font>**입니다.<br/>\n",
        "이 방법에서는 하이퍼파라미터마다 탐색할 지점을 정해주면 모든 지점에 해당하는 조합을 알아서 수행합니다.\n",
        "\n",
        "    Grid Search는 학습을 실행한 뒤 한참 놀다오면 되는 매우 편한 방법이지만 **장점만 있는 것은 아닙니다.**<br/>\n",
        "범위를 너무 많이 설정하면 '좀 놀다 오면 끝나는' 수준을 넘어 '수료하고 취직을 하고 나서도 끝나지 않을 수도' 있는데요.<br/>\n",
        "만약 5개의 파라미터에 대해 각각 5개의 지점을 지정해주면 Grid Search는 총 $5^5=3,125$ 번의 모델 학습을 진행하게 됩니다.<br/>\n",
        "여기에 5번의 교차 검증까지 진행한다면 모델은 $3,125 \\times 5 = 15,625$ 번이나 학습을 수행합니다.<br/>\n",
        "모델 한 번 학습에 10분만 걸린다고 쳐도 **3달 반**이 걸리는 무시무시한 작업입니다. 실제로 이런 일은 없어야겠죠?\n",
        "\n",
        "    그렇기 때문에 Grid Search 로 너무 많은 하이퍼파라미터 조합을 찾으려고 하지 않는 것이 좋습니다.<br/>\n",
        "1개, 혹은 최대 2개 정도의 파라미터 최적값을 찾는 용도로 적합합니다.<br/>\n",
        "굳이 많은 하이퍼파라미터 조합을 시도할 필요는 없습니다.<br/>\n",
        "모델 성능에 **보다 직접적인 영향을 주는 하이퍼파라미터가 따로 있기 때문**인데요.<br/>\n",
        "이러한 파라미터만 제대로 튜닝해서 최적값을 찾은 후 나머지 하이퍼파라미터도 조정해나가면 못해도 90% 이상의 성능을 확보할 수 있습니다.<br/>\n",
        "이런 식으로 하나씩 접근하다 보면 적어도 무한루프가 발생하는 위험은 줄일 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy3bS48nhclC"
      },
      "source": [
        "3. **Random Search**\n",
        "\n",
        "    **<font color=\"ff6f61\">\"Random Search\"</font>** 는 무한 루프라는 Grid Search의 단점을 해결하기 위해 나온 방법입니다.<br/>\n",
        "Random Search 는 지정된 범위 내에서 무작위로 모델을 돌려본 후 최고 성능의 모델을 반환합니다.<br/> 시도 횟수를 정해줄 수 있기 때문에 Grid Search 에 비해서 훨씬 적은 횟수로도 끝마칠 수 있겠죠?\n",
        "\n",
        "    Grid Search 에서는 파라미터의 중요도가 모두 동등하다고 가정합니다.<br/>\n",
        "하지만 위에서 알아본 것처럼 실제로 더 중요한 하이퍼파라미터가 있는데요.<br/>\n",
        "Random Search 는 **상대적으로 중요한 하이퍼파라미터에 대해서는 탐색을 더 하고, 덜 중요한 하이퍼파라미터에 대해서는 실험을 덜 하도록** 합니다.\n",
        "\n",
        "    Random Search 는 절대적으로 완벽한 하이퍼파라미터를 찾아주지는 않는다는 단점을 가지고 있는데요.<br/>\n",
        "하지만 Grid Search와 비교했을 때, 학습에 걸리는 시간이 훨씬 더 적다는 점으로도 Random Search의 의의를 찾을 수 있습니다.\n",
        "\n",
        "> ❗️ ***아래 그림을 보면서 Grid Search 와 Random Search 의 차이에 대해서 생각해봅시다.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7J5Z0d1Gr4Wa"
      },
      "source": [
        "<img src=\"https://i.imgur.com/qwySX8w.png\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbCIi2QWhdSX"
      },
      "source": [
        "4. **Bayesian Methods**\n",
        "\n",
        "    \"Baby sitting\" 이나 \"Grid Search\" 등의 방식에서는 탐색 결과를 보고, 결과 정보를 다시 새로운 탐색에 반영하면 성능을 더 높일 수 있었습니다.<br/> **<font color=\"ff6f61\">베이지안 방식(Bayesian Method)</font> 은 이렇게 이전 탐색 결과 정보를 새로운 탐색에 활용하는 방법**입니다.<br/>\n",
        "그렇기 때문에 베이지안 방법을 사용하면 하이퍼파라미터 탐색 효율을 높일 수 있습니다.<br/>\n",
        "`bayes_opt` 나 `hyperopt`와 같은 패키지를 사용하면 베이지안 방식을 적용할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yZ3D2_a0ck-"
      },
      "source": [
        "### 튜닝 가능한 파라미터에는 어떤 것이 있을까요?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "신경망에서 탐색해 볼 수 있는 하이퍼파라미터의 종류는 다음과 같습니다."
      ],
      "metadata": {
        "id": "pi7Pk6Z3881W"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7KVdgV00em0"
      },
      "source": [
        "- 배치 크기(**`batch_size`**)\n",
        "- 에포크(**`epochs`**)\n",
        "- 옵티마이저(**`optimizers`**)\n",
        "- 학습률(**`learning rate`**)\n",
        "- 활성화 함수(**`activation`**)\n",
        "- Regularization(**`weight decay, Dropout`** 등)\n",
        "- 은닉층(Hidden layer)의 노드(Node) 수"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ❗️ ***실제로는 이보다 더 많은 하이퍼파라미터를 튜닝할 수 있습니다.<br/>\n",
        "하지만 일단은 이정도만 기억해도 좋습니다. 반복하여 시도하다 보면 익숙해질 것입니다.***"
      ],
      "metadata": {
        "id": "OU2bTp3r9FpK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GridSearch 를 사용한 최적의 배치 사이즈 탐색하기"
      ],
      "metadata": {
        "id": "st2t6v75_yu_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "당뇨병 데이터셋을 신경망에 적용해보고 배치 사이즈를 여러 개로 조정하면서 최적의 배치 사이즈를 찾아보겠습니다."
      ],
      "metadata": {
        "id": "_MCgqf3S_7jR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uA45tZ2gnAzA"
      },
      "source": [
        "1. **필요한 패키지를 import 합니다.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHljoCgV0jsv"
      },
      "source": [
        "import numpy\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKv1O8YGnhkl"
      },
      "source": [
        "2. **재현성을 위해 랜덤시드를 고정합니다**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV0abQqmnEU-"
      },
      "source": [
        "numpy.random.seed(42)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVPaC9BKnoKF"
      },
      "source": [
        "3. **데이터셋을 불러온 후에 Feature 와 Label로 분리합니다.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMe4iH0LnEPS"
      },
      "source": [
        "url =\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "\n",
        "dataset = pd.read_csv(url, header=None).values"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCE86l1XnENJ"
      },
      "source": [
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuMkvkCCnxUy"
      },
      "source": [
        "4. **모델을 제작합니다.**\n",
        "\n",
        "    추후 **`KerasClassifier`** 로 Wrapping 하기 위하여 신경망 모델을 함수 형태로 정의합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBqWHYPknHe_"
      },
      "source": [
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(100, input_dim=8, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    \n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkFMgOpAoVCu"
      },
      "source": [
        "4. **`KerasClassifier` 로 wrapping 하여줍니다.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y459TFBFnNvW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7d47182-4bcb-43a9-e622-c8237add5ca9"
      },
      "source": [
        "model = KerasClassifier(build_fn=create_model, verbose=0)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEVdKbdgolHD"
      },
      "source": [
        "5. **하이퍼파라미터 탐색을 위한 탐색 범위를 설정한 후 `GridSearchCV` 를 지정하여 학습합니다.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUhn1yvGnNq6"
      },
      "source": [
        "batch_size = [8, 16, 32, 64, 128]\n",
        "param_grid = dict(batch_size=batch_size)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqwMdrE5nNmQ",
        "outputId": "49c901dd-6505-4ff6-e0f9-bf34b366d7b6"
      },
      "source": [
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
        "grid_result = grid.fit(X, Y)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff56d729b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff5603aa560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDzoXSrmotJK"
      },
      "source": [
        "6. **최적의 결과를 낸 하이퍼파라미터와 각각의 결과를 출력해봅시다.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoubhatunBXs",
        "outputId": "6f445a04-a94b-4302-dde4-bbfb66d20c13"
      },
      "source": [
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.6407011389732361 using {'batch_size': 16}\n",
            "Means: 0.6315423130989075, Stdev: 0.014911532846494317 with: {'batch_size': 8}\n",
            "Means: 0.6407011389732361, Stdev: 0.04977887055410017 with: {'batch_size': 16}\n",
            "Means: 0.5677192091941834, Stdev: 0.058128465916732146 with: {'batch_size': 32}\n",
            "Means: 0.6277056336402893, Stdev: 0.05704244478573418 with: {'batch_size': 64}\n",
            "Means: 0.4517019033432007, Stdev: 0.10637838660895693 with: {'batch_size': 128}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vW76-VK800nN"
      },
      "source": [
        "## 라이브러리를 사용한 하이퍼파라미터 튜닝"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzeyt1jRFenG"
      },
      "source": [
        "### Keras Tuner 를 사용하여 하이퍼파라미터 탐색하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eO5YYXzw02kI"
      },
      "source": [
        "\n",
        "**<font color=\"ff6f61\">Keras Tuner</font>** 는 케라스 프레임워크에서 하이퍼파라미터를 튜닝하는 데 도움이 되는 라이브러리입니다.<br/>\n",
        "Fashion MNIST 예제에 Keras Tuner를 적용하여 하이퍼파라미터 튜닝을 수행해보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPVzHEC0FwQJ"
      },
      "source": [
        "1. **필요한 패키지를 import 합니다.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8zKgeqO1xrI"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "import tensorflow as tf\n",
        "import IPython"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjsjRrOE4eJz"
      },
      "source": [
        "2. **Keras Tuner를 설치한 후 import 합니다.**\n",
        "\n",
        "Keras Tuner는 Colab에 내장된 패키지가 아니기 때문에 따로 설치를 해준 후에 import 하여줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5usUa4k4ddP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e98c06f-8ee8-4d31-a602-bb512f525e84"
      },
      "source": [
        "!pip install -U keras-tuner\n",
        "import kerastuner as kt"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.1.0-py3-none-any.whl (98 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▍                            | 10 kB 20.4 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 20 kB 23.9 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 30 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 40 kB 11.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 61 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 81 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 92 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 98 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.7.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.19.5)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (5.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (1.0.18)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2021.10.8)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.42.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.12.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.3.6)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.10.0.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.1.1)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.1.0 kt-legacy-1.0.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "at8ueGzt4gf6"
      },
      "source": [
        "3. **데이터셋을 불러온 후에 정규화(Normalizing) 해줍니다.**\n",
        "\n",
        "    Fashion MNIST 데이터셋을 불러온 후에 이미지를 0-1 사이의 값으로 정규화합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySHk6qzu4idS"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geA0XOpd4j9A"
      },
      "source": [
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6pNZKnf4msb"
      },
      "source": [
        "4. **Model을 제작합니다.**\n",
        "\n",
        "모델을 제작하고 탐색할 하이퍼파라미터 범위와 지점을 정의합니다.<br/>\n",
        "\n",
        "이 과정에서 Model builder 함수(**`model_builder`**)를 지정하는 과정이 필요합니다.<br/>\n",
        "`model_builder` 라는 함수를 정의하고 해당 함수 내부에서 모델 설계와 하이퍼파라미터 튜닝까지 모두 수행해보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **탐색할 하이퍼파라미터와 범위**\n",
        "    - 은닉층의 노드 수 : 32 부터 512 까지 32개씩 증가시키며 탐색\n",
        "    - 학습률(Learning rate) : 0.01, 0.001, 0.0001 의 3개 지점을 탐색\n"
      ],
      "metadata": {
        "id": "KfeXD2qNB9Ia"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NQgLcp64nNB"
      },
      "source": [
        "def model_builder(hp):\n",
        "  model = keras.Sequential()\n",
        "  model.add(Flatten(input_shape=(28, 28)))\n",
        "  \n",
        "  hp_units = hp.Int('units', min_value = 32, max_value = 512, step = 32)\n",
        "  model.add(Dense(units = hp_units, activation = 'relu'))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \n",
        "  \n",
        "  model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate),\n",
        "                loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True), \n",
        "                metrics = ['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_QHPhoG4qFM"
      },
      "source": [
        "5. **하이퍼파라미터 튜닝을 수행할 튜너(Tuner)를 지정합니다.**\n",
        "\n",
        "Keras Tuner 에서는 **Random Search, Bayesian Optimization, Hyperband** 등의 최적화 방법을 수행할 수 있습니다.<br/>\n",
        "아래에서는 **`Hyperband`** 를 통해서 튜닝을 수행해보도록 하겠습니다.\n",
        "\n",
        "Hyperband 사용 시 Model builder function(**`model_builder`**), 훈련할 최대 epochs 수(**`max_epochs`**) 등을 지정해주어야 합니다.<br/>\n",
        "Hyperband 는 리소스를 알아서 조절하고 조기 종료(Early-stopping) 기능을 사용하여 \n",
        "높은 성능을 보이는 조합을 신속하게 통합한다는 장점을 가지고 있습니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBbsQL-a4q07"
      },
      "source": [
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective = 'val_accuracy', \n",
        "                     max_epochs = 10,\n",
        "                     factor = 3,\n",
        "                     directory = 'my_dir',\n",
        "                     project_name = 'intro_to_kt')                       "
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-xByktJ4wZx"
      },
      "source": [
        "6. **Callback 함수를 지정합니다.**\n",
        "\n",
        "    하이퍼파라미터 탐색을 실행하기 전에 학습이 끝날 때마다 이전 출력이 지워지도록 콜백 함수를 정의해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnacgPFJ4usU"
      },
      "source": [
        "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
        "  def on_train_end(*args, **kwargs):\n",
        "    IPython.display.clear_output(wait = True)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "하이퍼파라미터 탐색을 수행합니다.\n",
        "\n",
        "> ❗️ ***아래 코드를 통해 하이퍼파라미터 탐색을 수행하려면 약 20분의 시간이 필요합니다.<br/>\n",
        "충분한 시간 여유를 가지고 수행해주세요.***\n"
      ],
      "metadata": {
        "id": "jjJHUf7nG6Cz"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUiW8GdP40It",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4c34ae8-5607-4e64-880d-0f5ec7ec2cc9"
      },
      "source": [
        "tuner.search(X_train, y_train, epochs = 10, validation_data = (X_test, y_test), callbacks = [ClearTrainingOutput()])\n",
        "\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "하이퍼 파라미터 검색이 완료되었습니다. \n",
        "최적화된 첫 번째 Dense 노드 수는 {best_hps.get('units')} 입니다.\n",
        "최적의 학습 속도는 {best_hps.get('learning_rate')} 입니다.\n",
        "\"\"\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30 Complete [00h 01m 22s]\n",
            "val_accuracy: 0.8533999919891357\n",
            "\n",
            "Best val_accuracy So Far: 0.8804000020027161\n",
            "Total elapsed time: 00h 19m 18s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "\n",
            "하이퍼 파라미터 검색이 완료되었습니다. \n",
            "최적화된 첫 번째 Dense 노드 수는 448 입니다.\n",
            "최적의 학습 속도는 0.001 입니다.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOnVR4xj43cm"
      },
      "source": [
        "7. **최고 성능을 보이는 하이퍼파라미터 조합으로 다시 학습을 진행해봅시다.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3046jg3s43zR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6eb27289-1fac-4af1-86b4-d1bf60c2e5c7"
      },
      "source": [
        "model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 448)               351680    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                4490      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 356,170\n",
            "Trainable params: 356,170\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjtkdgh845Zt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8e375fc-e9b9-478a-b2ba-37281efab5cf"
      },
      "source": [
        "model.fit(X_train, y_train, epochs = 10, validation_data = (img_test, label_test))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4778 - accuracy: 0.8297 - val_loss: 64.3352 - val_accuracy: 0.8294\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.3610 - accuracy: 0.8679 - val_loss: 52.7949 - val_accuracy: 0.8505\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.3236 - accuracy: 0.8809 - val_loss: 55.0612 - val_accuracy: 0.8547\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2990 - accuracy: 0.8886 - val_loss: 54.0619 - val_accuracy: 0.8621\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2812 - accuracy: 0.8946 - val_loss: 50.8726 - val_accuracy: 0.8790\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2673 - accuracy: 0.9004 - val_loss: 63.9975 - val_accuracy: 0.8576\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2514 - accuracy: 0.9053 - val_loss: 62.4039 - val_accuracy: 0.8608\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2414 - accuracy: 0.9089 - val_loss: 65.6685 - val_accuracy: 0.8615\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2306 - accuracy: 0.9139 - val_loss: 78.2690 - val_accuracy: 0.8477\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2226 - accuracy: 0.9164 - val_loss: 59.1385 - val_accuracy: 0.8704\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff56d460490>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    }
  ]
}